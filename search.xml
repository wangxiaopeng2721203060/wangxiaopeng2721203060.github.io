<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Docker存储</title>
      <link href="/2096/09/26/docker%E5%AD%98%E5%82%A8/"/>
      <url>/2096/09/26/docker%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<p>#Docker 存储</p><h3 id="Docek-镜像层的镜像分层结构"><a href="#Docek-镜像层的镜像分层结构" class="headerlink" title="Docek 镜像层的镜像分层结构"></a>Docek 镜像层的镜像分层结构</h3><a id="more"></a><ul><li>docker的镜像分层结构，如下所示：</li></ul><p><img src="https://docs.docker.com/storage/storagedriver/images/container-layers.jpg" alt="基于Ubuntu映像的容器层"></p><ul><li><p>docker镜像中引入层layer概念，镜像的制作过程中的每一步都会生产一个新的镜像层</p></li><li><p>容器读写层的工作原理</p><blockquote><p>我们刚刚在说镜像的分层特性的时候说到镜像是只读的。而事实上当我们使用镜像启动一个容器的时候，我们其实是可以在容器里随意读写的，从结果上看，似乎与镜像的只读特性相悖。</p><p>我们继续看上面的图，其实可以看到在镜像的最上层，还有一个读写层。而这个读写层，即在容器启动时为当前容器单独挂载。每一个容器在运行时，都会基于当前镜像在其最上层挂载一个读写层。而用户针对容器的所有操作都在读写层中完成。一旦容器销毁，这个读写层也随之销毁。</p><blockquote><p>知识点： 容器=镜像+读写层</p></blockquote><p>而我们针对这个读写层的操作，主要基于两种方式：写时复制和用时分配。</p></blockquote></li></ul><hr><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p><img src="https://docs.docker.com/storage/storagedriver/images/sharing-layers.jpg" alt="容器共享相同的图像"></p><ul><li><p>容器由最上面一个可写的容器层和若干个只读的镜像层组成，容器的数据就存在这些层中。这种分层结构最大的特点是Copy-on-Write。</p><ol><li><p>新数据会直接存放在最上面的容器层</p></li><li><p>修改现有数据会从镜像层复制文件到容器中，再在容器层修改并保存，镜像层的数据不会发生改变</p></li><li><p>若多个层中有命名相同的文件，用户只能看到最上面一层的文件</p></li></ol></li></ul><ul><li>分层结构使镜像和容器的创建、共享以及分发变得非常高效，而这些都要归功于 Docerk stoage driver。<strong>正是 storage driver 实现了多层数据的堆叠并为用户提供一个单一的合并之后的统一视图</strong>。</li></ul><hr><h3 id="Docker-为容器提供了两种存放数据的资源："><a href="#Docker-为容器提供了两种存放数据的资源：" class="headerlink" title="Docker 为容器提供了两种存放数据的资源："></a>Docker 为容器提供了两种存放数据的资源：</h3><ul><li>由storage driver（存储驱动） 管理的镜像层和容器层<ul><li>用来放一些无状态的数据<ul><li><strong>对于某些容器，直接将数据放在由</strong> storage driver <strong>维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。</strong></li></ul></li></ul></li><li>Data Volume。（数据卷）<ul><li>用来放一些有状态的数据，例如数据库<ul><li><strong>本质上是</strong> Docker Host （主机）<strong>文件系统中的目录或文件，能够直接被 ** mount （挂载）</strong>到容器的文件系统中**。</li></ul></li></ul></li></ul><h4 id="关于docker镜像的三问"><a href="#关于docker镜像的三问" class="headerlink" title="关于docker镜像的三问"></a>关于docker镜像的三问</h4><ul><li>基于镜像A创建镜像B时是否会拷贝A镜像中的所有文件：<code>是不会的</code></li><li>基于镜像创建容器时是否会拷贝镜像中的所有文件至文件层：<code>不会的</code></li><li>容器与镜像在结构上有什么区别：<code>没有区别容器会比镜像多了一个</code> <code>merged</code>文件</li></ul><blockquote><p>在讲原理前，先讲下写时复制和写时分配</p></blockquote><h4 id="写时复制（CoW）"><a href="#写时复制（CoW）" class="headerlink" title="写时复制（CoW）"></a>写时复制（CoW）</h4><blockquote><p>所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论多少个容器共享同一个image，所作的写操作都是从image中复制到自己的文件系统中的复制本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离的，相互不影响。使用CoW可以有效的提高磁盘的利用率。</p></blockquote><h4 id="用时分配（allocate-on-demand）"><a href="#用时分配（allocate-on-demand）" class="headerlink" title="用时分配（allocate-on-demand）"></a>用时分配（allocate-on-demand）</h4><blockquote><p>而用时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。</p></blockquote><h4 id="Docker存储驱动的作用"><a href="#Docker存储驱动的作用" class="headerlink" title="Docker存储驱动的作用"></a>Docker存储驱动的作用</h4><blockquote><p>将这些分层的镜像文件堆叠起来，并且提供统一的视图.使container的文件系统看上去和我们普通的文件系统没什么区别。<br>当创建一个新的容器的时候,实际上是在镜像的分层上新添加了一层container layer（容器层）.之后所有对容器产生的修改,实际都只影响这一层。</p><p>注意</p><p>容器层：读写层(可写层)<br>镜像层：只读层</p></blockquote><blockquote><p> Docker 支持多种 storage driver，有 AUFS 、Device Mapper 、Btrfs 、OverlayFS 、VFS 和ZFS。它们都能实现分层的架构，同时又有各自的特性。对于Docker 用户来说，具体选择使用哪个 storage driver 是一个难题，因为：</p></blockquote><p>​            没有哪个driver 能够适应所有的场景。</p><p>​            driver 本身在快速发展和迭代。</p><blockquote><p>优先使用 Linux 发行版默认的 storage driver。Docker 安装时会根据当前系统的配置选择默认的 driver。默认 driver 具有最好的稳定性，因为默认 driver 在发行版上经过了严格的测试。</p></blockquote><blockquote><p>运行<code>docker info</code>可以查看可查看当前系统使用的<code>Storage driver</code>。</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; &gt; [root@izbp1dg6m4eebtcm77n0smz ~]# docker info</span><br><span class="line">&gt; &gt; Client:</span><br><span class="line">&gt; &gt; Debug Mode: false</span><br><span class="line">&gt; &gt; </span><br><span class="line">&gt; &gt; Server:</span><br><span class="line">&gt; &gt; Containers: 6</span><br><span class="line">&gt; &gt; Running: 4</span><br><span class="line">&gt; &gt; Paused: 0</span><br><span class="line">&gt; &gt; Stopped: 2</span><br><span class="line">&gt; &gt; Images: 4</span><br><span class="line">&gt; &gt; Server Version: 19.03.5</span><br><span class="line">&gt; &gt; Storage Driver: overlay2</span><br><span class="line">&gt; &gt; Backing Filesystem: extfs</span><br><span class="line">&gt; &gt; Supports d_type: true</span><br><span class="line">&gt; &gt; Native Overlay Diff: false</span><br><span class="line">&gt; &gt; Logging Driver: json-file</span><br><span class="line">&gt; &gt; Cgroup Driver: cgroupfs</span><br><span class="line">&gt; &gt;</span><br></pre></td></tr></table></figure></blockquote></blockquote><blockquote></blockquote><hr><blockquote><p>Ubuntu 用的 <code>AUFS</code>，底层文件系统是 <code>extfs</code>，各层数据存放在 <code>/var/lib/docker/aufs</code>。<br>centos默认的<code>driver</code>用的是<code>overlay2</code>，底层的文件系统是xfs,各层数据存放在<code>/var/lib/docker</code></p></blockquote><blockquote><p>而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。</p><p>比如启动一个容器，并不是为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。</p></blockquote><ul><li>docker提供了多种的存储驱动来实现不同的方式存储镜像</li></ul><h5 id="Docker五种存储驱动原理及应用场景和性能测试对比"><a href="#Docker五种存储驱动原理及应用场景和性能测试对比" class="headerlink" title="Docker五种存储驱动原理及应用场景和性能测试对比"></a>Docker五种存储驱动原理及应用场景和性能测试对比</h5><blockquote><p><code>Docker</code> 最开始采用AUFS作为文件系统，也得益于AUFS分层的概念，实现了多个Container可以共享同一个image。但由于<code>AUFS</code> 为并入 <code>Linux</code>内核，且只支持 <code>Ubuntu</code>，考虑到兼容的问题，在 <code>Docker 0.7</code> 版本中引入了存储驱动，就如Docker官网上说的，没有单一的驱动适应所有的应用场景，要根据不同的场景选择合适的存储驱动，才能有效的提高Docker 的性能。如何选择适合的存储驱动，要先了解存储驱动原理才能更好的判断。</p></blockquote><blockquote><p>接下来我们说说这些分层的镜像是如何在磁盘中存储的。</p></blockquote><ul><li><p><code>docker</code> 提供了多种存储驱动来实现不同的方式存储镜像</p><ul><li><p>下列出了 <code>Docker</code> 中支持的存储驱动程序：</p><table><thead><tr><th align="center">技术</th><th align="center">存储驱动成名称</th></tr></thead><tbody><tr><td align="center"><code>OverlayFS</code></td><td align="center"><code>overlay</code> 或  <code>overlay2</code></td></tr><tr><td align="center"><code>AUFS</code></td><td align="center"><code>aufs</code></td></tr><tr><td align="center"><code>Btrfs</code></td><td align="center"><code>btrfs</code></td></tr><tr><td align="center"><code>Device Mapper</code></td><td align="center"><code>devicemapper</code></td></tr><tr><td align="center"><code>VFS</code></td><td align="center"><code>vfs</code></td></tr><tr><td align="center"><code>ZFS</code></td><td align="center"><code>zfs</code></td></tr></tbody></table></li></ul></li></ul><h5 id="AUFS"><a href="#AUFS" class="headerlink" title="AUFS"></a>AUFS</h5><blockquote><p>AUFS（AnotherUnionFS）是一种 Union FS ，是文件级的存储驱动。AUFS 是一个能透明覆盖一个或多个县有文件系统的层状文件系统，把多层合并成文件系统的单层表示。简单来说就是支持将不同目录挂载到同一个虚拟文件系统下的文件系统。这种文件可以一层一层地叠加修改文件。无论低下有多少层都是只读的，只有最上层的文件系统是可写的。当需要修改文件时，AUFS创建该文件的一个副本，使用CoW将文件从只读层复制到可写层进行修改，结果保存在可写层。在Docker中，低下的只读层就是image，可写层就是Container。结构如下图所示：</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/87af417e9f80a3eb8ae9716ae07b3dc1.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/87af417e9f80a3eb8ae9716ae07b3dc1.jpg" alt="1.jpg"></a></p><blockquote><p><strong>历史</strong>：aufs驱动老早就在Docker中存在了！其实，他在使用<code>graphdriver</code>这个名字之前久存在了。如果你查看项目在那（即首次使用graphdriver名称）提交之前的历史，之前项目中当时只有一个aufs的实现。下边devicemapper部分会讲到更多关于graphdriver这个名称诞生的历史。</p><p><strong>实现</strong>：Aufs最初代表的意思“另一个联合文件系统（another union filesystem）”，试图对当时已经存在的UnionFS实现进行重写。正如你期望的那样，它是一个传统意义的上层覆盖，通过利用aufs称作为“分支（branch）”的特性，让堆叠的目录合并成一个堆叠内容单一挂载点视图。此驱动会将父级信息组合一个有序列表，并把它作为挂载参数，然后把重活移交给aufs来把这些分层组装成一个联合视图。更多的细节信息可以在aufs的<a href="http://aufs.sourceforge.net/aufs3/man.html" target="_blank" rel="noopener">帮助文档</a>上看到。</p><p><strong>优点</strong>：这可能是历史最久且测试最完善的graphdriver后端了。它拥有不错的性能，也比较稳定，适用于广泛的场景。尽管它只在Ubuntu或者Debian的内核上才可以启用（下边有说明），但是这两个发行版和Docker一起使用的场景已经非常多，这让它在广阔的环境中得到了验证。同时，通过让不同的容器从同一个分层里面加载相同的库（因为他们在磁盘上是相同的inode）达到了共享内存页的效果。</p><p><strong>缺点</strong>：Aufs从来没有被上游Linux内核社区接受。多年来Ubuntu和Debian都需要往内核集成一个历史久远的补丁包，且原作者已经放弃了让它被内核采纳的努力。可能与IPV4和IPv6的辩论有些类似，人们担心某一天内核更新后会出现难以整合aufs的补丁的情况，从而导致aufs没得玩。但是就如IPv6，替换aufs势在必行的决心讲了一年又一年。除此之外，它面临着很多其他比较棘手的问题。其中一个最麻烦的、也是比较有历史的问题（尽管某种程度上这是一个安全的特性），是关于在高层更改向上拷贝的文件的权限的，这个问题困扰了不少用户。最终在2015年早期的时候通过编号为<a href="http://dockone.io/docker/docker#11799" target="_blank" rel="noopener">#11799</a>的PR使用aufs的<code>dirperm1</code>特性修复了。自然，这需要内核中有具有<code>dirperm1</code>能力aufs，然而这在今天任何较新版本的Ubuntu或者Debian上都已经不成问题了。</p><p><strong>总结</strong>：如果你在使用Ubtuntu或者Debian，那默认的graphdriver就是aufs，它能满足你绝大多数需求。有人期望有一天它能被overlay的实现取代，但是考虑到overlay文件系统的诸多问题，以及在上游内核中的成熟程度等挑战，这尚未实现。最后，aufs中没有配额的支持。</p></blockquote><h5 id="Overlay"><a href="#Overlay" class="headerlink" title="Overlay"></a>Overlay</h5><blockquote><p>Overlay 是Linux内核3.18后支持的，也是一种Union FS，和AUFS的多层不同的是Overlay只有两层：一个upper文件系统和一个lower文件系统，分别代表Docekr的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。在Docekr中，底下的只读层就是image，可写层就是Container。目前最新的OverlayFS为Overlay2。结构图如下所示：</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/c12e244abea02f7ed1eb42f0ccdbcf1d.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/c12e244abea02f7ed1eb42f0ccdbcf1d.jpg" alt="2.jpg"></a></p><blockquote><p><strong>历史</strong>：<strong>2014年8月</strong>，Red Hat的 Alex Larsson在编号为<a href="https://github.com/docker/docker/commit/453552c8384929d8ae04dcf1c6954435c0111da0" target="_blank" rel="noopener">453552c8384929d8ae04dcf1c6954435c0111da0</a>的代码提交中添加了针对OverlayFS（最初的上游内核的名称）的graphdriver。</p><p><strong>实现</strong>：Overlay是一个联合文件系统，它的概念较之aufs的分支模型更为简单。Overlay通过三个概念来实现它的文件系统：一个“下层目录（lower-dir）”，一个“上层目录（upper-dir）”，和一个做为文件系统合并视图的“合并（merged）”目录。受限于只有一个“下层目录”，需要额外的工作来让“下层目录”递归嵌套（下层目录自己又是另外一个overlay的联合），或者按照Docker的实现，将所有位于下层的内容都硬链接到“下层目录”中。正是这种可能潜在的inode爆炸式增长（因为有大量的分层和硬连接）阻碍了很多人采用Overlay。Overlay2通过利用更高内核（4.0以及以上的版本）中提供了的更优雅处理多个位于下层分层的机制解决了这个问题。</p><p><strong>优点</strong>：Overlay作为一个合并进主线Linux内核的一个有完整支持的联合文件系统有望成为人们的焦点。与aufs类似，通过使用磁盘上相同的共享库，它也能让分散的容器实现内存共享。Overlay同时有很多的上游Linux内核基于现代的应用场景，如Docker，被持续开发（参看overlay2）。</p><p><strong>缺点</strong>：硬链接的实现方式已经引发了 <a href="http://dockone.io/docker/docker#10613" target="_blank" rel="noopener">inode耗尽</a>的问题，这阻碍了它的大规模采用。inode耗尽并不是唯一的问题，还有其他一些与用户命名空间、SELinux支持有关的问题，且整体的成熟状况不足也阻碍着overlay直接取代aufs成为Docker默认的graphdriver。随着很多问题的解决，特别是在最新的内核发新版中，overlay的可用度越来越高了。如今出现的Overlay2修复了inode耗尽的问题，应该是从Docker 1.12版本之后的焦点，成为overlay驱动的后续开发对象。出于向后兼容的原因，<code>overlay</code>驱动将会继续留在Docker引擎中继续支持现有的用户。</p><p><strong>总结</strong>：考虑到aufs没有足够多的发行版的支持，能有一个上游集成的联合文件系统且拥有Linux内核文件系统社区的支持，overlay驱动的加入是一个重大进步。Overlay在过去的18-24个月已经成熟了很多，并且随着overlay2的出现，它之前一些麻烦的问题已经解决了。希望overlay（或者更具可能性的overlay2）会成为未来默认的graphdriver。为了overlay最好的体验，上游内核社区在4.4.x的内核系列里面修复了很多overlay实现中存在的问题；选择该系列中更新的版本可以获得overlay更好的性能和稳定性。</p></blockquote><h5 id="Overlay2"><a href="#Overlay2" class="headerlink" title="Overlay2"></a>Overlay2</h5><blockquote><p><strong>历史</strong>：<a href="https://github.com/dmcgowan" target="_blank" rel="noopener">Derek McGowan</a>在编号为<a href="https://github.com/docker/docker/pull/22126" target="_blank" rel="noopener">#22126</a>的PR中添加了overlay2的graphdriver，在<strong>2016年6月</strong>被合并进Docker 1.12版本，正如该PR的标题注明的，要取代之前overlay的主要原因是它能“支持多个下层目录”，能解决原先驱动中inode耗尽的问题。</p><p><strong>实现</strong>：在上面的overlay部分已经讲述了Linux内核中的Overlay的框架。上面链接的PR中改进了原有的设计，基于Linux内核4.0和以后版本中overlay的特性，可以允许有多个下层的目录。</p><p><strong>优点</strong>：overlay2解决了一些因为最初驱动的设计而引发的inode耗尽和一些其他问题。Overlay2继续保留overlay已有的优点，包括在同一个引擎的多个容器间从同一个分层中加载内库从而达到内存共享。</p><p><strong>缺点</strong>：现在可能唯一能挑出overlay2的问题是代码库还比较年轻。很多早期的问题已经在早期测试过程中发现并被及时解决了。但是Docker 1.12是第一个提供overlay2的发行版本，随着使用量的增长，相信可能还会发现其他问题。</p><p><strong>总结</strong>：将Linux内核中的一个现代的、广受支持的联合文件系统，和一个和Docker中一个性能优秀的graphdriver结合起来，这应该是Docker引擎未来打造默认的graphdriver最好的道路，只有这样才能获得各种Linux发行版广泛的支持。</p></blockquote><h5 id="Device-mapper"><a href="#Device-mapper" class="headerlink" title="Device mapper"></a>Device mapper</h5><blockquote><p>Device mapper 是Linux 内核 2.6.9 后支持的，提供的一种从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略。前面讲的 AUFS 和 OverlayFS 都是文件级存储，而 Device mapper 是块级存储，所有的操作都是直接对块进行操作，而不是文件。Device mapper 驱动会先在块设备上创建一个资源池，然后在资源池上创建一个带有文件系统的基本设备，所有镜像都是这个基本设备的快照，而容器则是镜像的快照。所以在容器里看到文件系统是资源池上基本设备的文件系统的快照，并不有为容器分配空间。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个用时分配。当要修改已有文件时，再使用 CoW 为容器快照分配块空间，将要修改的数据复制在容器快照中新的块里在进行修改。Device mapper 驱动默认会创建一个 100 G 的文件包含镜像和容器。每个容器被限制在 10G 大小的卷内，可以自己设置调整。结构如下图所示：</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/0ef920a30190955999076f524229f321.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/0ef920a30190955999076f524229f321.jpg" alt="3.jpg"></a></p><blockquote><p> <strong>历史</strong>：Devicemapper很早就以Ｃ代码的包装器面貌存在了，用来和libdevmapper进行交互； 是2013的９月Alex Larsson在编号为<a href="https://github.com/docker/docker/commit/739af0a17f6a5a9956bbc9fd1e81e4d40bff8167" target="_blank" rel="noopener"> 739af0a17f6a5a9956bbc9fd1e81e4d40bff8167</a>的代码提交中添加的。几个月后的重构了才诞生了我们现在所知道的“graphdriver”这个词；Solomon Hykes在2013年10月份早期代码合并的注释中说：将devmapper和aufs整合进通用的“graphdriver”框架。</p><p>  <strong>实现</strong>：devicemapper这个graphdriver利用了Linux中devicemapper代码中众多特性之一，“轻配置（thin provisioning）”，或者简称为“thinp”。<em>（译注：根据Wikipedia，“thin provisioning是利用虚拟化技术，让人觉得有比实际可用更多的物理资源。如果系统的资源足够，能同时满足所有的虚拟化的资源，那就不能叫做thin-provisioned。”）</em> 这与之前提到的联合文件系统不同，因为devicemapper是基于块设备的。这些“轻配置（thin-provisioned）”的块设备带来的是如联合文件系统所提供的一样轻量的行为，但是最重要的一点是，他们不是基于文件的（而是基于块设备的）。正如你能推测的，这让计算分层之间的差别变得不再容易，也丧失了通过在容器间使用同样的库片段而共享内存的能力。</p><p>  <strong>优点</strong>：Devicemapper在过去的年间也被一些人感到不屑，但是它提供的一个非常重要的能力让红帽系（Fedora,RHEL，Project Atomic）也有了一个graphdriver。因为它是基于块设备而不是基于文件的，它有一些内置的能力如配额支持，而这在其他的实现中是不容易达到的。</p><p>  <strong>缺点</strong>：使用devicemapper没有办法达到开箱立即唾手可得很好的性能。你必须遵循<a href="https://docs.docker.com/engine/userguide/storagedriver/device-mapper-driver/#/configure-direct-lvm-mode-for-production" target="_blank" rel="noopener">安装和配置指示</a>才能得到性能还可以的配置。并且最重要的是，在任何需要用Docke引擎来做点正事的地方，都不要使用“虚拟设备（loopback）”模式（对于运行有devicemapper且负载高的系统，如延迟删除（ deferred removal）这样的特性绝对有必要的，这能减少引擎看起来好似夯住了一样的悲剧。）。它的一些特性依赖libdevmaper特定的版本，并且需要比较高级的技能来验证系统上所有的设置。同时，如果Docker Engine的二进制是静态编译的话，devicemapper会完全无法工作，因为它需要<a href="http://dockone.io/docker/docker#11412" target="_blank" rel="noopener">udev sync</a>的支持，而这不能被静态编译进引擎中。</p><p>  <strong>总结</strong>：对于红帽类发行版本来说，devicemapper已经成为“可以直接用”的选择，并且在过去几年间里得到了红帽团队的大力支持和改进。它质量上有优点也有缺点，如果安装/配置过程中没有特别格外注意的话，可能导致和其他选项比较起来性能低下、质量不高。鉴于overlay和overlay2受到了Fedora和RHEL最新的内核的支持，并且拥有SELinux的支持，除非在Red Hat场景中有某种必须使用devicemapper的需求，我想随着用户的成熟他们会转向overlay的怀抱。</p></blockquote><h5 id="Btrfs"><a href="#Btrfs" class="headerlink" title="Btrfs"></a>Btrfs</h5><blockquote><p>Btrfs 被称为下一代写时复制文件系统，并入Linux内核，也是文件级存储，但可以向 Device mapper 一直操作底层设备。 Btrfs 把文件系统的一部分配置为一个完整的子文件系统，称为 subvolume。那么采用 subvolume ，一个大的文件系统可以被划分为很多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间使用时便从底层设备中分配，类似应用程序调用 malloc（）分配内存一样。为了灵活利用设备空间， Btrfs 将磁盘空间划分为多个 chunk。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata ，某些chunk 只存放数据。这种模型有很多优点，比如 Btrfs 支持动态添加设备。用户在系统中添加新的磁盘之后，可以使用 Btrfs 的命令将该设备添加到文件系统中。Btrfs 把一个大的文件系统当成一个资源池，配置成多个完整的子文件系统，还可以往资源池里加新的子文件系统，而基础镜像则是子文件系统的快照，每个子镜像和容器都有自己的快照，这些快照都是 subvolume 的快照。</p></blockquote><p>   <a href="http://dockone.io/uploads/article/20190702/99ab3acda52806a948625219d9e96a0b.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/99ab3acda52806a948625219d9e96a0b.jpg" alt="4.jpg"></a></p><blockquote><p>当写入一个新文件时，为在容器的快照里为其分配一个新的数据块，文件写在这个空间里，这个叫做分配。而当要修改已有文件时，使用 CoW 复制分配一个新的原始数据和快照，在这个新分配的空间变更数据，变结束再跟新相关的数据结构指向新子文件系统和快照，原来的原始数据和快照没有指针指向，被覆盖。</p></blockquote><blockquote><p><strong>历史</strong>：<strong>2013年12月</strong>较晚的时候，Red Hat公司的Alex Larsson在编号为<a href="https://github.com/docker/docker/commit/e51af36a85126aca6bf6da5291eaf960fd82aa56" target="_blank" rel="noopener">e51af36a85126aca6bf6da5291eaf960fd82aa56</a>的提交中，让使用btrfs作为管理<code>/var/lib/docker</code>的文件系统成为可能。</p><p><strong>实现</strong>：Btrfs的原生特性中，有两个是“子卷（subvolumes）”和“快照（snapshots）”。<em>（译注：根据Wikipedia，“子卷在btrfs中不是一个块设备，也不应该被当做是一个块设备。相反，子卷可以被想象成POSIX文件的命名空间。这个命名空间可以通过顶层的子卷来访问到，也可以独立地被挂载。快照在Btrfs中实际上是一个子卷，通过使用Btrfs的写时复制来和其他的子卷共享数据，对快照的更改不会影响原先的子卷。” ）</em> graphdriver实现中主要结合了这两个能力，从而提供了堆叠和类似写时复制的特性。当然，graphdriver的根（默认情况下是：<code>/var/lib/docker</code>）需要是一个被btrfs文件系统格式化的磁盘。</p><p><strong>优点</strong>：Btrfs几年前发布的时候（2007-2009时代），它被视作一个未来的Linux文件系统并<a href="https://lwn.net/Articles/342892/" target="_blank" rel="noopener">受到了大量的关注</a>。如今在上游Linux内核中，该文件系统已经比较健壮，并受到良好的支持，是众多可选的文件系统之一。</p><p><strong>缺点</strong>：但是Btrfs并没有成为Linux发行版的主流选择，所以你不大可能已经有一个btrfs格式化的磁盘。因为这种在Linux发行版中采用不足的原因，它并没有受到类似其他graphdriver一样的关注和采用。</p><p><strong>总结</strong>：如果你正在使用btrfs，那很显然的这个graphdriver应该迎合了你的需求。在过去几年有过很多Bug，并且有一段时间缺乏对SELinux的支持，但是这已经<a href="http://dockone.io/docker/docker#16452" target="_blank" rel="noopener">被修复</a>了。同时，对btrfs配额的支持也直接加进了docker守护进程中，这是<a href="https://github.com/zhuguihua" target="_blank" rel="noopener">Zhu Guihua</a>在编号为<a href="http://dockone.io/docker/docker#19651" target="_blank" rel="noopener">#19651</a>的PR中添加的，这个特性包含在了Docker 1.12版本中。</p></blockquote><h5 id="ZFS"><a href="#ZFS" class="headerlink" title="ZFS"></a>ZFS</h5><blockquote><p>ZFS 文件系统是一个革命性的全新的文件系统，它从根本上改变了文件系统的管理方式， ZFS 完全抛弃了 “ 卷管理 ” ，不再创建虚拟的卷，而是把所有设备集中到一个存储池中进行管理，用 “ 存储池 ”  的概念来管理物理存储空间。过去，文件系统都是构建在物理设备之上的，为了管理这些物理设备，并为数据提供冗余，“ 卷管理 ” 的概念提供了一个单设备的映射。而 ZFS 创建在虚拟的，被称为 “ zpools ” 的存储池之上。每个存储池由若干虚拟设备（ virtual devices ，vdevs ）组成。这些虚拟设备可以是原始磁盘，也节能是一个RAID1 镜像设备，或是非标准 RAID 等级的多磁盘组。  于是 zpool 上的文件系统可以使用这些虚拟设备的总存储容量。</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/d6daba2b7adfe96daca62f9ed90bf0c4.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/d6daba2b7adfe96daca62f9ed90bf0c4.jpg" alt="5.jpg"></a></p><blockquote><p>下面看一下Docker 里ZFS的使用。首先从 zpool里分配一个ZFS 文件系统给镜像的基础层，而其他镜像层则是这个 ZFS 文件系统快照的克隆，快照是只读的，而克隆是可写的，当容器启动时则在镜像的顶层生成一个可写层。如下图所示：</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/34cc4c9ea6c96b6f83dabb961ed8950e.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/34cc4c9ea6c96b6f83dabb961ed8950e.jpg" alt="6.jpg"></a></p><blockquote><p>d当要写一个新文件时，使用按需分配，一个新的数据块从 zpool 里生成新的数据写入这个块，而这个新空间存于容器（ ZFS 的克隆 ）里。</p><p>当要修改一个已存在的文件时，使用写时复制，分配一个新空间并把原始数据复制到新空间完成修改。</p></blockquote><blockquote><p><strong>历史</strong>：ZFS的graphdriver是由Arthur Gautier和Jörg Thalheim一起在<a href="http://dockone.io/docker/docker#9411" target="_blank" rel="noopener">#9411</a>的PR中实现的，在<strong>2014年的5月</strong>被合并进了Docker引擎里面，并且从Docker 1.7版本开始用户可以使用。该实现依赖Go的一个三方包<a href="https://github.com/mistifyio/go-zfs" target="_blank" rel="noopener">go-zfs</a>进行相关zfs命令的交互。</p><p><strong>实现</strong>：与btrfs和devicemapper类似，要使用zfs驱动必需要有一个ZFS格式化的块设备挂载到graphdriver路径（默认是/var/lib/docker）。同时也需要安装好zfs工具（在绝大多数的发行版上是一个名为zfs-utils的包）供zfs Go库调用来执行相关操作。ZFS有能力创建快照（与btrfs类似），然后以快照的克隆作为分享层的途径（在ZFS的实现中成了一个快照）。因为ZFS不是一个基于文件的实现，aufs和overlay中所拥有的内存共享能力在ZFS是没有的。</p><p><strong>优点</strong>：ZFS正在受到越来越多的欢迎，在Ubuntu 16.04中，在Ubuntu的LXC/LXD中已经被使用。最初由Sun创建，ZFS已经存在很长的时间了，并且在Solaris和很多BSD的衍生版中使用，并且它的Linux移植版实现看起来也比较稳定，对于容器文件系统的场景也有足够合理性能。<code>ZFS</code>graphdriver也很及时的在Dockr 1.12中通过PR <a href="http://dockone.io/docker/docker#21946" target="_blank" rel="noopener">#21946</a>添加了配额的支持，这让它在配额支持方面和btrfs、devicemapper站在了同一起跑线上。</p><p><strong>缺点</strong>：除了没有基于文件（inode）的共享达到内库共享之外，很难说ZFS和其它同样基于块设备的实现相比有什么缺点。通过比较，ZFS看起来欢迎程度越来越高。对于那些完全支持或者正在使用ZFS的Linux发行版或者UNIX衍生版而言，zfs graphdriver可以是一个非常好的选择。</p><p><strong>总结</strong>：ZFS的支持为Docker引擎中稳定的graphdriver加了分。对于那些ZFS的使用者，或者那些ZFS扮演了更要角色的发行版来说，Docker能直接支持该文件系统，对这些社区来说是一个好消息。对于那些默认文件系统是ext4和xfs的发行版，默认采用overlay驱动的用户来说，时间会告诉我们他们是否会对zfs驱动产生更多的兴趣。</p></blockquote><h4 id="存储驱动的对比及适应场景"><a href="#存储驱动的对比及适应场景" class="headerlink" title="存储驱动的对比及适应场景"></a>存储驱动的对比及适应场景</h4><table><thead><tr><th><strong>存储驱动</strong></th><th><strong>特点</strong></th><th><strong>优点</strong></th><th><strong>缺点</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td>AUFS</td><td>联合文件系统、未并入内核主线、文件级存储</td><td>作为docker的第一个存储驱动，已经有很长的历史，比较稳定，且在大量的生产中实践过，有较强的社区支持</td><td>有多层，在做写时复制操作时，如果文件比较大且存在比较低的层，可能会慢一些</td><td>大并发但少IO的场景</td></tr><tr><td>overlayFS</td><td>联合文件系统、并入内核主线、文件级存储</td><td>只有两层</td><td>不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件消耗更多的时间</td><td>大并发但少IO的场景</td></tr><tr><td>Devicemapper</td><td>并入内核主线、块级存储</td><td>块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件</td><td>不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本，在很多容器启停的情况下可能会导致磁盘溢出</td><td>适合io密集的场景</td></tr><tr><td>Btrfs</td><td>并入linux内核、文件级存储</td><td>可以像devicemapper一样直接操作底层设备，支持动态添加设备</td><td>不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本</td><td>不适合在高密度容器的paas平台上使用</td></tr><tr><td>ZFS</td><td>把所有设备集中到一个存储池中来进行管理</td><td>支持多个容器共享一个缓存块，适合内存大的环境</td><td>COW使用碎片化问题更加严重，文件在硬盘上的物理地址会变的不再连续，顺序读会变的性能比较差</td><td>适合paas和高密度的场景</td></tr></tbody></table><p><a href="http://dockone.io/uploads/article/20190702/747be895d53add6ea9ddf868f95ff8ec.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/747be895d53add6ea9ddf868f95ff8ec.jpg" alt="7.jpg"></a></p><h5 id="AUFS-VS-Overlay"><a href="#AUFS-VS-Overlay" class="headerlink" title="AUFS VS  Overlay"></a>AUFS VS  Overlay</h5><blockquote><p>AUFS和Overlay都是联合文件系统，但AUFS有多层，而Overlay只有两层，所以在做写时复制操作时，如果文件比较大且存在比较低的层，则AUSF可能会慢一些。而且Overlay并入了linux kernel mainline，AUFS没有，所以可能会比AUFS快。但Overlay还太年轻，要谨慎在生产使用。而AUFS做为docker的第一个存储驱动，已经有很长的历史，比较的稳定，且在大量的生产中实践过，有较强的社区支持。目前开源的DC/OS指定使用Overlay。</p></blockquote><h5 id="Overlay-VS-Device-mapper"><a href="#Overlay-VS-Device-mapper" class="headerlink" title="Overlay VS Device mapper"></a>Overlay VS Device mapper</h5><blockquote><p>Overlay是文件级存储，Device mapper是块级存储，当文件特别大而修改的内容很小，Overlay不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件要消耗更多的时间，而块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件，在这种场景下，显然device mapper要快一些。因为块级的是直接访问逻辑盘，适合IO密集的场景。而对于程序内部复杂，大并发但少IO的场景，Overlay的性能相对要强一些。</p></blockquote><h5 id="Device-mapper-VS-Btrfs-Driver-VS-ZFS"><a href="#Device-mapper-VS-Btrfs-Driver-VS-ZFS" class="headerlink" title="Device mapper VS Btrfs Driver VS ZFS"></a>Device mapper VS Btrfs Driver VS ZFS</h5><blockquote><p>Device mapper和Btrfs都是直接对块操作，都不支持共享存储，表示当有多个容器读同一个文件时，需要生活多个复本，所以这种存储驱动不适合在高密度容器的PaaS平台上使用。而且在很多容器启停的情况下可能会导致磁盘溢出，造成主机不能工作。Device mapper不建议在生产使用。Btrfs在docker build可以很高效。<br>ZFS最初是为拥有大量内存的Salaris服务器设计的，所在在使用时对内存会有影响，适合内存大的环境。ZFS的COW使碎片化问题更加严重，对于顺序写生成的大文件，如果以后随机的对其中的一部分进行了更改，那么这个文件在硬盘上的物理地址就变得不再连续，未来的顺序读会变得性能比较差。ZFS支持多个容器共享一个缓存块，适合PaaS和高密度的用户场景。</p></blockquote><h4 id="IO性能对比"><a href="#IO性能对比" class="headerlink" title="IO性能对比"></a>IO性能对比</h4><blockquote><p>测试工具：IOzone（是一个文件系统的benchmark工具，可以测试不同的操作系统中文件系统的读写性能）<br>测试场景：从4K到1G文件的顺序和随机IO性能<br>测试方法：基于不同的存储驱动启动容器，在容器内安装IOzone，执行命令：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./iozone -a -n 4k -g 1g -i 0 -i 1 -i 2 -f /root/test.rar -Rb ./iozone.xls</span><br></pre></td></tr></table></figure><h5 id="测试项的定义和解释"><a href="#测试项的定义和解释" class="headerlink" title="测试项的定义和解释"></a>测试项的定义和解释</h5><blockquote><p>Write：测试向一个新文件写入的性能。<br>Re-write：测试向一个已存在的文件写入的性能。<br>Read：测试读一个已存在的文件的性能。<br>Re-Read：测试读一个最近读过的文件的性能。<br>Random Read：测试读一个文件中的随机偏移量的性能。<br>Random Write：测试写一个文件中的随机偏移量的性能。</p></blockquote><h5 id="测试数据对比"><a href="#测试数据对比" class="headerlink" title="测试数据对比"></a>测试数据对比</h5><blockquote><p>Write：</p><p><a href="http://dockone.io/uploads/article/20190702/f592fe0e47c24441541b3970f6775674.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/f592fe0e47c24441541b3970f6775674.jpg" alt="8.jpg"></a></p><p>Re-write:</p><p><a href="http://dockone.io/uploads/article/20190702/778f51a47542033e0ded1b1b1d0edd63.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/778f51a47542033e0ded1b1b1d0edd63.jpg" alt="9.jpg"></a></p><p>Read：</p><p><a href="http://dockone.io/uploads/article/20190702/3028c70ce9a0abcfa673459b199612a3.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/3028c70ce9a0abcfa673459b199612a3.jpg" alt="10.jpg"></a></p><p>Re-Read：</p><p><a href="http://dockone.io/uploads/article/20190702/fb9fe60305c941fbfbc564cb2351e588.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/fb9fe60305c941fbfbc564cb2351e588.jpg" alt="11.jpg"></a></p><p>Random Read：</p><p><a href="http://dockone.io/uploads/article/20190702/ef273f23ee51927344a224ef3798e75a.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/ef273f23ee51927344a224ef3798e75a.jpg" alt="12.jpg"></a></p><p>Random Write：</p><p><a href="http://dockone.io/uploads/article/20190702/3a07e8a8a9b4de99602d02dc849b771b.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/3a07e8a8a9b4de99602d02dc849b771b.jpg" alt="13.jpg"></a></p></blockquote><ul><li>通过以上的性能数据可以看到：<ul><li>AUFS在读的方面性能相比Overlay要差一些，但在写的方面性能比Overlay要好。</li><li>device mapper在512M以上文件的读写性能都非常的差，但在512M以下的文件读写性能都比较好。</li><li>btrfs在512M以上的文件读写性能都非常好，但在512M以下的文件读写性能相比其他的存储驱动都比较差。</li><li>ZFS整体的读写性能相比其他的存储驱动都要差一些。 简单的测试了一些数据，对测试出来的数据原理还需要进一步的解析。</li></ul></li></ul><blockquote><p><code>Docker</code> 提供了可插拔的存储驱动程序架构。它使我们能够灵活地 <code>插入</code> <code>Docker</code>中的存储驱动程序。他完全基于<code>Linux</code>文件系统 。</p></blockquote><blockquote><p>要实现这一功能，我们必须 在<code>docker</code> 守护进程的开始时就设置驱动程序。 <code>Docker</code> 守护程序只能运行一个存储驱动程序，并且该守护程序实例创建的所有容器使用相同的存储驱动程序。</p></blockquote><ul><li><p>当前存储驱动</p><ul><li>查看守护程序使用哪个存储驱动程序，可以使用一下命令。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker info</span><br></pre></td></tr></table></figure><blockquote><p>可以看到上面的命令显示了守护进程使用的存储驱动程序。备份文件系统 <code>extfs</code> 。 <code>extfs</code> 表示覆盖存储驱动程序在文件系统的顶部运行。</p><p>后备文件系统实质用于在 <code>/var/lib/docker</code> 录下创建 <code>Docker</code> 主机的本地存储区域的文件系统。</p></blockquote><ul><li><p>下表包含必须与主机备份文件系统相匹配的存储驱动程序。</p><table><thead><tr><th align="center">存储驱动</th><th align="center">常用</th><th align="center">已禁用</th></tr></thead><tbody><tr><td align="center">overlay</td><td align="center">ext4xfs</td><td align="center">btrfs  aufs  overlayzfs  eCryptfs</td></tr><tr><td align="center">overlay2</td><td align="center">ext4xfs</td><td align="center">btrfs  aufs  overlayzfs  eCryptfs</td></tr><tr><td align="center">aufs</td><td align="center">ext4xfs</td><td align="center">btrfs  aufs  eCryptfs</td></tr><tr><td align="center">aufs</td><td align="center">btrfsonly</td><td align="center">N/A</td></tr><tr><td align="center">devicemapper</td><td align="center">Direct-lvm</td><td align="center">N/A</td></tr><tr><td align="center">vfs</td><td align="center">debugging only</td><td align="center">N/A</td></tr><tr><td align="center"></td><td align="center"></td><td align="center">N/A</td></tr></tbody></table></li></ul><blockquote><p>注意 ：- “已禁用/Disabled on” 表示某些存储驱动程序无法在某些后台文件系统上运行</p></blockquote></li></ul><h4 id="设置存储驱动程序"><a href="#设置存储驱动程序" class="headerlink" title="设置存储驱动程序"></a>设置存储驱动程序</h4><blockquote><p>可以通过 <code>dockersd</code>命令按指定名称来设置存储驱动程序。以下命令启动守护程序并设置新的驱动程序。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ dockerd --storage-driver=devicemapper</span><br></pre></td></tr></table></figure><blockquote><p>稍后，可以通过 <code>docker info</code> 命令检查 <code>docker</code> 服务驱动程序</p></blockquote><hr><p><strong>对于某些容器，直接将数据放在由</strong> storage driver <strong>维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 如一些工具箱，启动是为了执行命令，不需要保存数据供以后使用，使用完直接退出，容器删除时存在容器层的工作数据也一起删除，这没问题，下次启动新容器即可。</span><br><span class="line"></span><br><span class="line"># 但对于另一类应用这种方式就不合适了，它们有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的，例如数据库。</span><br><span class="line">这就要用到docker 的另一个存储机制：data volume</span><br></pre></td></tr></table></figure><h3 id="Data-Volume（数据卷）"><a href="#Data-Volume（数据卷）" class="headerlink" title="Data Volume（数据卷）"></a>Data Volume（数据卷）</h3><hr><blockquote><p>对于有些容器，我们可能会持久化数据的需求，也就是容器启动时需要加载已有的数据，容器销毁时希望保留产生的数据，也就是说这类容器是有状态的。</p><p>这就需要用到 <code>Docker</code> 的 <code>Data Volume</code> 存储机制。<code>Data Volume</code>本质上是 <code>Docker host</code>文件系统中的目录或文件，能够直接被 <code>mount</code> 到容器的文件系统。</p><p>在具体的使用上，<code>Docekr</code> 提供了两种类型的Volume：bind mount 和docker managed volume。</p></blockquote><h5 id="附：bind-mount-与-docker-managed-volume-的区别"><a href="#附：bind-mount-与-docker-managed-volume-的区别" class="headerlink" title="附：bind mount 与 docker managed volume 的区别"></a>附：bind mount 与 docker managed volume 的区别</h5><ul><li>这两种 <strong>data volume</strong> 实际上都是使用 <strong>host</strong> 文件系统的中的某个路径作为 <strong>mount</strong> 源。它们不同之处在于：</li></ul><table><thead><tr><th><strong>不同点</strong></th><th><strong>bind mount</strong></th><th><strong>docker managed volume</strong></th></tr></thead><tbody><tr><td><strong>volume 位置</strong></td><td>可任意指定</td><td><strong>/var/lib/docker/volumes/…</strong></td></tr><tr><td><strong>对已有mount point 影响</strong></td><td>隐藏并替换为 <strong>volume</strong></td><td>原有数据复制到 <strong>volume</strong></td></tr><tr><td><strong>是否支持单个文件</strong></td><td>支持</td><td>不支持，只能是目录</td></tr><tr><td><strong>权限控制</strong></td><td>可设置为只读，默认为读写权限</td><td>无控制，均为读写权限</td></tr><tr><td><strong>移植性</strong></td><td>移植性弱，与 <strong>host path</strong> 绑定</td><td>移植性强，无需指定 <strong>host</strong> 目录</td></tr></tbody></table><h5 id="什么是数据卷"><a href="#什么是数据卷" class="headerlink" title="什么是数据卷"></a>什么是数据卷</h5><ul><li><p>Data Volume 数据卷 ：是可以存放在一个或多个容器内的 <strong>特定的目录</strong>，提供独立于容器之外的<strong>持久化存储</strong>；是经过<strong>特殊设计的目录</strong>，可以绕过联合文件系统（UFS），为一个或多个容器提供访问；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Docker Contrainer</span><br><span class="line">面向对象中的对象</span><br><span class="line"></span><br><span class="line">对象一旦被销毁，数据就不存在了</span><br><span class="line"></span><br><span class="line">容器一旦被销毁，则容器内的数据将一并被删除</span><br><span class="line"></span><br><span class="line">服务器中的图案也会一并销毁</span><br><span class="line"></span><br><span class="line">容器中的数据不是持久化状态的</span><br></pre></td></tr></table></figure><blockquote><p>不使用 <code>volume</code>的时候，对容器进行的改动是不会被保存的，使用 <code>volume</code>可以实现持久化存储；比如运行一个数据的操作，数据库的一个容器，数据库的数据应该被持久化存储的，<code>volume</code>就可以实现这个，并且 <code>volume</code>可以提供容器与容器之间的共享数据；</p></blockquote></li></ul><h5 id="Docker-的理念之一："><a href="#Docker-的理念之一：" class="headerlink" title="Docker 的理念之一："></a>Docker 的理念之一：</h5><blockquote><p>就是将其应用于其运行的环境打包，因此，通过<code>Docker</code> 容器的生存周期，都是与容器中运行的程序相一致的，而我们对数据的要求通常是持久化的；另一方面，<code>docker</code>容器之间也需要有一个 <strong>共享数据的渠道</strong> ，而这些需求就催生出了<code>docker</code>数据卷的产生；</p></blockquote><h5 id="数据卷的设计的目的："><a href="#数据卷的设计的目的：" class="headerlink" title="数据卷的设计的目的："></a>数据卷的设计的目的：</h5><blockquote><p>在于 <strong>数据的永久化</strong> ，它完全独立于容器的生存周期，因此，<code>Docekr</code>不会在容器删除时删除其挂载的数据卷，也不会存在类似垃圾收集机制，对容器引用的数据卷进行处理了；</p></blockquote><h5 id="数据卷特点："><a href="#数据卷特点：" class="headerlink" title="数据卷特点："></a>数据卷特点：</h5><ul><li><ol><li><code>Docker</code>数据卷是独立于<code>Docker</code>的存在，它存在于<code>Docker host</code>（宿主机）中，因此，它与容器的生存周期是分离的；</li><li><code>Docker</code>数据卷本质上是存在于<code>Docker</code>宿主机的本地文件系统中；</li><li><code>Docker</code> 数据卷可以是目录也可以是文件；（不是块设备）</li><li><code>Docker</code> 容器可以利用数据卷的技术与容器宿主机进行数据共享；</li><li>同一个目录或者文件，可以支持多个容器进行访问，这样其实实现了容器的数据共享和交换；</li><li>数据卷是在容器启动是进行初始化的，那么如果容器使用的镜像包含了的数据也会在容器启动时拷贝到容器的数据卷中；</li><li><code>数据卷可以在容器之间共享和重用</code>；</li><li><code>数据卷的修改会立马生效</code>；容器可以对数据卷里的内容直接修改；容器对数据卷进行的修改是及时的，所有的修改都会直接体现在数据卷中；</li><li><code>数据卷的更新不会影响镜像</code>；因为文件不会写到镜像中去，数据卷是独立于联合文件系统的，而镜像本身基于联合文件系统，so镜像与数据卷之间不会有相互影响的情况；</li><li><code>数据卷会一直存在，即使挂载数据卷的容器已经删除</code>因为数据均本质上是宿主机上的一个目录，同时为了提供数据的永久化，它的生存周期与容器是完全隔离的；</li></ol><p><img src="https://img-blog.csdnimg.cn/20190617160156293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQ2ODkx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li></ul><blockquote><p>Docker 容器中的数据操作经过了UFS 的，UFS 会在宿主机中写一次文件，这个文件在宿主机上是临时的，这时候就出现了重复写的情况，会影响系统的性能；此外，删除容器的时候，就没有人能够通过UFS 在访问到宿主机中的文件了；</p></blockquote><p><img src="https://img-blog.csdnimg.cn/20190617160937555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQ2ODkx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><blockquote><p>容器卷可以绕过 UFS 直接操作主机上的文件，当容器删除的时候，宿主机上的文件还在，就在指定的目录下，在重新创建容器的时候们可以指定容器继续读取宿主机上的文件；</p></blockquote><p><img src="https://img-blog.csdnimg.cn/20190617161045446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQ2ODkx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h5 id="创建一个数据卷"><a href="#创建一个数据卷" class="headerlink" title="创建一个数据卷"></a>创建一个数据卷</h5><blockquote><p>包含数据卷挂载的容器在容器关闭时，如果修改了宿主机下的数据卷会，容器里面会产生改变吗？ </p></blockquote><ul><li><strong>bind mount 数据卷</strong></li></ul><blockquote><p>使用docker run –name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx  创建一个bind mount 数据卷 是宿主机的存储位置必须是绝对路径。目录不存在则会生成</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 以下两种情况创建的数据卷如果浏览器访问宿主机的ip:8080 会出现报错，因为这是创建的时候清空了容器数据卷下index.html</span><br><span class="line"># 创建的宿主机和容器的数据卷都有读写的权限</span><br><span class="line">$ docker run --name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx</span><br><span class="line"># 这样执行后的文件宿主机的~/myvolume 文件如果不存在直接创建，容器的文件路径不存在也会直接创建，如果/usr/share/nginx/html文件存在里面内容会清空</span><br><span class="line"></span><br><span class="line"># 给容器里面的数据卷加权限</span><br><span class="line">$ docker run --name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html:ro nginx</span><br><span class="line"># 如果执行这个 :/usr/share/nginx/html:ro这个地方加的是 :ro 是设置的只有读取权限</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 运行dockers inspect 容器名称或容器（ID） 是将容器的配置文件已json字符串的形式返回</span><br><span class="line">&quot;Binds&quot;: [</span><br><span class="line">                &quot;/root/myvolume:/usr/share/nginx/html&quot;   # 宿主机数据卷位置: 容器的目录位置</span><br><span class="line">            ],</span><br><span class="line"></span><br><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/root/myvolume&quot;,   # 是宿主机数据卷的存储位置</span><br><span class="line">                &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,   # 权限 true是可以读写 fales 是只读</span><br><span class="line">                &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 在宿主机的数据卷下执行:</span><br><span class="line">vim index.html </span><br><span class="line"># 在文件里写入hello ， 你在访问的时候就可以在页面上看到你写入得数据了</span><br></pre></td></tr></table></figure><blockquote><p>执行 docker exec -it 容器名称（容器ID） bahs进入到容器里面，每个容器都会包含一个迷你版的linux系统</p><p>执行 cd /usr/share/nginx/html  </p><p>执行 ls</p><p>你会看到容器目录里会有我们刚才创建好的文件</p><p>index.html</p><p>执行 cat index.html  可以看到里面我们加入的数据</p><p>如果是挂载数据卷的时候加 <code>:ro</code> 容器内修改文件，发现会提示该文件是只读的  </p></blockquote><hr><ul><li><strong>docker managed volume 数据卷</strong><ul><li>创建出来的两个都是有读写权限的</li></ul></li></ul><blockquote><p>使用docker run –name nginx-test2 -p 8080:80 -d -v /usr/share/nginx/html nginx 创建一个<strong>docker managed volume 数据卷</strong> </p><p>这种命令创建是不用指定宿主机数据卷存储位置的默认在 /var/lib/docker/volumes/ 下的文件名是经过<code>sha256</code> 摘要过的</p></blockquote><ul><li>查看宿主机创建出来的数据卷</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd  /var/lib/docker/volumes/</span><br><span class="line">$ ls </span><br><span class="line">8d668720aaeccee44b5fb554571912a6a257eb3a28cecf334203805a0c9b6fd3  #这是自己创建出来的数据卷</span><br><span class="line"># 执行 cd _data 进入这这个文件夹里面</span><br><span class="line">$ ls</span><br><span class="line">50x.html  index.html   # 这两个文件是把容器里文件给拷贝了出来</span><br></pre></td></tr></table></figure><blockquote><p>可以在宿主机或者容器里面都可以对文件进行读写操作</p></blockquote><h5 id="挂载多个目录实现数据卷的"><a href="#挂载多个目录实现数据卷的" class="headerlink" title="挂载多个目录实现数据卷的"></a>挂载多个目录实现数据卷的</h5><ul><li>就是执行多个 <code>-v</code> 就可以</li></ul><h5 id="容器间的数据共享"><a href="#容器间的数据共享" class="headerlink" title="容器间的数据共享"></a>容器间的数据共享</h5><ul><li>数据卷容器挂载了一个本地文件系统的目录，其它容器通过挂载这个数据卷容器来实现容器间的数据的共享；</li></ul><p><img src="https://img-blog.csdn.net/20180524134945342?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQ2ODkx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><h5 id="容器间挂载"><a href="#容器间挂载" class="headerlink" title="容器间挂载"></a>容器间挂载</h5><blockquote><p>创建数据卷，只要在<code>docker run</code>命令后面跟上<code>-v</code>参数即可创建一个数据卷，当然也可以跟多个<code>-v</code>参数来创建多个数据卷，当创建好带有数据卷的容器后，就可以在其他容器中通过<code>--volumes-from</code>参数来挂载该数据卷了，而不管该容器是否运行。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -tid --rm --volumes-from nginx-test --name nginx-test3 nginx</span><br></pre></td></tr></table></figure><blockquote><p>-i  : 以交互模式运行容器，通常与 -t 同时使用；</p><p>-t  : 为容器重新分配一个伪输入终端，通常与 -i 同时使用；</p><p>-d : 后台运行容器，并返回容器ID；</p></blockquote><ul><li>再创建一个nginx-test4，挂载nginx-test3中从nginx-test挂载的数据卷，当然也可以直接挂载初识的nginx-test容器的数据卷</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* 即使删除了初始的数据卷容器 nginx-test，或者是删除了其他容器，但只要是有容器在使用该数据卷，那么它里面的数据就不会丢失</span><br><span class="line">* 命令中的rm表示当容器退出即停止的时候，会自动删除该容器</span><br></pre></td></tr></table></figure><hr><h5 id="备份数据卷"><a href="#备份数据卷" class="headerlink" title="备份数据卷"></a>备份数据卷</h5><ul><li>创建一个容器container1，包含两个数据卷/usr/share/nginx/html1和/usr/share/nginx/html2（这两个目录是在容器里的数据卷路径）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container1 -p 8080:80 nginx</span><br><span class="line"># 创建容器container1</span><br><span class="line"></span><br><span class="line">$ docker exec -it container1 bash   #进入创建好的容器里面</span><br><span class="line"></span><br><span class="line">$ cd html1/  # 进入到html1数据卷中</span><br><span class="line">$ echo html1 &gt;&gt; 1.text # 向 1.text 文件中追加数据，文件不存在则会创建文件</span><br><span class="line"></span><br><span class="line">$ cd html2/  # 进入到html2数据卷中</span><br><span class="line">$ echo html2 &gt;&gt; 2.text # 向 2.text 文件中追加数据，文件不存在则会创建文件</span><br></pre></td></tr></table></figure><ul><li>接下来进行数据卷的备份操作</li></ul><blockquote><p>使用  - -volumes-from 来创建一个加载 container1 容器卷的容器，并从宿主机挂载当前所在目录到容器的 /backup 目录，容器内会 tar 压缩 /var/colume1 目录下的文件到 /backup/backup1.tar，因为宿主机当前目录已经映射到 /backup 目录了，因此会在宿主机当前目录也存在该压缩包。备份完毕后 -rm 自动删除该创建的容器。</p></blockquote><ul><li>备份container1容器中的/usr/share/nginx/html1数据卷数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 备份container1容器中的/usr/share/nginx/html1数据卷数据</span><br><span class="line"># -tid 这个参数加不加都可以</span><br><span class="line"># --rm 加上，备份后就会自动删除这个容器，如果不加这个 --rm 参数，name备份后的容器就会保留，docker ps -a就会查看到）</span><br><span class="line"># $(pwd) </span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup1.tar /usr/share/nginx/html1</span><br><span class="line">b3663a3bdd302a38036d6a156471cd448c8e5b9333a20f9480b3c61cbd9270df</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# ls</span><br><span class="line">backup1.tar</span><br></pre></td></tr></table></figure><blockquote><ul><li>–volumes-from [containerName]：这个命令来指定需要备份的容器的名字；（数据卷容器的名字）</li><li>-v $(pwd):/backup:权限：使用-v命令来指定希望备份文件存放的位置；本地存放目录：容器存放目录：读写权限；（默认权限是读写）</li><li>tar cvf /backup/backup.tar [container data volume]：tar表示执行备份的操作是：压缩文件的命令；</li><li>/backup/backup.tar是文件存放的地址， [container data volume]指定需要备份的目录；</li><li>tar cvf 压缩；tar xvf解压缩；</li></ul></blockquote><ul><li>备份container1容器中的/usr/share/nginx/html2数据卷数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 备份container1容器中的/usr/share/nginx/html2数据卷数据</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup2.tar /usr/share/nginx/html2</span><br><span class="line">001129bc393d5d0ed4665d053d4ca7972584cf2bd56980064be182ec758138cd</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# ll</span><br><span class="line">total 22464</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 18:52 backup1.tar  # 文件1</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 19:05 backup2.tar  # 文件2</span><br><span class="line">drwxr-xr-x 2 root root     4096 Dec 16 16:45 myvolume</span><br><span class="line">-rw-r--r-- 1 root root 22973527 Mar 26  2019 Python-3.7.3.tgz</span><br></pre></td></tr></table></figure><ul><li>备份container1 容器中的 /usr/share/nginx/html1 和 /usr/share/nginx/html2 数据卷数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#  备份container1 容器中的 /usr/share/nginx/html2 和 /usr/share/nginx/html2 数据卷数据</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup.tar /usr/share/nginx/html1 /usr/share/nginx/html2</span><br><span class="line">441df929e123cbe51564ca3d6bf3f06a5ea415298a34bb9871f1ed2b68a60102</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# ll</span><br><span class="line">total 22476</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 18:52 backup1.tar</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 19:05 backup2.tar</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 19:09 backup.tar</span><br><span class="line">drwxr-xr-x 2 root root     4096 Dec 16 16:45 myvolume</span><br><span class="line">-rw-r--r-- 1 root root 22973527 Mar 26  2019 Python-3.7.3.tgz</span><br></pre></td></tr></table></figure><h5 id="恢复数据给同一个容器"><a href="#恢复数据给同一个容器" class="headerlink" title="恢复数据给同一个容器"></a>恢复数据给同一个容器</h5><blockquote><p>之前的数据卷是从 container1 中备份的，现在模拟 container1 数据卷丢失，然后直接用之前备份的 backup.tar 进行恢复</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"># 为了测试恢复，先删除容器里原先的数据（注意：数据卷目录不能删除，只能删除其中的数据）</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container1 bash </span><br><span class="line">#进入到创建的容器里</span><br><span class="line">root@6869560e6ff5:/# ls</span><br><span class="line">bin  boot  devetc  home  liblib64  media  mnt  optproc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line">root@6869560e6ff5:/# cd /usr/share/nginx  </span><br><span class="line">#进入到容器里面的数据卷所在的目录</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# ls</span><br><span class="line">html  html1  html2  </span><br><span class="line"></span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# cd html1</span><br><span class="line"># 进入到 html1 数据卷目录</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx/html1# ls</span><br><span class="line">1.text</span><br><span class="line"></span><br><span class="line">root@6869560e6ff5:/usr/share/nginx/html1# rm -rf 1.text </span><br><span class="line"># 删除 1.text 文件</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx/html1# ls</span><br><span class="line"></span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# cd html2</span><br><span class="line"># 进入到 html2 的数据卷目录</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx/html2# ls</span><br><span class="line">2.text</span><br><span class="line"></span><br><span class="line">root@6869560e6ff5:/usr/share/nginx/html2# rm -rf 2.text </span><br><span class="line"># 删除 2.text 文件</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx/html2# ls</span><br><span class="line"></span><br><span class="line"># 进行数据卷恢复，恢复数据卷中的所有数据</span><br><span class="line">注意-C后面的路径，表示将数据恢复到容器里的路径直接使用压缩包中文件的各个路径。比如压缩包中的结果如下：</span><br><span class="line">tar -xvf backup.tar   #解压压缩文件</span><br><span class="line"></span><br><span class="line"># 数据1</span><br><span class="line">usr/share/nginx/html1/1.text</span><br><span class="line">--usr</span><br><span class="line">--share</span><br><span class="line">--nginx</span><br><span class="line">--html1</span><br><span class="line">--1.text</span><br><span class="line"># 数据2</span><br><span class="line">usr/share/nginx/html2/2.text</span><br><span class="line">--usr</span><br><span class="line">--share</span><br><span class="line">--nginx</span><br><span class="line">--html2</span><br><span class="line">--2.text</span><br><span class="line"># 直接将文件解压到 /usr/share/nginx/html1 和 /usr/share/nginx/html2 目录</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker run --rm --volumes-from container1 -v $(pwd):/backup nginx tar xvf /backup/backup.tar -C /</span><br><span class="line">usr/share/nginx/html1/</span><br><span class="line">usr/share/nginx/html1/1.text</span><br><span class="line">usr/share/nginx/html2/</span><br><span class="line">usr/share/nginx/html2/2.text</span><br><span class="line"></span><br><span class="line"># 直接进入容器查看</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container1 bash</span><br><span class="line">root@6869560e6ff5:/# cd /usr/share/nginx/ </span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# ls</span><br><span class="line">html  html1  html2</span><br><span class="line"># 查看数据是否存在</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# ls html1</span><br><span class="line">1.text</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# ls html2</span><br><span class="line">2.text</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# cat html1/1.text </span><br><span class="line">html1</span><br><span class="line">root@6869560e6ff5:/usr/share/nginx# cat html2/2.text </span><br><span class="line">html2</span><br></pre></td></tr></table></figure><h5 id="恢复数据给新的容器"><a href="#恢复数据给新的容器" class="headerlink" title="恢复数据给新的容器"></a>恢复数据给新的容器</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 新建一个容器container2</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container2 nginx</span><br><span class="line">89abb55858fb1e3dddc07c2066d05614349aaf78ba446a1ea12f1241b98e4896</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line">89abb55858fb        nginx               &quot;/bin/bash&quot;         9 seconds ago       Up 8 seconds        80/tcp              container2</span><br><span class="line">6869560e6ff5        nginx               &quot;/bin/bash&quot;         2 hours ago         Up 2 hours          80/tcp              container1</span><br><span class="line"></span><br><span class="line"># 开始恢复数据</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# ll</span><br><span class="line">total 22476</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 18:52 backup1.tar</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 19:05 backup2.tar</span><br><span class="line">-rw-r--r-- 1 root root    10240 Dec 16 19:09 backup.tar</span><br><span class="line">drwxr-xr-x 2 root root     4096 Dec 16 16:45 myvolume</span><br><span class="line">-rw-r--r-- 1 root root 22973527 Mar 26  2019 Python-3.7.3.tgz</span><br><span class="line"></span><br><span class="line"># 恢复数据</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker run --rm --volumes-from container2 -v $(pwd):/backup nginx tar xvf /backup/backup.tar -C /</span><br><span class="line">usr/share/nginx/html1/</span><br><span class="line">usr/share/nginx/html1/1.text</span><br><span class="line">usr/share/nginx/html2/</span><br><span class="line">usr/share/nginx/html2/2.text</span><br><span class="line"></span><br><span class="line"># 查看确实已经恢复了</span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container2 bash</span><br><span class="line">root@89abb55858fb:/# ls /usr/share/nginx/</span><br><span class="line">html  html1  html2</span><br><span class="line">root@89abb55858fb:/# ls /usr/share/nginx/html1</span><br><span class="line">1.text</span><br><span class="line">root@89abb55858fb:/# ls /usr/share/nginx/html2</span><br><span class="line">2.text</span><br><span class="line">root@89abb55858fb:/# cat /usr/share/nginx/html1/1.text </span><br><span class="line">html1</span><br><span class="line">root@89abb55858fb:/# cat /usr/share/nginx/html2/2.text </span><br><span class="line">html2</span><br></pre></td></tr></table></figure><blockquote><p>注意：</p><ul><li><p>–volumes-from [containerName]：这个命令来指定需要备份的容器的名字；（数据卷容器的名字）</p></li><li><p>-v $(pwd):/backup:权限：使用-v命令来指定希望备份文件存放的位置；本地存放目录：容器存放目录：读写权限；（默认权限是读写）</p></li><li><p>tar cvf /backup/backup.tar [container data volume]：tar表示执行备份的操作是：压缩文件的命令；</p></li><li><p>/backup/backup.tar是文件存放的地址， [container data volume]指定需要备份的目录；</p></li><li><p>tar cvf 压缩；tar xvf解压缩；</p></li><li><p>新容器创建时挂载的数据卷路径最好和之前备份的数据卷路径一致</p></li><li><p>新容器创建时，如果挂载的数据卷只是备份卷的一部分，那么恢复的时候也只是恢复一部分数据。</p></li><li><p>比如新建容器挂载数据卷为 <code>-v /usr/share/nginx/html1</code> ,那么使用 <code>backup.tar</code> 恢复时，只会恢复 <code>/usr/share/nginx/html1</code> 的数据， <code>/usr/share/nginx/html2</code> 的数据是不会恢复的</p></li><li><p>比如新容器创建时挂载的数据卷目录和备份的数据卷目录不一致，那么数据恢复不了，除非修改 - C 后面的路径，比如新建容器时指定数据卷目录为 <code>/usr/share/nginx/html</code> ，恢复时也是用 <code>-C /usr/share/nginx/html</code>，则是可以成功恢复的</p></li></ul></blockquote><h5 id="删除数据卷"><a href="#删除数据卷" class="headerlink" title="删除数据卷"></a>删除数据卷</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker volume ls     列出所有的数据卷</span><br><span class="line">docker volume ls --filter dangling=true     过滤不在使用的数据卷</span><br><span class="line">docker volume rm [volume name]     删除一个数据卷，容器正在使用的数据卷不能删除，绑定挂载的数据卷无法删除</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume rm my-volio  删除数据卷 my-volio</span><br></pre></td></tr></table></figure><blockquote><p>数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。</p></blockquote><ul><li>无主的数据卷可能会占据很多空间，要清理请使用以下命令</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume prune</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手动定义一个全局中间件</title>
      <link href="/2060/07/18/%E6%89%8B%E5%8A%A8%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%85%A8%E5%B1%80%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
      <url>/2060/07/18/%E6%89%8B%E5%8A%A8%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%85%A8%E5%B1%80%E4%B8%AD%E9%97%B4%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="手动定义一个全局中间件"><a href="#手动定义一个全局中间件" class="headerlink" title="手动定义一个全局中间件"></a>手动定义一个全局中间件</h3><blockquote><p>创建一个 middlerware.py（名字可以自己定义一个） 的文件</p></blockquote><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># 导入 MiddlewareMixin</span><br><span class="line"># 没有这个模块就下载一个</span><br><span class="line">from django.utils.deprecation import MiddlewareMixin</span><br><span class="line"># 导入</span><br><span class="line">from django.shortcuts import reverse</span><br><span class="line">from django.http import JsonResponse</span><br><span class="line">import time</span><br><span class="line">from .views import decrypt_oralce</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">LOGIN_REQUIRE_LIST = [reverse(var) for var in []] # 定义一个全局监控的路由列表，表里添加路由名</span><br><span class="line"># LoginRequired 函数名需要到 settings.py 里面进行配置,如下</span><br><span class="line"># 列表里面放的是需要登录判断的路由</span><br><span class="line">LOGIN_REQUIRE_LIST = [reverse(var) for var in []]</span><br><span class="line">class LoginRequired(MiddlewareMixin):</span><br><span class="line">    def process_request(self,request):</span><br><span class="line">        # 重定义请求来临需要做的事情</span><br><span class="line">        # 判断请求是否需要登录</span><br><span class="line">        # request.path()  # 返回当前用户访问的路径</span><br><span class="line">        # print(request.META[&apos;HTTP_AUTHORIZATION&apos;])</span><br><span class="line">        if request.path in LOGIN_REQUIRE_LIST:</span><br><span class="line">            token = request.META.get(&apos;HTTP_AUTHORIZATION&apos;) </span><br><span class="line">            if not token or token == &apos;null&apos;:</span><br><span class="line">                return JsonResponse(&#123;</span><br><span class="line">                    &apos;code&apos;:6207,</span><br><span class="line">                    &apos;message&apos;:&apos;未认证登录&apos;</span><br><span class="line">                &#125;)</span><br><span class="line">            else:</span><br><span class="line">                # 逆向解析</span><br><span class="line">                token_data = json.loads(decrypt_oralce(token))</span><br><span class="line">                user_id = token_data.get(&apos;id&apos;)</span><br><span class="line">                if token_data[&apos;expire&apos;] &lt; time.time():</span><br><span class="line">                    # token 过期</span><br><span class="line">                    return JsonResponse(&#123;</span><br><span class="line">                        &apos;code&apos;:7001,</span><br><span class="line">                        &apos;message&apos;:&apos;登陆时间已过期&apos;</span><br><span class="line">                    &#125;)</span><br><span class="line">                data = request.POST.copy()</span><br><span class="line">                data[&apos;id&apos;] = user_id</span><br><span class="line">                request.POST = data</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># settings.py配置</span><br><span class="line">MIDDLEWARE = [</span><br><span class="line">    &apos;django.middleware.security.SecurityMiddleware&apos;,</span><br><span class="line">    &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;,</span><br><span class="line">    &apos;corsheaders.middleware.CorsMiddleware&apos;,</span><br><span class="line">    &apos;django.middleware.common.CommonMiddleware&apos;,</span><br><span class="line">    # &apos;django.middleware.csrf.CsrfViewMiddleware&apos;,</span><br><span class="line">    &apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;,</span><br><span class="line">    &apos;django.contrib.messages.middleware.MessageMiddleware&apos;,</span><br><span class="line">    &apos;django.middleware.clickjacking.XFrameOptionsMiddleware&apos;,</span><br><span class="line">    &apos;peng.middlerware.LoginRequired&apos;,  # LoginRequired -&gt; 这个名字就是你在 middlerware.py里面的函数名 加一行这个注册一下</span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>views.py  里面</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"># 密码加密</span><br><span class="line">import hashlib</span><br><span class="line">from django.contrib.auth.hashers import make_password,check_password</span><br><span class="line"></span><br><span class="line"># 全局中间件</span><br><span class="line">import itsdangerous</span><br><span class="line">from shiyanpro.settings import SECRET_KEY</span><br><span class="line"></span><br><span class="line"># AES 加密算法容器</span><br><span class="line">from Crypto.Cipher import AES</span><br><span class="line">import base64</span><br><span class="line">import json</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># Create your views here.</span><br><span class="line"></span><br><span class="line"># 定义memcache连接对象 </span><br><span class="line">mem = memcache.Client([&apos;47.96.189.157&apos;])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BLOCK_SIZEE = 16</span><br><span class="line">AES_KEY = &apos;wxpeng&apos;   # key 值一定是16、32等</span><br><span class="line">EXPIRE = 3000</span><br><span class="line">def add_16(value):</span><br><span class="line">    while len(value) % 16 != 0:</span><br><span class="line">        value += &apos;\0&apos;</span><br><span class="line">    return str.encode(value) </span><br><span class="line"></span><br><span class="line">def add_32(value):</span><br><span class="line">    while len(value) % 32 != 0:</span><br><span class="line">        value += &apos;\0&apos;</span><br><span class="line">    return str.encode(value)</span><br><span class="line"></span><br><span class="line"># ECB 加密</span><br><span class="line">def encrypt_oracle(text):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        text的格式：</span><br><span class="line">        text:&#123;&apos;name&apos;:&apos;zhangsan,&apos;id&apos;:3&#125;</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    aes = AES.new(add_32(AES_KEY),AES.MODE_ECB)</span><br><span class="line">    encrypt_value = aes.encrypt(add_16(text)) # text --&gt;  需要加密的东西</span><br><span class="line">                                              # ECB 模式加密，内容必须是‘进制流’</span><br><span class="line">    encrypt_text = str(base64.encodebytes(encrypt_value),encoding=&apos;utf-8&apos;)</span><br><span class="line">    print(encrypt_text)</span><br><span class="line">    return encrypt_text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ECB 解密</span><br><span class="line">def decrypt_oralce(text):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        text的格式：</span><br><span class="line">        text:&#123;&apos;name&apos;:&apos;zhangsan,&apos;id&apos;:3&#125;</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    aes = AES.new(add_32(AES_KEY),AES.MODE_ECB)</span><br><span class="line">    base64_decrypted = base64.decodebytes(text.encode(encoding=&apos;utf-8&apos;))</span><br><span class="line">    decrypted_text = str(aes.decrypt(base64_decrypted),encoding=&apos;utf-8&apos;).replace(&apos;\0&apos;,&apos;&apos;)</span><br><span class="line">    return decrypted_text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 生成token函数</span><br><span class="line">def jwt_itsdangerous_token(user):</span><br><span class="line">    jwt_ = itsdangerous.TimedJSONWebSignatureSerializer(SECRET_KEY,300)  </span><br><span class="line">    data = &#123;</span><br><span class="line">                &apos;id&apos;:user.id,</span><br><span class="line">            &#125;</span><br><span class="line">    token = jwt_.dumps(data).decode()</span><br><span class="line">    return token</span><br><span class="line"></span><br><span class="line"># 定义密码加密函数</span><br><span class="line">def get_pass(str_):</span><br><span class="line">    s = hashlib.sha1()</span><br><span class="line">    s.update(str_.encode())</span><br><span class="line">    return s.hexdigest()</span><br><span class="line"></span><br><span class="line"># 在登录接口中，账号密码验证成功的情况下，写入如下代码，</span><br><span class="line">data = &#123;</span><br><span class="line">                &apos;id&apos;:user.id,</span><br><span class="line">                &apos;expire&apos;:time.time() + EXPIRE # token 过期时间</span><br><span class="line">            &#125;</span><br><span class="line">            token = encrypt_oracle(json.dumps(data))</span><br><span class="line">            return JsonResponse(&#123;</span><br><span class="line">                &apos;code&apos;:1,</span><br><span class="line">                &apos;message&apos;:&apos;登录成功&apos;,</span><br><span class="line">                &apos;token&apos;:token</span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure><blockquote><p>前端判断返回的 code 是否是 6027 或 7001 就OK</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker（2）</title>
      <link href="/2056/02/12/Docker%E6%A6%82%E5%BF%B5/"/>
      <url>/2056/02/12/Docker%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是Docker"><a href="#什么是Docker" class="headerlink" title="什么是Docker"></a>什么是Docker</h1><p>Docker 是一个开源的应用容器引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在本地编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。</p><a id="more"></a><p>简单的理解，Docker类似于集装箱，各式各样的货物，经过集装箱的标准化进行托管，而集装箱和集装箱之间没有影响。也就是说，Docker平台就是一个软件集装箱化平台，这就意味着我们自己可以构建应用程序，将其依赖关系一起打包到一个容器中，然后这容器就很容易运送到其他的机  器上进行运行，而且非常易于装载、复制、移除，非常适合软件弹性架构。 </p><p>因此，就像船只、火车或卡车运输集装箱而不论其内部的货物一样，软件容器充当软件部署的标准单元，其中可以包含不同的代码和依赖项。 按照这种方式容器化软件，开发人员和 IT 专业人员只需进行极少修改或不修改，即可将其部署到不同的环境。</p><p>总而 言之，Docker 是一个开放平台，使开发人员和管理员可以在称为容器的松散隔离的环境中构建镜像、交付和运行分布式应用程序。以便在开发、QA 和生产环境之间进行高效的应用程序生命周期管理。</p><h1 id="Docker能解决什么问题"><a href="#Docker能解决什么问题" class="headerlink" title="Docker能解决什么问题"></a>Docker能解决什么问题</h1><p>高效有序利用资源</p><ul><li>机器资源有限；</li><li>单台机器得部署多个应用；</li><li>应用之间互相隔离；</li><li>应用之间不能发生资源抢占，每个应用只能使用事先注册申请的资源。</li></ul><p>一次编译，到处运行</p><ul><li>类似于java代码，应用及依赖的环境构建一次，可以到处运行</li></ul><h1 id="Docker架构"><a href="#Docker架构" class="headerlink" title="Docker架构"></a>Docker架构</h1><p>Docker使用C/S架构，Client 通过接口与Server进程通信实现容器的构建，运行和发布。client和server可以运行在同一台集群，也可以通过跨主机实现远程通信。</p><p><img src="https://img-blog.csdnimg.cn/20181108181808777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NsZXZlckNvZGU=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="Docker核心原理"><a href="#Docker核心原理" class="headerlink" title="Docker核心原理"></a>Docker核心原理</h1><h3 id="Namespaces"><a href="#Namespaces" class="headerlink" title="Namespaces"></a>Namespaces</h3><p>命名空间（namespaces）是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。</p><p><a href="http://dockone.io/uploads/article/20190625/6498a2be3f3ddcb2a032df838ac24069.png" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190625/6498a2be3f3ddcb2a032df838ac24069.png" alt="3.png"></a></p><p>在这种情况下，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这也是我们不想看到的，而 Docker 其实就通过 Linux 的 Namespaces 对不同的容器实现了隔离。</p><p>Linux 的命名空间机制提供了以下七种不同的命名空间，包括 CLONE_NEWCGROUP、CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER 和 CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。</p><h1 id="Docker镜像原理"><a href="#Docker镜像原理" class="headerlink" title="Docker镜像原理"></a>Docker镜像原理</h1><ol><li><h2 id="镜像是什么"><a href="#镜像是什么" class="headerlink" title="镜像是什么"></a>镜像是什么</h2><p>镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件, 它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。</p></li></ol><h3 id="1-1-UnionFS-联合文件系统"><a href="#1-1-UnionFS-联合文件系统" class="headerlink" title="1.1 UnionFS(联合文件系统)"></a>1.1 UnionFS(联合文件系统)</h3><p>UnionFS(联合文件系统): Union文件系统(UnionFS)是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承, 基于基础镜像(没有父镜像)， 可以制作各种具体的应用镜像。<br>特性: 一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</p><h3 id="1-2-Docker镜像加载原理"><a href="#1-2-Docker镜像加载原理" class="headerlink" title="1.2 Docker镜像加载原理"></a>1.2 Docker镜像加载原理</h3><p>docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。</p><p><strong>bootfs(boot file system)</strong>主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的, 包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。</p><p>rootfs(root file system), 在bootfs之上。包含的就是典型Linux系统中的/dev, /proc, /bin, /etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。</p><p>平时我们安装虚拟机的CentOS都是好几个G，为什么docker这里才200M？linux mini 200G 2G </p><p>对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就行了。由此可见对于不同的linux发行版，bootfs基本是一致的，rootfs会有差别，因此不同的发行版可以共用bootfs。</p><h3 id="1-3-分层的镜像"><a href="#1-3-分层的镜像" class="headerlink" title="1.3 分层的镜像"></a>1.3 分层的镜像</h3><p>以我们的pull为例，在下载的过程中我们可以看到docker的镜像好像是在一层一层的在下载</p><h3 id="1-4-为什么docker镜像要采用这种分层结构呢"><a href="#1-4-为什么docker镜像要采用这种分层结构呢" class="headerlink" title="1.4 为什么docker镜像要采用这种分层结构呢"></a>1.4 为什么docker镜像要采用这种分层结构呢</h3><p>最大的一个好吃就是共享资源<br>比如：有多个镜像都从相同的base镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像,同时内存中也只需加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。</p><ol start="2"><li><h4 id="镜像的特点"><a href="#镜像的特点" class="headerlink" title="镜像的特点"></a>镜像的特点</h4><p>Docker镜像都是只读的<br>当容器启动时，一个新的可写层被加载到镜像的顶部。<br>这一层通常被称作为”容器层”，“容器层”之下的都叫”镜像层”。</p></li></ol><h1 id="Docker容器原理"><a href="#Docker容器原理" class="headerlink" title="Docker容器原理"></a>Docker容器原理</h1><p><strong>Docker 容器通过 Docker 镜像来创建，容器与镜像的关系类似于面向对象编程中的对象与类。</strong></p><p>如图所示基本架构：</p><p><img src="http://p3.pstatp.com/large/pgc-image/1536290868344c25780cff9" alt="阿里P8架构师谈:Docker容器的原理、特征、基本架构、与应用场景"></p><p><strong>Docker 镜像(Images)</strong></p><p>Docker 镜像是用于创建 Docker 容器的模板。</p><p><strong>Docker 容器(Container)</strong></p><p>容器是独立运行的一个或一组应用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>创建有一个新的 Django 项目</title>
      <link href="/2050/10/10/%E5%88%9B%E5%BB%BAdjango%E9%A1%B9%E7%9B%AE/"/>
      <url>/2050/10/10/%E5%88%9B%E5%BB%BAdjango%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="创建一个新的-Django-项目"><a href="#创建一个新的-Django-项目" class="headerlink" title="创建一个新的 Django 项目"></a>创建一个新的 Django 项目</h2><a id="more"></a><pre><code>- Django-admin startproject 项目名称- Cd 到 创建的 django 项目中- 创建子项目：- Python manage.py startapp 子项目名- Python manage.py createsuperuser 创建超级用户管理员- Python manage.py runserver 启动项目</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django-Views-视图层</title>
      <link href="/2032/12/09/Django-Views-%E8%A7%86%E5%9B%BE%E5%B1%82/"/>
      <url>/2032/12/09/Django-Views-%E8%A7%86%E5%9B%BE%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h3 id="视图层"><a href="#视图层" class="headerlink" title="视图层"></a>视图层</h3><blockquote><p>视图函数一般用来接收一个<code>Web</code>请求<code>HttpRequest</code>，之后返回一个Web响应<code>HttpResponse</code></p></blockquote><a id="more"></a><h4 id="HttpRequest"><a href="#HttpRequest" class="headerlink" title="HttpRequest"></a>HttpRequest</h4><blockquote><p>一个视图函数用来响应用户的<code>Request</code>请求，每个视图函数默认的第一个位置参数<code>request</code>用来接收用户发起请求的<code>HttpRequest</code>信息。</p><p>视图函数的返回值，为一个<code>HttpResponse</code>值，包括我们要返回给用户的<code>HTML</code>页面或者字符串等等，以及对应的头部字段信息</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line"><span class="keyword">return</span> HttpResponse(<span class="string">'Hello world'</span>)</span><br></pre></td></tr></table></figure><h4 id="常见请求方式"><a href="#常见请求方式" class="headerlink" title="常见请求方式"></a>常见请求方式</h4><blockquote><p><code>POST</code>和<code>GET</code>是<code>HTTP</code>协议定义的与服务器交互的方法。</p><p><code>GET</code>一般用于获取/查询资源信息，而<code>POST</code>一般用于更新资源信息。另外，还有<code>PUT</code>和<code>DELETE</code>方法</p></blockquote><h5 id="get"><a href="#get" class="headerlink" title="get"></a>get</h5><blockquote><p>常用来从指定地址请求数据；</p><p>如果需要在请求时提交某些数据，则以路由形式传递参数，查询<code>Query</code>字符串如下格式所示：</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.baidu.com/?key=abc&amp;pos=hebei</span><br></pre></td></tr></table></figure><ul><li><code>get</code>请求可被浏览器缓存，保存在历史记录中</li><li><code>get</code>不应在使用敏感数据时使用，明文包路在请求地址中</li><li><code>get</code>有长度限制</li></ul><h5 id="post"><a href="#post" class="headerlink" title="post"></a>post</h5><blockquote><p>向指定的资源提交要被处理的数据</p><p>使用<code>POST</code>，提交的数据保存在<code>HTTP</code>协议中的消息主体部分</p></blockquote><ul><li><code>post</code>请求不会被浏览器缓存</li><li><code>post</code>提交数据长度无限制</li><li><code>post</code>比<code>get</code>更加安全</li></ul><h4 id="request"><a href="#request" class="headerlink" title="request"></a>request</h4><blockquote><p>如果说<code>urls.py</code>是<code>Django</code>中前端页面和后台程序桥梁，那么<code>request</code>就是桥上负责运输的小汽车，可以说后端接收到的来至前端的信息几乎全部来自于<code>requests</code>中</p></blockquote><h5 id="request-method"><a href="#request-method" class="headerlink" title="request.method"></a>request.method</h5><blockquote><p>获取当前用户请求方式，</p><p>请求方式字符串为纯大写：<code>&#39;GET&#39;</code>、<code>&#39;POST&#39;</code></p><p>如用户以<code>get</code>方式发起请求，对应代码中获取到的结果以及在判断时像是这样</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line"><span class="keyword">if</span> request.method == <span class="string">'GET'</span>:</span><br><span class="line">…</span><br></pre></td></tr></table></figure><h5 id="request-GET"><a href="#request-GET" class="headerlink" title="request.GET"></a>request.GET</h5><blockquote><p>当用户通过<code>get</code>方式请求站点，并在路由中提供了查询参数，可以通过该属性获取到对应提交的值</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    print(request.GET) </span><br><span class="line">    <span class="comment"># &lt;QueryDict: &#123;'name': ['jack'], 'id': ['1']&#125;&gt;</span></span><br><span class="line">    print(type(request.GET)) </span><br><span class="line">    <span class="comment"># &lt;class 'django.http.request.QueryDict'&gt;</span></span><br><span class="line">    name_ = request.GET.get(<span class="string">'name'</span>)</span><br><span class="line">    id_ = request.GET.get(<span class="string">'id'</span>)</span><br><span class="line">    content = <span class="string">'%s:%s'</span> % (name_,id_)</span><br><span class="line">    <span class="keyword">return</span> HttpResponse(content)</span><br></pre></td></tr></table></figure><blockquote><p><code>request.GET</code>是一个类似字典的数据类型：<code>QueryDict</code></p><p>其中也支持类似对字典的<code>get</code>或直接<code>dict.[key]</code>键值访问方式，当然使用<code>get</code>方式进行对应<code>key</code>获取会更好，因为<code>get</code>在访问不到时不会报错</p></blockquote><ul><li>如果定义了如上所示的视图函数，那么在访问连接时，我们可以通过路由传参：</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://127.0.0.1:8000/?name=jack&amp;id=1</span><br></pre></td></tr></table></figure><ul><li>这里对应页面会显示的结果：</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jack:1</span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong>：使用<code>GET</code>方法在连接中进行参数提交，后台接收到的数据类型均是字符串</p></blockquote><hr><h5 id="request-POST"><a href="#request-POST" class="headerlink" title="request.POST"></a>request.POST</h5><blockquote><p>获取用户以<code>post</code>形式提交的数据并保存在后台，为类字典数据，这里和<code>request.GET</code>是一个东西；</p><p>在网页中，一般我们通过<code>html</code>的表单进行数据的提交，<code>POST</code>方式可以提交空数据</p></blockquote><ul><li>因为涉及到了表单页面，所以我们先来弄一个<code>HTML</code>页面</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span>这是一个关于POST的测试<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/"</span> <span class="attr">method</span>=<span class="string">"POST"</span>&gt;</span></span><br><span class="line">        &#123;% csrf_token %&#125;</span><br><span class="line">        账号:<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"account"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        密码:<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">name</span>=<span class="string">"passwd"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"提交"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>在模板页面中，一旦涉及到了表单提交，那么一定要注意在表单区域添加<code>csrf_token</code>标签进行防跨站伪造令牌的加载，否则表单数据的将被认为是无效的。</p></blockquote><blockquote><p>在接下来的视图函数中会使用到<code>input</code>标签中的<code>name</code>属性；</p><p><code>name</code>值属性维护了<code>post</code>的数据传入到后台时的标示，会与表单的数据组合成类字典格式</p><p>如<code>name</code>属性为<code>account</code>的输入框中输入了<code>test</code>，那么后台数据接收到的值类似：<code>{&#39;account&#39;:&#39;test&#39;}</code></p></blockquote><ul><li>写一个视图函数用来捕获当前表单使用POST形式提交的数据：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> request.method=<span class="string">"POST"</span>:</span><br><span class="line">        print(request.POST)</span><br><span class="line">        print(type(request.POST))</span><br><span class="line">        account = request.POST.get(<span class="string">"account"</span>)</span><br><span class="line">        passwd = request.POST.get(<span class="string">"passwd"</span>)</span><br><span class="line">        content = <span class="string">"%s:%s"</span> % (account,passwd)</span><br><span class="line">        <span class="keyword">return</span> HttpResponse(content)</span><br><span class="line">   <span class="keyword">return</span> render(request,<span class="string">"index.html"</span>) <span class="comment">#在使用get形式请求时，返回表单页面</span></span><br></pre></td></tr></table></figure><ul><li>如果在表单页面中账号填写为test，密码为123456；在视图函数中捕捉到的结果为：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;QueryDict: &#123;&apos;csrfmiddlewaretoken&apos;: [&apos;EmyGwsVcrXI2LDkYLS9qflkUH4N7bM1nfTQxr3fsOsZlI4vJFwci7TargtYRAGl2&apos;], &apos;account&apos;: [&apos;test&apos;], &apos;passwd&apos;: [&apos;123456&apos;]&#125;&gt;</span><br></pre></td></tr></table></figure><h6 id="表单夺表提交"><a href="#表单夺表提交" class="headerlink" title="表单夺表提交"></a>表单夺表提交</h6><blockquote><p>在<code>request.POST</code>中需要注意，某些情况下，使用POST提交数据的表单数据可能是多个值，类似复选框<code>CheckBox</code>，直接使用<code>request.POST.get()</code>进行获取是有一些问题的，比如修改模板页`面如下所示</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/"</span> <span class="attr">method</span>=<span class="string">"POST"</span>&gt;</span></span><br><span class="line">    &#123;% csrf_token %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">name</span>=<span class="string">"taste"</span> <span class="attr">value</span>=<span class="string">"eat"</span>&gt;</span>吃</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">name</span>=<span class="string">"taste"</span> <span class="attr">value</span>=<span class="string">"sleep"</span>&gt;</span>睡</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">name</span>=<span class="string">"taste"</span> <span class="attr">value</span>=<span class="string">"play"</span>&gt;</span>耍</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"提交"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>这是一个<code>name</code>值为<code>taste</code>的兴趣爱好采集的多选框，<code>value</code>值将会作为选中时，提交到后台的值，比如现在我们全选这些表单数据，那么后台接收到的值是这样的</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;QueryDict: &#123;&apos;csrfmiddlewaretoken&apos;: [&apos;nuaLzxc2E0artYKUZiefMPv5iHTX5gLFY1sCu8wi1vrKqpVFTWh7EnlCR64Hua5k&apos;], &apos;taste&apos;: [&apos;eat&apos;, &apos;sleep&apos;, &apos;play&apos;]&#125;&gt;</span><br></pre></td></tr></table></figure><blockquote><p>但是问题接踵而至，我们发现使用<code>get</code>函数获取不到对应全选的整个结果，而是只拿到了选中的最后一项</p></blockquote><ul><li><p><code>request.POST.get(key, default=None)</code></p><blockquote><p>返回对应<code>key</code>值的数据中的<strong>最后一个</strong>数据单独返回；<code>key</code>值不存在，取<code>default</code></p></blockquote></li></ul><blockquote><p>要想真正拿出所有的结果，应该使用<code>getlist</code>函数</p></blockquote><ul><li><p><code>request.POST.getlist(key, default=None)</code></p><blockquote><p>将对应<code>key</code>值的所有数据以<strong>一个列表</strong>形式返回；<code>key</code>值不存在，取<code>default</code></p></blockquote></li></ul><h5 id="request-META"><a href="#request-META" class="headerlink" title="request.META"></a>request.META</h5><blockquote><p><code>request.MAT</code>E获取的是一个标准的<code>python</code>字典。它包含了所有的<code>HTTP</code>请求信息</p><p>比如用户IP地址和用户<code>Agent</code>（通常是浏览器的名称和版本号）。</p><p>注意，<code>Header</code>信息的完整列表取决于用户所发送的<code>Header</code>信息和服务器端设置的<code>Header</code>信息</p></blockquote><ul><li><code>CONTENT_LENGTH</code>：请求的正文的长度，字符串类型</li><li><code>CONTENT_TYPE</code>：请求的正文的<code>MIME</code> 类型</li><li><code>HTTP_ACCEPT</code>：响应可接收的<code>Content-Type</code></li><li><code>HTTP_ACCEPT_ENCODING</code>：响应可接收的编码</li><li><code>HTTP_ACCEPT_LANGUAGE</code>：响应可接收的语言</li><li><code>HTTP_HOST</code>：客服端发送的<code>HTTP Host</code>头部</li><li><code>HTTP_REFERER</code>：请求前的连接地址</li><li><code>HTTP_USER_AGENT</code>：客户端的<code>user-agent</code>字符串</li><li><code>QUERY_STRING</code>：单个字符串形式的查询字符串（未解析过的形式）</li><li><code>REMOTE_ADDR</code>：客户端的IP 地址</li><li><code>REMOTE_HOST</code>：客户端的主机名</li><li><code>REMOTE_USER</code>：服务器认证后的用户</li><li><code>REQUEST_METHOD</code>：一个字符串，例如<code>GET</code> 或<code>POST</code></li><li><code>SERVER_NAME</code>：服务器的主机名</li><li><code>SE0RVER_PORT</code>：服务器的端口，字符串类型</li></ul><h5 id="request-FILES"><a href="#request-FILES" class="headerlink" title="request.FILES"></a>request.FILES</h5><blockquote><p>接收用户上传文件及相关信息。同样类似于<code>request.POST</code>，提取到的数据为一个类字典的数据类型，包含所有文件上传的信息</p></blockquote><ul><li><p><code>f = request.FILES.get(&#39;upload_file&#39;)</code></p><blockquote><p><code>file_data = f.read()</code>：读取整个上传文件的内容，适合小文件上传</p><p><code>yiled = f.chunks()</code>：返回一个类似生成器<code>（&lt;class &#39;generator&#39;&gt;）</code>的数据，每一次读取按块返回文件，可以通过<code>for</code>迭代访问其中数据；适合上传大文件到服务器。</p><p><code>f.multiple_chunks()</code>：返回文件大小，当文件大小大于<code>2.5M</code>时，返回<code>True</code>，反之返回<code>False</code>，可以通过该函数来选择是否使用<code>chunks</code>方法或<code>read</code>直接存储。</p><p>如果想要修改这个文件判定的默认值，可以通过：<code>FILE_UPLOAD_MAX_MEMORY_SIZE</code>在<code>settings</code>文件下进行设置</p><p><code>f.content_type</code>：上传文件时头部中的<code>Content-Type</code>字段值，参考MIME类型</p><p><code>f.name</code>：上传文件名字</p><p><code>f.charset</code>：上传文件编码</p><p><code>f.size</code>： 上传文件大小，字节为单位：<code>byte</code></p></blockquote></li></ul><blockquote><p>创建好静态资源目录，并在下面创建一个<code>img</code>文件夹，保存我们即将上传的图片；</p><p>完成上传文件的<code>HTML</code>表单页面</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/"</span> <span class="attr">method</span>=<span class="string">"POST"</span> <span class="attr">enctype</span>=<span class="string">"multipart/form-data"</span>&gt;</span></span><br><span class="line">    &#123;% csrf_token %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"file"</span> <span class="attr">name</span>=<span class="string">"upload_file"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"提交"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"&#123;% static 'img/1.jpg' %&#125;"</span> <span class="attr">alt</span>=<span class="string">"这是一张图片"</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 这里使用的是即将要上传的文件名字，只做文件是否上传成功的简单测试 --&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong>：上传文件的页面表单，一定要记得设置属性<code>enctype=&quot;multipart/form-data&quot;</code></p></blockquote><ul><li>视图函数如下编写，接收上传图片，并保存在静态目录下刚才创建好的img目录中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">"POST"</span>:</span><br><span class="line">        f = request.FILES.get(<span class="string">"upload_files"</span>)</span><br><span class="line">        path = os.path.join(settings.STATICFILES_DIRS[<span class="number">0</span>],<span class="string">'img/'</span>+f.name)</span><br><span class="line">  <span class="comment"># 上传文件本地保存路径</span></span><br><span class="line">        <span class="keyword">with</span> open(path,<span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            <span class="keyword">if</span> f.multiple_chunks: <span class="comment">#判断到上传文件为大于2.5MB的大文件</span></span><br><span class="line">                <span class="keyword">for</span> buf <span class="keyword">in</span> f.chunks(): <span class="comment">#迭代写入文件</span></span><br><span class="line">                    fp.write(buf)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fp.write(f.read())</span><br><span class="line">            <span class="keyword">return</span> HttpResponse(<span class="string">"Success!"</span>)</span><br><span class="line">  <span class="keyword">return</span> render(request, <span class="string">'index.html'</span>)</span><br></pre></td></tr></table></figure><blockquote><p>测试上传一个名为<code>1.jpg</code>的图片，如果成功上传，那么后台<code>static</code>目录下会出现该图片，并且模板页面也可以展示对应图片效果</p></blockquote><h4 id="HTTPResponse"><a href="#HTTPResponse" class="headerlink" title="HTTPResponse"></a>HTTPResponse</h4><blockquote><p>一个视图的返回值经常是为了向用户返回一个<code>HttpResponse</code>响应，</p><p>有如下常用的可以返回<code>HttpResponse</code>的函数</p></blockquote><h5 id="response"><a href="#response" class="headerlink" title="response"></a>response</h5><ul><li><p><code>HttpResponse(content=b&#39;&#39;)</code></p><blockquote><p>返回一个字符串内容</p><p><em>from</em> django.http <em>import</em> HttpResponse</p></blockquote></li><li><p><code>render(request,template_name,context=None,content_type=None,status=None)</code></p><blockquote><p>返回一个可渲染HTML页面，状态码为<code>200</code></p><p><em>from</em> django.shortcuts <em>import</em> render</p></blockquote><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; request`：固定参数，响应的`request`请求，来自于参数部分接收的`HttpRequest</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><blockquote><p><code>template_name</code>：返回的模板页面路径</p><p><code>context</code>：模板页面渲染所需的数据，默认为字典格式</p><p><code>content_type</code>：生成之后的结果使用的<code>MIME</code>类型</p><p><code>status</code>：响应的状态码，默认为<code>200</code></p></blockquote></li><li><p>redirect(to, permanent=False)</p><blockquote><p>一个重定向，浏览器通过该状态码自动跳转到一个新的路由地址，默认返回响应状态码<code>302</code></p><p><em>from</em> django.shortcuts <em>import</em> redirect</p></blockquote><blockquote><p><code>to</code>：可以是一个<code>django</code>项目中视图函数的路由映射，也可以是一个<code>reverse</code>的反向路由解析</p><p><code>permanent</code>：如果设置为<code>True</code>，将返回<code>301</code>状态码，代表永久重定向</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">302</span>：临时重定向，旧地址资源临时不能用了，搜索引擎只会暂时抓取新地址的内容而保存旧的地址。</span><br><span class="line"><span class="number">301</span>：永久重定向，旧地址资源已经不复存在，搜索引擎不光会抓取新地址的内容，还会替换旧地址为新地址</span><br></pre></td></tr></table></figure></li></ul><h4 id="视图错误处理"><a href="#视图错误处理" class="headerlink" title="视图错误处理"></a>视图错误处理</h4><blockquote><p>为了方便我们开发，<code>django</code>提供了一个异常叫做<code>Http404</code>异常，我们可以在视图函数的代码中按照需求进行抛出，抛出之后<code>django</code>项目会自动捕获该异常，并会展示默认的<code>404</code>页面</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> Http404</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> request.GET.get(<span class="string">"id"</span>) == <span class="string">"1"</span>:</span><br><span class="line">        <span class="keyword">raise</span> Http404</span><br></pre></td></tr></table></figure><blockquote><p>在<code>settings</code>中的<code>debug</code>配置项为<code>false</code>时，访问<code>http://127.0.0.1:8000/?id=1</code>，可以看到<code>django</code>为我们提供的错误页面；</p><p>除了<code>django</code>默认提供的，我们还可以可以在模板目录下定义全局<code>404.html</code>进行错误页面的定制</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span></span><br><span class="line">    抱歉，找不到你要的东西</span><br><span class="line"><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="自定义错误处理视图"><a href="#自定义错误处理视图" class="headerlink" title="自定义错误处理视图"></a>自定义错误处理视图</h5><blockquote><p>除去<code>404</code>错误的自定义，<code>django</code>还提供了覆盖默认错误行为处理的办法；</p><p>有些时候，<code>django</code>自动的错误处理可能不能满足我们的需求，那么我们可以重新定义一些新的视图函数，</p><p>来覆盖掉<code>django</code>所提供的错误处理视图函数，最后在<code>urls.py</code>路由配置文件下通过定义全局变量来重新设置默认的错误处理视图函数</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">handler404：覆盖page_not_found()视图。</span><br><span class="line">handler500：覆盖server_error()视图。</span><br><span class="line">handler403：覆盖permission_denied()视图。</span><br><span class="line">handler400：覆盖bad_request()视图。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,include</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    path(<span class="string">''</span>, include(<span class="string">"viewapp.urls"</span>)),</span><br><span class="line">]</span><br><span class="line">handler404 = <span class="string">"viewapp.views.error_404"</span></span><br><span class="line"><span class="comment"># APP.模块.视图函数</span></span><br><span class="line">handler500 = <span class="string">"viewapp.views.error_500"</span></span><br></pre></td></tr></table></figure><blockquote><p>相关定义好的错误处理视图函数</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">error_404</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">"这是404错误"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">error_403</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">"这是403错误"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">error_500</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">"这是500错误"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程线程协程</title>
      <link href="/2031/10/26/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B/"/>
      <url>/2031/10/26/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="进程线程协程"><a href="#进程线程协程" class="headerlink" title="进程线程协程"></a>进程线程协程</h1><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><blockquote><p>进程概念</p></blockquote><p> <strong>概念</strong>:就是一个程序在一个数据集上的一次动态执行过程(本质上来讲,就是运行中的程序(代指运行过程),程序不运行就不是进程)   抽象概念</p><a id="more"></a><p> <strong>阐释</strong>:进程与进程之间都占用的是独立的内存块,它们彼此之间的数据也是独立的</p><p><strong>优点</strong>:同时利用多个CPU,能够同时进行多个操作</p><p><strong>缺点</strong>:耗费资源(需要重新开辟内存空间)</p><blockquote><p>进程定义</p></blockquote><ol><li>进程是资源分配的最小单位</li><li>一个运行起来的程序就是一个进程</li><li>进程之间内存独立，不能够相互访问</li></ol><blockquote><p>进程通信</p></blockquote><ul><li><p>python提供了多种进程通信的方式，主要Queue和Pipe这两种方式，Queue用于多个进程间实现通信，Pipe是两个进程的通信</p><ul><li><p>创建进程模块下的队列（Queue）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Queue有两个方法：</span></span><br><span class="line"><span class="string">Put方法：以插入数据到队列中，他还有两个可选参数：blocked和timeout。详情自行百度</span></span><br><span class="line"><span class="string">Get方法：从队列读取并且删除一个元素。同样，他还有两个可选参数：blocked和timeout。详情自行百度</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#!coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br><span class="line"><span class="keyword">import</span> os,time,random</span><br><span class="line"></span><br><span class="line"><span class="comment">#写数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc_write</span><span class="params">(q,urls)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Process is write....'</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        q.put(url)</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'put %s to queue... '</span> %url</span><br><span class="line">        time.sleep(random.random())</span><br><span class="line"></span><br><span class="line"><span class="comment">#读数据进程的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc_read</span><span class="params">(q)</span>:</span></span><br><span class="line">    print(<span class="string">'Process is reading...'</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        url = q.get(<span class="literal">True</span>)</span><br><span class="line">        print(<span class="string">'Get %s from queue'</span> %url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#父进程创建Queue，并传给各个子进程</span></span><br><span class="line">    q = Queue()</span><br><span class="line">    proc_write1 = Process(target=proc_write,args=(q,[<span class="string">'url_1'</span>,<span class="string">'url_2'</span>,<span class="string">'url_3'</span>]))</span><br><span class="line">    proc_write2 = Process(target=proc_write,args=(q,[<span class="string">'url_4'</span>,<span class="string">'url_5'</span>,<span class="string">'url_6'</span>]))</span><br><span class="line">    proc_reader = Process(target=proc_read,args=(q,))</span><br><span class="line">    <span class="comment">#启动子进程，写入</span></span><br><span class="line">    proc_write1.start()</span><br><span class="line">    proc_write2.start()</span><br><span class="line"></span><br><span class="line">    proc_reader.start()</span><br><span class="line">    <span class="comment">#等待proc_write1结束</span></span><br><span class="line">    proc_write1.join()</span><br><span class="line">    proc_write2.join()</span><br><span class="line">    <span class="comment">#proc_raader进程是死循环，强制结束</span></span><br><span class="line">    proc_reader.terminate()</span><br></pre></td></tr></table></figure></li><li><p>管道（Pipe）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">* Pipe常用于两个进程，两个进程分别位于管道的两端</span></span><br><span class="line"><span class="string">* Pipe方法返回（conn1,conn2）代表一个管道的两个端，Pipe方法有duplex参数，默认为True，即全双工模式，若为FALSE，conn1只负责接收信息，conn2负责发送，</span></span><br><span class="line"><span class="string">* send和recv方法分别为发送和接收信息。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment">#!coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os,time,random</span><br><span class="line"></span><br><span class="line"><span class="comment">#写数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc_send</span><span class="params">(pipe,urls)</span>:</span></span><br><span class="line">    <span class="comment">#print 'Process is write....'</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Process is send :%s'</span> %url</span><br><span class="line">        pipe.send(url)</span><br><span class="line">        time.sleep(random.random())</span><br><span class="line"></span><br><span class="line"><span class="comment">#读数据进程的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc_recv</span><span class="params">(pipe)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        print(<span class="string">'Process rev:%s'</span> %pipe.recv())</span><br><span class="line">        time.sleep(random.random())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#父进程创建pipe，并传给各个子进程</span></span><br><span class="line">    pipe = multiprocessing.Pipe()</span><br><span class="line">    p1 = multiprocessing.Process(target=proc_send,args=(pipe[<span class="number">0</span>],[<span class="string">'url_'</span>+str(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>) ]))</span><br><span class="line">    p2 = multiprocessing.Process(target=proc_recv,args=(pipe[<span class="number">1</span>],))</span><br><span class="line">    <span class="comment">#启动子进程，写入</span></span><br><span class="line">    p1.start()</span><br><span class="line">    p2.start()</span><br><span class="line"></span><br><span class="line">    p1.join()</span><br><span class="line">    p2.terminate()</span><br></pre></td></tr></table></figure></li></ul></li></ul><blockquote><p>进程同步</p></blockquote><p>Loke</p><p>锁是为了确保数据一致性，比如读写锁，每个进程给一个变量增加 1 ，但是如果在一个进程读取但还没有写入的时候，另外的进程也同时读取了，并写入该值，则最后写入的值是错误的，这时候就需要锁 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为什么引申进程同步</span></span><br><span class="line"><span class="comment"># 数据的一致性</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Lock, Process</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(i, lock)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> lock:  <span class="comment"># 自动获得锁和释放锁</span></span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    lock = Lock()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        p = Process(target=run,args=(i,lock,))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><blockquote><p>进程池</p></blockquote><p>如果有50个任务要去执行,CPU只有4核,那创建50个进程完成,其实大可不必，徒增管理开销。如果只想创建4个进程，让它们轮流替完成任务，不用自己去管理具体的进程的创建销毁，那 Pool 是非常有用的。</p><p>Pool 是进程池，进程池能够管理一定的进程，当有空闲进程时，则利用空闲进程完成任务，直到所有任务完成为止</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os,time</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> pool,Process</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="comment"># print(os.getpid())</span></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    print(n)</span><br><span class="line">    <span class="keyword">return</span> n    <span class="comment"># 该函数的返回值,是回调函数的所要传入的值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bar</span><span class="params">(args)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># print("bar &#123;&#125;".format(args))</span></span><br><span class="line">    <span class="comment"># print(os.getpid())</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    p_pool = pool.Pool(<span class="number">5</span>)   <span class="comment"># 设置进程池中的最大放置</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        <span class="comment"># 回调函数,就是某个函数执行成功或结束执行的函数</span></span><br><span class="line">        <span class="comment"># apply_async  (任务都是并发进行,并且可以设置回调函数) 进程的并发其实可以称之为并行了,可以利用到多核CPU</span></span><br><span class="line">        p_pool.apply_async(func=run,args=(n,),callback=bar)<span class="comment"># 非堵塞式运行</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># apply  (每个任务是排队进行,类似于串行失去意义)</span></span><br><span class="line"><span class="comment"># p_pool.apply(func=run,args=(n,),callback=bar) # 堵塞式运式</span></span><br><span class="line">        </span><br><span class="line">    p_pool.close()  <span class="comment"># 进程的关闭和等待是有顺序的</span></span><br><span class="line">    p_pool.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"ending"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 看看 Pool 的执行流程，有三个阶段。第一、一个进程池接收很多任务，然后分开执行任务；第二、不再接收任务了；第三、等所有任务完成了，回家，不干了。</span></span><br><span class="line"><span class="comment"># 这就是上面的方法，close 停止接收新的任务，如果还有任务来，就会抛出异常。 join 是等待所有任务完成。 join 必须要在 close 之后调用，否则会抛出异常。terminate 非正常终止，内存不够用时，垃圾回收器调用的就是这个方法。</span></span><br></pre></td></tr></table></figure><h2 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h2><blockquote><p>线程概念</p></blockquote><p> <strong>概念</strong>:线程是应用程序中工作的最小单元，或者又称之为微进程。 </p><p> <strong>阐释</strong>:线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。线程可以共享(调用)进程的数据资源 </p><p> <strong>优点</strong>:共享内存,IO操作时候,创造并发操作 </p><blockquote><p>线程定义</p></blockquote><ol><li>线程是系统调度的最小单位</li><li>同进程下线程资源共享</li><li>进程无法自己执行，只有通过线程操作CUP内存</li></ol><blockquote><p>多线程</p></blockquote><p>多线程类似于同时执行多个不同程序，多线程运行有如下优点：</p><ul><li>使用线程可以把占据长时间的程序中的任务放到后台去处理。</li><li>用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度</li><li>程序的运行速度可能加快</li><li>在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下我们可以释放一些珍贵的资源如内存占用等等。</li></ul><p><strong>GIL</strong></p><ul><li>在Cpython解释器中，同一个进程下开启的多线程，同一时刻只能有一个线程执行，无法利用多核优势</li><li><strong>百度翻译</strong>：：在CPython中，全局解释器锁（global interpreter lock，GIL）是一个互斥体，它防止多个本机线程同时执行Python字节码这个锁是必要的，主要是因为cpython的内存管理不是线程安全的。（然而，由于吉尔存在，其他特征已经发展成依赖于它所实施的保证。）</li></ul><p><strong>死锁和递归锁</strong></p><ul><li><p>在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁，因为系统判断这部分资源都正在使用，所有这两个线程在无外力作用下将一直等待下去</p></li><li><p>解决死锁就可以使用递归锁</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading,time</span><br><span class="line"></span><br><span class="line"><span class="comment"># lock_A = threading.Lock()</span></span><br><span class="line"><span class="comment"># lock_B = threading.Lock()</span></span><br><span class="line">r_lock = threading.RLock()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mythread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">actionA</span><span class="params">(self)</span>:</span></span><br><span class="line">        r_lock.acquire()</span><br><span class="line">        print(self.name,time.ctime())</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">        r_lock.acquire()</span><br><span class="line">        print(self.name,time.ctime())</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        r_lock.release()</span><br><span class="line">        r_lock.release()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">actionB</span><span class="params">(self)</span>:</span></span><br><span class="line">        r_lock.acquire()</span><br><span class="line">        print(self.name,time.ctime())</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">        r_lock.acquire()</span><br><span class="line">        print(self.name,time.ctime())</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        r_lock.release()</span><br><span class="line">        r_lock.release()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.actionA()</span><br><span class="line">        self.actionB()</span><br><span class="line">li = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    t = Mythread()</span><br><span class="line">    t.start()</span><br><span class="line">    li.append(t)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> li:</span><br><span class="line">    t.join()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"ending"</span>)</span><br></pre></td></tr></table></figure></li></ul><blockquote><p> <strong>join() 作用</strong></p></blockquote><p>知识点一：<br>当一个进程启动之后，会默认产生一个主线程，因为线程是程序执行流的最小单元，当设置多线程时，主线程会创建多个子线程，在python中，默认情况下（其实就是setDaemon(False)），主线程执行完自己的任务以后，就退出了，此时子线程会继续执行自己的任务，直到自己的任务结。</p><p>知识点二：<br>当我们使用setDaemon(True)方法，设置子线程为守护线程时，主线程一旦执行结束，则全部线程全部被终止执行，可能出现的情况就是，子线程的任务还没有完全执行结束，就被迫停止，例子见下面二。</p><p>知识点三：<br>此时join的作用就凸显出来了，join所完成的工作就是线程同步，即主线程任务结束之后，进入阻塞状态，一直等待其他的子线程执行结束之后，主线程在终止，例子见下面三。</p><p>知识点四：<br>join有一个timeout参数：</p><ol><li>当设置守护线程时，含义是主线程对于子线程等待timeout的时间将会杀死该子线程，最后退出程序。所以说，如果有10个子线程，全部的等待时间就是每个timeout的累加和。简单的来说，就是给每个子线程一个timeout的时间，让他去执行，时间一到，不管任务有没有完成，直接杀死。</li><li>没有设置守护线程时，主线程将会等待timeout的累加和这样的一段时间，时间一到，主线程结束，但是并没有杀死子线程，子线程依然可以继续执行，直到子线程全部结束，程序退出。</li></ol><blockquote><p> <strong>信号量(Semaphore):从意义上来讲,也可以称之为一种锁</strong></p></blockquote><p>信号量：指同时开几个线程并发</p><p> 　　信号量用来控制线程并发数的，BoundedSemaphore或Semaphore管理一个内置的计数 器，每当调用acquire()时-1，调用release()时+1。</p><p>计数器不能小于0，当计数器为 0时，acquire()将阻塞线程至同步锁定状态，直到其他线程调用release()。(类似于停车位的概念)</p><p><strong>例</strong>：</p><p>以一个停车场的运作为例。简单起见，假设停车场只有三个车位，一开始三个车位都是空的。这时如果同时来了五辆车，看门人允许其中三辆直接进入，然后放下车拦，剩下的车则必须在入口等待，此后来的车也都不得不在入口处等待。这时，有一辆车离开停车场，看门人得知后，打开车拦，放入外面的一辆进去，如果又离开两辆，则又可以放入两辆，如此往复。</p><p>在这个停车场系统中，车位是公共资源，每辆车好比一个<a href="https://baike.baidu.com/item/线程" target="_blank" rel="noopener">线程</a>，看门人起的就是信号量的作用。</p><blockquote><p>线程池</p></blockquote><p>为什么要使用线程池？</p><p><strong>答</strong>：对于任务数量不断增加的程序，每有一个任务就生成一个线程，最终会导致线程数量的失控</p><p>例如：整站爬虫，假设初始只有一个链接a，那么，这个时候只启动一个线程，运行之后，得到这个链接对应页面上的b，c，d，，，等等新的链接，作为新任务，这个时候，就要为这些新的链接生成新的线程，线程数量暴涨。在之后的运行中，线程数量还会不停的增加，完全无法控制。所以，对于任务数量不端增加的程序，固定线程数量的线程池是必要的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> threadpool<span class="comment"># pip3 install threadpool</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sayhello</span> <span class="params">(a)</span>:</span></span><br><span class="line">    print(<span class="string">"hello: "</span>+a)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> result</span><br><span class="line">    seed=[<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>]</span><br><span class="line">    start=time.time()</span><br><span class="line">    task_pool=threadpool.ThreadPool(<span class="number">5</span>)</span><br><span class="line">    requests=threadpool.makeRequests(sayhello,seed)</span><br><span class="line">    <span class="keyword">for</span> req <span class="keyword">in</span> requests:</span><br><span class="line">        task_pool.putRequest(req)</span><br><span class="line">    task_pool.wait()</span><br><span class="line">    end=time.time()</span><br><span class="line">    time_m = end-start</span><br><span class="line">    print(<span class="string">"time: "</span>+str(time_m))</span><br><span class="line">    start1=time.time()</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> seed:</span><br><span class="line">        sayhello(each)</span><br><span class="line">    end1=time.time()</span><br><span class="line">    print(<span class="string">"time1: "</span>+str(end1-start1))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><blockquote><p>概念</p></blockquote><p> <strong>概念：</strong>协程，又称微线程，纤程。英文名Coroutine。 是非抢占式的程序 主要也是解决I/O操作的 </p><p><strong>优点：</strong></p><p>优点1: 协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。</p><p>优点2: 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</p><p>因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。</p><blockquote><p>协程定义</p></blockquote><ol><li>协程在单线程下实现并发效果</li><li>协程遇到IO自动切换</li><li>携程保留上一次调用状态</li></ol><blockquote><p>携程处理并发</p></blockquote><ul><li><p>Gevent</p><ul><li><p>遇IO自动切换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gevent</span><br><span class="line"><span class="keyword">import</span> requests,time</span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    print(<span class="string">"get: &#123;&#125;"</span>.format(url))</span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    data = resp.text</span><br><span class="line">    print(len(data),url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get_url('https://www.python.org/')</span></span><br><span class="line"><span class="comment"># get_url('https://www.yahoo.com/')</span></span><br><span class="line"><span class="comment"># get_url('https://www.baidu.com/')</span></span><br><span class="line"><span class="comment"># get_url('https://www.sina.com.cn/')</span></span><br><span class="line"><span class="comment"># get_url('http://www.xiaohuar.com/')</span></span><br><span class="line"></span><br><span class="line">gevent.joinall(</span><br><span class="line">    [</span><br><span class="line">        gevent.spawn(get_url, <span class="string">'https://www.python.org/'</span>),</span><br><span class="line">        gevent.spawn(get_url, <span class="string">'https://www.yahoo.com/'</span>),</span><br><span class="line">        gevent.spawn(get_url, <span class="string">'https://www.baidu.com/'</span>),</span><br><span class="line">        gevent.spawn(get_url, <span class="string">'https://www.sina.com.cn/'</span>),</span><br><span class="line">        gevent.spawn(get_url,<span class="string">'http://www.xiaohuar.com/'</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(time.time()-start_time)</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>Greenlet</p><ul><li><p>遇IO手动切换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> greenlet <span class="keyword">import</span> greenlet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test1</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="number">12</span>)</span><br><span class="line">    gr2.switch()</span><br><span class="line">    print(<span class="number">34</span>)</span><br><span class="line">    gr2.switch()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test2</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="number">56</span>)</span><br><span class="line">    gr1.switch()</span><br><span class="line">    print(<span class="number">78</span>)</span><br><span class="line"></span><br><span class="line">gr1 = greenlet(test1)</span><br><span class="line">gr2 = greenlet(test2)</span><br><span class="line">gr1.switch()</span><br><span class="line">gr2.switch()</span><br></pre></td></tr></table></figure></li></ul></li></ul><p><strong>协程的优势</strong>：</p><p>1、没有切换的消耗</p><p>2、没有锁的概念</p><p>有一个问题：能用多核吗？</p><p>答：可以采用多进程+协程，是一个很好的解决并发的方案</p><blockquote><p>select、poll、epoll（重点）</p></blockquote><p>IO复用：为了解释这个名词，首先来理解下复用这个概念，复用也就是共用的意思，这样理解还是有些抽象</p><ul><li>例：客户端发来的请求服务端会产生一个进程来对其进行服务，每当来一个客户请求就产生一个进程来服务，然而进程不可能无限制的产生</li></ul><p>因此为了解决大量客户端访问的问题，引入了IO复用技术，即：一个进程可以同时对多个客户请求进行服务。</p><p> select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。<strong>但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的</strong>，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 </p><p>（1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用 epoll_wait<br>不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在 epoll_wait中<br>进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的 时候只要判断一下就绪链表<br>是否为空就行了，这节省了大量的CPU时间，这就是回调机制带来的性能提升。</p><p>（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要 一次拷贝，<br>而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内<br>部定义的等待队列），这也能节省不少的开销。</p><blockquote><p>猴子补丁</p></blockquote><p><strong>猴子补丁的功能(一切皆对象)</strong></p><p>　　1.拥有在模块运行时替换的功能, 例如: 一个函数对象赋值给另外一个函数对象(把函数原本的执行的功能给替换了)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Example</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func1</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'我才是原装'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">(*args)</span>:</span></span><br><span class="line">    print(<span class="string">'我要取代你'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func3</span><span class="params">(*args)</span>:</span></span><br><span class="line">    print(<span class="string">'都给我一边去'</span>)</span><br><span class="line"></span><br><span class="line">instance = Example()</span><br><span class="line">Example.func1 = func2</span><br><span class="line">instance.func1() <span class="comment"># 我要取代你</span></span><br><span class="line">instance.func1 = func3</span><br><span class="line">instance.func1() <span class="comment"># 都给我一边去</span></span><br><span class="line">instance2 = Example()</span><br><span class="line">instance2.func1() <span class="comment"># 我要取代你</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 进程线程协程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql主从复制</title>
      <link href="/2031/08/11/Mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
      <url>/2031/08/11/Mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="Mysql主从复制"><a href="#Mysql主从复制" class="headerlink" title="Mysql主从复制"></a>Mysql主从复制</h3><ul><li>什么是<strong>主从复制</strong>？</li></ul><a id="more"></a><blockquote><p>主从复制至少需要两台服务器，或两个<strong>mysql</strong>服务，可以配置一主多从，多主多从</p><p>建立与某个业务数据库一样的数据库环境，即为主从复制</p><p>一般情况下，主库用以写，而从库用以读</p></blockquote><ul><li>为什么要搭建主从复制？ <ul><li>构建主从热备，当某天数据库宕机或或数据丢失情况，可以有备份数据库继续工作</li><li>降低IO频次，多库之间可以合理分配读写压力，提高单个数据库服务的数据库访问压力</li><li>隔离读写，在某些锁表情况下，可以使数据库读操作继续进行</li></ul></li><li>主从复制原理 </li></ul><blockquote><p>利用数据库<strong>bin-log</strong>二进制文件，该文件包含有数据库操作的所有SQL语句 </p><p>复制该文件至其余数据库服务中并执行即可</p></blockquote><ul><li><p>主从复制过程 </p><ul><li><p>当主库具有新数据时，主库会被从库请求，建立线程进行连接，用以传输<strong>binlog</strong>日志</p></li><li><p>从库开启两个线程</p><blockquote><p>A线程：也叫做<strong>IO线程</strong>，连接主库，并请求binlog中的更新记录至从库中，写入至从库的<strong>relaylog</strong>文件中</p><p>B线程：也叫做<strong>SQL线程</strong>，读取<strong>relaylog</strong>文件中的更新操作并执行</p></blockquote></li><li><p>如果，有多个从库同时存在，主库会为每个从库建立一个<strong>binlog</strong>输出线程 </p></li></ul></li></ul><p><img src="/images/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B61-1.png" alt="1578228433821"></p><p>首先输入如下命令配置全局环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set global validate_password_policy=LOW;</span><br><span class="line"></span><br><span class="line">set global validate_password_length=6;</span><br></pre></td></tr></table></figure><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><blockquote><p>此处以一主一从为例 </p></blockquote><ul><li>系统环境<ul><li>主库（master）：47.96.189.157</li><li>从库（slave）：116.62.237.164</li></ul></li></ul><h3 id="主库修改"><a href="#主库修改" class="headerlink" title="主库修改"></a>主库修改</h3><ul><li>主库配置修改</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server-id = 1</span><br><span class="line">log-bin=mysql-bin # 开启log bin</span><br><span class="line">expire_logs_days=7 # 日志保存时间</span><br></pre></td></tr></table></figure><blockquote><p><strong>server-id</strong>：</p><p>同步数据中必须包含<strong>server-id</strong>，用于标识该语句最初是从哪个<strong>server</strong>写入</p><p>每个<strong>slave</strong>端只能有一个线程在<strong>master</strong>端连接，如果两个<strong>slave</strong>端的<strong>server-id</strong>一致，一个连接成功之后，前一个连接将会被断开</p><p>主主同步时，避免数据同步陷入死循环</p></blockquote><p><strong>修改完配置要记得重新启动下数据库</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysqld restart</span><br></pre></td></tr></table></figure><ul><li>主库创建用户，用以从机连接获取<strong>binlog</strong>日志 ，密码根据实际情况来定</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grant replication slave on *.* to &apos;master&apos;@&apos;%&apos; identified by &apos;123456&apos;;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to master@&apos;%&apos; identified by &quot;123456&quot;;</span><br></pre></td></tr></table></figure><ul><li>查看master状态</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show master status;</span><br></pre></td></tr></table></figure><ul><li>记录上条命令返回的<strong>binlog</strong>文件名，<strong>Position</strong>属性，从机连接的时候要用 </li></ul><p><img src="/images/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B61-2.png" alt="1578228433821"></p><h3 id="从库修改"><a href="#从库修改" class="headerlink" title="从库修改"></a>从库修改</h3><ul><li>从库配置修改 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server-id=100</span><br></pre></td></tr></table></figure><blockquote><p><strong>master</strong>与<strong>slave</strong>端的<strong>server-id</strong>不能一样</p><p><strong>slave</strong>端无需开启<strong>log-bin</strong>功能</p><p><strong>还是不要忘记重新启动一下数据库</strong></p></blockquote><ul><li>从库指定master，执行如下 </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">change master to master_host=&apos;47.96.189.157&apos;, master_port=3306, master_user=&apos;master&apos;, master_password=&apos;123456&apos;, master_log_file=&apos;mysql-bin.000001&apos;, master_log_pos=154;</span><br></pre></td></tr></table></figure><ul><li>启动从机</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start slave;</span><br></pre></td></tr></table></figure><p>这样就ok啦！</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DockerFile</title>
      <link href="/2031/06/30/DockerFile/"/>
      <url>/2031/06/30/DockerFile/</url>
      
        <content type="html"><![CDATA[<h2 id="DockerFile"><a href="#DockerFile" class="headerlink" title="DockerFile"></a>DockerFile</h2><h4 id="1、DockerFile简介"><a href="#1、DockerFile简介" class="headerlink" title="1、DockerFile简介"></a>1、DockerFile简介</h4><a id="more"></a><ul><li>DockerFile是用来构建Docker镜像的<strong>构建文件</strong>，是由一系列命令和参数构成的脚本</li><li>构建步骤（1）编写DockerFile文件（2）执行docker build（3）docker run</li></ul><h4 id="2、DockerFile构建过程解析"><a href="#2、DockerFile构建过程解析" class="headerlink" title="2、DockerFile构建过程解析"></a>2、DockerFile构建过程解析</h4><ul><li>编写规范<ul><li>每条保留字指令都必须为大写字母且必须跟参数：例如 FROM nginx</li><li>指令从上到下，顺序执行</li><li>#表示注释</li><li>每条指令都会创建一个新的镜像层，并对镜像进行提交</li></ul></li><li>编写步骤<ul><li>docker从基础镜像运行一个容器</li><li>执行一条指令并对容器做出修改</li><li>执行类似docker commit的操作提交一个新的镜像层</li><li>docker再基于刚提交的镜像运行一个新容器</li><li>执行dockerfile中的下一条指令直到所有指令都指向完成</li></ul></li></ul><blockquote><p>dockerfile、镜像、容器之间的关系可以类比为生产环境中的，原材料，交付品，运行的产品</p></blockquote><h4 id="3、常用关键字（语法）"><a href="#3、常用关键字（语法）" class="headerlink" title="3、常用关键字（语法）"></a>3、常用关键字（语法）</h4><table><thead><tr><th>关键字</th><th>释意</th></tr></thead><tbody><tr><td>FROM</td><td>基础镜像，当前新镜像的父镜像</td></tr><tr><td>MAINTAINER</td><td>镜像维护者的姓名和邮箱</td></tr><tr><td>RUN</td><td>容器构建需要运行的命令，用&amp;&amp;连接脚本可以减少镜像的层数</td></tr><tr><td>EXPOSE</td><td>当前容器对外暴露出的端口</td></tr><tr><td>WORKDIR</td><td>指定在创建容器后，终端默认登录进来的目录</td></tr><tr><td>ENV</td><td>构建过程中的环境变量</td></tr><tr><td>ADD</td><td>将宿主机文件拷贝进镜像内并解压缩</td></tr><tr><td>COPY</td><td>拷贝文件到镜像中</td></tr><tr><td>VOLUME</td><td>容器数据卷，数据保存和持久化</td></tr><tr><td>CMD</td><td>指定容器需要运行的命令，多个命令出现时只执行最后一个CMD命令</td></tr><tr><td>ENTRYPOINT</td><td>指定容器需要运行的命令</td></tr><tr><td>ONBUILD</td><td>当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像内触发</td></tr></tbody></table><h4 id="4、案例解析"><a href="#4、案例解析" class="headerlink" title="4、案例解析"></a>4、案例解析</h4><ul><li>以官方centos7镜像为例</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FROM scratch</span><br><span class="line">ADD centos-7-x86_64-docker.tar.xz /</span><br><span class="line"></span><br><span class="line">LABEL org.label-schema.schema-version="1.0" \</span><br><span class="line">    org.label-schema.name="CentOS Base Image" \</span><br><span class="line">    org.label-schema.vendor="CentOS" \</span><br><span class="line">    org.label-schema.license="GPLv2" \</span><br><span class="line">    org.label-schema.build-date="20191001"</span><br><span class="line"></span><br><span class="line">CMD ["/bin/bash"]</span><br></pre></td></tr></table></figure><blockquote><p>官方仓库里的centos为精简压缩版，我们可centos添加额外功能，例如：netstat查看所有端口。</p><p>尝试编写Dockerfile来实现这一功能</p></blockquote><p>任意目录下新建DockerFile空文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch DockerFile</span><br><span class="line">vi DockerFile</span><br></pre></td></tr></table></figure><p>写入可执行文本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM centos</span><br><span class="line">ENV mypath /home</span><br><span class="line">WORKDIR $mypath</span><br><span class="line">RUN yum -y install net-tools &amp;&amp; touch 1.txt</span><br><span class="line">EXPOSE 80</span><br><span class="line">CMD /bin/bash</span><br></pre></td></tr></table></figure><p>docker build执行DockerFile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t centos:1.1 -f DockerFile .</span><br></pre></td></tr></table></figure><ul><li><p>-t  指定镜像的名字。[name:版本 =&gt; centos:1.1]</p></li><li><p>-f  显示指定构建镜像的 Dockerfile 文件（Dockerfile 可不在当前路径下）。如果不使用 -f，则默认将上下文路径下的名为 Dockerfile 的文件认为是构建镜像的 “Dockerfile” </p></li><li><p>.  这个表示打包的上下文（其实就是Dockerfile所在目录）是在当前目录。指定构建镜像的上下文的路径，构建镜像的过程中，可以且只可以引用上下文中的任何文件 </p></li></ul><blockquote><p>docker build 官方语法 “docker build [OPTIONS] PATH | URL | -”。</p><p>更多详情请参考：<a href="https://docs.docker.com/engine/reference/commandline/build/" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/commandline/build/</a></p></blockquote><p>查看是否安装了netstat</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -t -i -d centos /bin/bash</span><br><span class="line">docker exec -it 容器id bash</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django-Urls-路由层</title>
      <link href="/2031/06/11/Django-Urls-%E8%B7%AF%E7%94%B1%E5%B1%82/"/>
      <url>/2031/06/11/Django-Urls-%E8%B7%AF%E7%94%B1%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h4 id="路由层"><a href="#路由层" class="headerlink" title="路由层"></a>路由层</h4><blockquote><p>路由是Web服务的入口，就好像办事大厅有各个服务窗口一样</p></blockquote><a id="more"></a><blockquote><p>Django奉行DRY主义，提倡使用简洁、优雅的URL：</p><p> 可以不用<code>.html</code>、<code>.php</code>或<code>.cgi</code>之类后缀</p><p> 尽量不要单独使用无序随机数字这样无意义的东西</p><p> 让你随心所欲设计你的URL，不受框架束缚</p></blockquote><h5 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h5><h6 id="urlpatterns"><a href="#urlpatterns" class="headerlink" title="urlpatterns"></a>urlpatterns</h6><blockquote><p>urlpatterns是路由文件中的一个全局变量，用来存放路由及视图函数的映射关系</p><p>用户发起的请求<code>URL</code>都会首先进入主控制目录下的这个<code>urls.py</code>文件中进行查找匹配</p></blockquote><ol><li>首先找到<code>urls.py</code>下的<code>urlpatterns</code>全局变量，这是一个路由规则实例的列表数据。</li><li>按照先后定义顺序，进行路由匹配。</li><li>找到第一个匹配项时停止匹配，执行匹配到的视图函数。</li><li>遍历完全，未发现匹配，<code>django</code>进行异常处理</li></ol><blockquote><p>其中<code>urlpatterns</code>中的每一个路由映射规则可以由<code>path</code>或<code>re_path</code>进行构造</p></blockquote><blockquote><p><strong>注意</strong>：<code>Django</code>的路由不考虑<code>HTTP</code>请求方式，仅根据URL进行路由；即，只要<code>URL</code>相同，无论<code>POST</code>、<code>GET</code>等哪种请求方式都指向同一个操作函数</p></blockquote><h6 id="path"><a href="#path" class="headerlink" title="path"></a>path</h6><ul><li><p><code>path(regex, view, kwargs=None, name=None)</code></p><blockquote><p><code>regex</code>：一个匹配对应url地址的规则字符串。</p><p><code>view</code>：路由对应的视图函数，并且会自动封装HttpRequest作为第一个参数给这个视图函</p><p><code>kwargs</code>：视图函数的关键字参数。</p><p><code>name</code>：该路由的全局命名，可以让我们方便的在django项目中任意部分显示的使用，相当于为<code>url</code>取变量名，接下来全局使用该命名值即可；当对应<code>url</code>路由改变之后，结合路由反向解析使用的地方不需要更改路由</p><p>此外，<code>django</code>还提供了一个兼容老版本<strong>url</strong>路由配置函数的<strong>re_path</strong>函数；<code>re_path</code>：第一个参数部分为一个正则匹配规则，其他与path同</p></blockquote></li></ul><h5 id="静态路由"><a href="#静态路由" class="headerlink" title="静态路由"></a>静态路由</h5><blockquote><p>静态路由用来映射对应视图函数，以下是一个简单的例子</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">'Hello Worlds!'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,re_path</span><br><span class="line"><span class="keyword">from</span> urlapp <span class="keyword">import</span> views</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">''</span>,views.index),</span><br><span class="line">    re_path(<span class="string">r"^"</span>,views.index),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h5 id="路由传参"><a href="#路由传参" class="headerlink" title="路由传参"></a>路由传参</h5><blockquote><p>有的时候，我们的路由设置不能一直维持一个一成不变的状态；</p><p>比如遇到一些内容翻页的场景，那么我们的连接可能是：<code>xx.com/airticle_list/1/</code>、<code>xx.com/airticle_list/2/</code></p><p>那么这样的路由其实对应的都应该是一个视图函数，用以展示页面内容，那么如何设计这样的路由，就要涉及到动态路由及路由传参</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request,x,y)</span>:</span></span><br><span class="line">    content = <span class="string">"x:%s\ny:%s"</span> % (x,y)  </span><br><span class="line"><span class="keyword">return</span> HttpResponse(content)</span><br></pre></td></tr></table></figure><blockquote><p>定义如上函数，将会接收连接中的后两部份<code>path</code>值作为参数，分别依次给到<code>x</code>和<code>y</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,re_path</span><br><span class="line"><span class="keyword">from</span> urlapp <span class="keyword">import</span> views</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'&lt;int:x&gt;/&lt;str:y&gt;/'</span>,views.index),</span><br><span class="line">    <span class="comment">#指明类型</span></span><br><span class="line">    path(<span class="string">"&lt;x&gt;/&lt;y&gt;/"</span>,views.index)</span><br><span class="line">    <span class="comment">#不指明类型</span></span><br><span class="line">    re_path(<span class="string">r"^(?P&lt;x&gt;\d+)/(?P&lt;y&gt;[a-zA-Z]+)/$"</span>),</span><br><span class="line">    <span class="comment"># (?P&lt;name&gt;pattern) 正则分组</span></span><br><span class="line">    re_path(<span class="string">r"^(\d+)/([a-zA-Z]+)/$"</span>),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>路由通过尖括号进行分组匹配，使用int以及str内置转换器将连接对应部分的值进行转换；并将匹配到的结果传递到视图函数对应的参数位置上；</p><p>访问：<code>http://127.0.0.1:8000/1/abc/</code></p><p>其中<code>1</code>将作为x的参数值，<code>abc</code>将作为y的参数</p><p>但如果访问连接是：<code>http://127.0.0.1:8000/abc/abc/</code>，这会匹配到第二个路由，第二个路由没有对传递参数的类型进行限定</p></blockquote><ul><li>内置Path转换器：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">str：匹配除了路径分隔符（`/`）之外的非空字符串，这是默认的形式</span><br><span class="line">int：匹配正整数，包含<span class="number">0</span></span><br><span class="line">slug：匹配字母、数字以及横杠、下划线组成的字符串</span><br><span class="line">uuid：匹配格式化的uuid，如 <span class="number">075194</span>d3<span class="number">-6885</span><span class="number">-417</span>e-a8a8<span class="number">-6</span>c931e272f00</span><br><span class="line">path：匹配任何非空字符串，包含了路径分隔符</span><br></pre></td></tr></table></figure><h6 id="自定义转换器"><a href="#自定义转换器" class="headerlink" title="自定义转换器"></a>自定义转换器</h6><blockquote><p>除了以上<code>django</code>所提供的path转换器，如果还觉得无法实现我们想要的功能，我们可以通过编写一个类进行自定义<code>path</code>转换器</p></blockquote><ol><li><p>定义转换器类，类名随意</p></li><li><p>定义类中必须属性</p><blockquote><p><code>regex</code>：一个字符串形式的正则表达式，也是对应的路由规则</p><p><code>to_python(self, value)</code>：用于将匹配到的路由字符串转换为<code>Python</code>中的数据类型，并传递给视图函数，<strong>如果转换失败，必须抛出ValueError</strong>，路由映射视图函数时使用</p><p><code>to_url(self, value)</code>：将<code>Python</code>数据类型转换为一段url的方法，<code>to_python</code>方法的反向操作，反向解析时使用</p></blockquote></li><li><p>通过django.urls模块中的register_converter函数进行注册</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">函数第一个参数为转换器类</span><br><span class="line">函数第二个参数为转换器别名</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>以下定义一个路由参数只能是三位字符的路由规则</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将转换器类定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreeChar</span>:</span></span><br><span class="line">    regex = <span class="string">"[a-zA-Z]&#123;3&#125;"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_python</span><span class="params">(self,value)</span>:</span></span><br><span class="line">        print(<span class="string">"to_python"</span>)</span><br><span class="line">        <span class="keyword">return</span> str(value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_url</span><span class="params">(self,value)</span>:</span></span><br><span class="line">        <span class="comment"># 当通过反向路由解析时，将会调用该函数</span></span><br><span class="line">        print(<span class="string">'to_url'</span>)</span><br><span class="line">        <span class="keyword">return</span> str(value)[:<span class="number">3</span>] </span><br><span class="line">    <span class="comment">#此处切片操作是为了当反向路由解析传参字符串长于3时，可以将其截断，符合转换器正则规则</span></span><br><span class="line"><span class="comment">#注册转换器</span></span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> register_converter</span><br><span class="line">register_converter(ThreeChar,<span class="string">'tc'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'&lt;tc:x&gt;/&lt;tc:y&gt;/'</span>,views.index)</span><br><span class="line">]</span><br><span class="line"><span class="comment">#127.0.0.1:8000/aaa/bbb/</span></span><br></pre></td></tr></table></figure><blockquote><p>接下里，通过路由进行访问该视图映射时，一定是三个字符所组成的路由才可以，否则是访问不到的</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#urls.py</span></span><br><span class="line">app_name = <span class="string">"app"</span></span><br><span class="line">path(<span class="string">'&lt;tc:x&gt;/&lt;tc:y&gt;/'</span>,views.index, name=<span class="string">"threechr"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#views.py</span></span><br><span class="line"><span class="keyword">return</span> redirect(reverse(<span class="string">"app:threechr"</span>,args=(<span class="string">'aaaa'</span>,<span class="string">'bbbb'</span>)))</span><br><span class="line"><span class="comment">#此时会调用three路由规则中的tc转换器中的to_url反向合成路由，并切片只取参数前三位</span></span><br></pre></td></tr></table></figure><h5 id="路由分发"><a href="#路由分发" class="headerlink" title="路由分发"></a>路由分发</h5><blockquote><p>我们的路由编写都是在项目主要目录下的<code>urls.py</code>文件中，但是如果<code>app</code>有很多的话，这么多路由都写到一起，明显是一件很不方便管理的事情</p><p>其实在之前的练习中，我们使用的方式均是路由分发，每个子<code>app</code>都拥有自己独立的<code>urls.py</code>路由映射文件，而主控路由文件里只需要使用<code>include</code>函数导入子<code>app</code>下路由文件即可，这就是路由分发</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,include</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    path(<span class="string">''</span>,include(<span class="string">"urlapp.urls"</span>)) <span class="comment"># 使用include 实现路由分发，找到子app下的路由文件</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>路由分发为我们带来的好处有很多，可以让我们在多个<code>app</code>的项目中更加方便有效的管理每一个路由</p><p>并且也可以让我们的用户在访问时看到浏览器中的<code>URL</code>地址更加<strong>赏心悦目</strong></p></blockquote><h5 id="路由反向解析"><a href="#路由反向解析" class="headerlink" title="路由反向解析"></a>路由反向解析</h5><blockquote><p>到了这里，思考一下，之前我们已经设置过了很多路由；</p><p>但是现在会出现一个问题，比如我们把其中某个路由规则进行了修改，把<code>aaa</code>换成了<code>aba</code>，那么现在我们需要回到每一个使用到这个路由的地方进行同步修改，这显然非常麻烦的，如果修改的路由更多，这甚至是一个灾难</p></blockquote><blockquote><p><code>django</code>也为我们提供了一个解决办法，通过为路由映射使用<code>name</code>参数，来为每一个路由映射设置一个独立唯一的变量名</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">path(<span class="string">'left/&lt;str:x&gt;/'</span>,views.left, name=<span class="string">"left"</span>),</span><br><span class="line">path(<span class="string">'right/&lt;int:x&gt;/'</span>,views.right, name=<span class="string">"right"</span>),</span><br><span class="line"><span class="comment"># 通过正则命名分组方式</span></span><br><span class="line">re_path(<span class="string">r'^left/([a-zA-Z]+)/$'</span>,views.left,name=<span class="string">"left"</span>),</span><br><span class="line">re_path(<span class="string">r'^right/(?P&lt;x&gt;\d+)/$'</span>,views.right, name=<span class="string">"right"</span>)</span><br></pre></td></tr></table></figure><ul><li>两个视图函数对应如下：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">left</span><span class="params">(request,x)</span>:</span></span><br><span class="line">    <span class="comment"># x: str</span></span><br><span class="line">    content = &#123;</span><br><span class="line">        <span class="string">'message'</span>:x,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> render(request, <span class="string">"left.html"</span>, content)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">right</span><span class="params">(request,x)</span>:</span></span><br><span class="line">    <span class="comment"># x: int</span></span><br><span class="line">    content = &#123;</span><br><span class="line">        <span class="string">'message'</span>:x,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> render(request, <span class="string">"right.html"</span>,content)</span><br></pre></td></tr></table></figure><ul><li>两个HTML页面</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;p&gt;我是左页面&lt;/p&gt;</span><br><span class="line">&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;a href="&#123;% url 'right' 123 %&#125;"&gt;右页面&lt;/a&gt;</span><br><span class="line">&lt;!-- ------另一个页面------ --&gt;</span><br><span class="line">&lt;p&gt;我是右页面&lt;/p&gt;</span><br><span class="line">&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;a href="&#123;% url 'left' 'abc' %&#125;"&gt;右页面&lt;/a&gt;</span><br></pre></td></tr></table></figure><blockquote><p>在模板页面中，对于已命名路由可以通过 &#123;% url “name” “arg” %&#125;模板标签进行反向解析</p><p>参数以空格隔开，在标签后传入</p></blockquote><ul><li>视图函数反向解析</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> redirect(reverse(<span class="string">"left"</span>,args=(<span class="string">'aaa'</span>,) ))</span><br></pre></td></tr></table></figure><blockquote><p>在视图函数中需要使用到路由命名时，进行反向解析需要我们通过<code>django.shortcuts</code>模块下的<code>reverse</code>函数</p></blockquote><ul><li><code>reverse(viewname,args=None,kwargs=None)</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">参数介绍</span><br><span class="line">viewname：视图函数、命名路由映射、或视图函数路径的字符串</span><br><span class="line">args：元组形式路由传参。</span><br><span class="line">kwargs：字典形式路由传参</span><br></pre></td></tr></table></figure><h5 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h5><blockquote><p>如果想在多个<code>app</code>下使用相同的<code>name</code>路由命名，那么我们可以通过路由分发过程中的include函数来指定不同<code>app</code>所属的命名空间</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,include</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    path(<span class="string">'app1/'</span>,include((<span class="string">"app1.urls"</span>,<span class="string">'app1'</span>))),</span><br><span class="line">    <span class="comment">#直接传递一个元祖，元祖第一个值为分发路由地址，第二个值为命名空间</span></span><br><span class="line">    path(<span class="string">'app2/'</span>,include((<span class="string">"app2.urls"</span>,<span class="string">'app2'</span>)))</span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>当为每个<code>app</code>的路由分发映射设置了命名空间，接下来在模板页面以及视图函数对路由的反向解析将是如下所示的样子，路由解析前加冒号指明命名空间</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line"><span class="keyword">return</span> redirect(reverse(<span class="string">"app1:left"</span>))</span><br></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"&#123;% url 'app2:left' %&#125;"</span>&gt;</span>app2:left<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><h6 id="应用命名空间：app-name"><a href="#应用命名空间：app-name" class="headerlink" title="应用命名空间：app_name"></a>应用命名空间：app_name</h6><blockquote><p>使用<code>app_name</code>指明命名空间，在子<code>app</code>的<code>urls.py</code>文件下配置全局变量<code>app_name</code>，这个值是唯一的</p><p>在这个路由文件中定义的其他映射关系，将具有命名空间<code>app1</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">app_name = <span class="string">"app1"</span> <span class="comment"># 这个值应该是唯一的</span></span><br><span class="line">urlpatterns = [</span><br><span class="line">   ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h6 id="实例命名空间：namespace"><a href="#实例命名空间：namespace" class="headerlink" title="实例命名空间：namespace"></a>实例命名空间：namespace</h6><blockquote><p>当有多个子<code>app</code>同时引入同一个子路由映射文件，比如这样</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,include</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    path(<span class="string">'app1/'</span>,include(<span class="string">"app1.urls"</span>)),</span><br><span class="line">    path(<span class="string">'app2/'</span>,include(<span class="string">"app1.urls"</span>))</span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>这就会出现一个问题，不同的路由访问在做路由反向解析时，会造成混淆，</p><p>此时需要给每一个路由分发的规则设置<code>namespace</code>属性，为实例进行命名空间</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,include</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    path(<span class="string">'app1/'</span>,include(<span class="string">"app1.urls"</span>,namespace=<span class="string">"app1"</span>)),</span><br><span class="line">    path(<span class="string">'app2/'</span>,include(<span class="string">"app1.urls"</span>,namespace=<span class="string">"app2"</span>))</span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>这样做的好处，可以在不同路由导向同一<code>app</code>下时，为他们的不同命名空间；</p><p>虽然看起来到最后执行的视图函数功能是一样的，但可以分清楚究竟是哪个路由引起视图函数在工作</p><p>接下来视图及模板页面中使用<code>namespace</code>的值</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>我是左页面<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>路由参数: &#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"&#123;% url 'app1:right' 123 %&#125;"</span>&gt;</span>app1的右页面<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>我是右页面<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>路由参数: &#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"&#123;% url 'app1:left' 'abc' %&#125;"</span>&gt;</span>app1的左页面<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ----------------------------------------- --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>我是左页面<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>路由参数: &#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"&#123;% url 'app2:right' 123 %&#125;"</span>&gt;</span>app2的右页面<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>我是右页面<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>路由参数: &#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"&#123;% url 'app2:left' 'abc' %&#125;"</span>&gt;</span>app2的左页面<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python配置环境变量</title>
      <link href="/2031/06/03/python%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"/>
      <url>/2031/06/03/python%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="Windows-配置python的环境变量"><a href="#Windows-配置python的环境变量" class="headerlink" title="Windows 配置python的环境变量"></a>Windows 配置python的环境变量</h2><ul><li>在Windos中安装Python2时是不会自动在计算机中配置环境变量的，导致有些初学者在CMD中通过输入 “python”没有出现预期结果。在这里就教大家如何配置Python的环境变量<a id="more"></a><h4 id="下载安装包地址"><a href="#下载安装包地址" class="headerlink" title="下载安装包地址"></a>下载安装包地址</h4><blockquote><p><a href="https://www.python.org/downloads/" target="_blank" rel="noopener">python官网下载环境地址</a><br>首先第一步我们可以通过文件资源管理器中，找到此电脑，随即右键点击选择“属性”，当然了，如果您的桌面上有“此电脑”快捷图标，也可以直接在桌面执行相同操作，之后便会弹出如图所示的“系统”窗口，接下来在左边选项卡中选择高级系统设置<br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/1.jpg" alt="1-1" title="本博客的主人最帅"><br>点击了高级系统设置之后，便会显示“系统属性”窗口，在该窗口的右下角便是”环境变量“选项。点击进入环境变量的配置窗口，如下图所示。<br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/2.jpg" alt="1-1" title="本博客的主人最帅"><br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/3.jpg" alt="1-1" title="本博客的主人最帅"><br>接下来便是对环境变量的配置了。先在系统变量中找到“Path”一项，选中后点击编辑，出现接下来的“编辑环境变量”窗口。这个窗口中显示的便是计算机中已经配置好的环境变量，在此为了不破坏掉其他的变量，请不要对其他的内容做任何的操作，点击”新建”即可。<br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/4.jpg" alt="1-1" title="本博客的主人最帅"><br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/6.jpg" alt="1-1" title="本博客的主人最帅"><br>点击“新建”后窗口中会自动添加一项空白待填写的输入框，在其中输入Python的根目录即可。如图所示。接下来确定保存。这个时候再WIN+R -&gt; cmd打开命令窗口，输入“python“ ，确认环境变量的配置成功。以上便是Win10如何配置Python环境变量。<br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/7.jpg" alt="1-1" title="本博客的主人最帅"><br><img src="/images/Win10%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F1_files/8.jpg" alt="1-1" title="本博客的主人最帅"><br>这就ok啦！</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> python基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>虚拟化、云计算概念</title>
      <link href="/2030/12/30/%E8%99%9A%E6%8B%9F%E5%8C%96%E3%80%81%E4%BA%91%E8%AE%A1%E7%AE%97%E6%A6%82%E5%BF%B5/"/>
      <url>/2030/12/30/%E8%99%9A%E6%8B%9F%E5%8C%96%E3%80%81%E4%BA%91%E8%AE%A1%E7%AE%97%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h3 id="虚拟化、云计算概念："><a href="#虚拟化、云计算概念：" class="headerlink" title="虚拟化、云计算概念："></a>虚拟化、云计算概念：</h3><p>美国环境保护署（EPA）报告的一组有趣的统计数据。</p><a id="more"></a><p>EPA研究服务器和数据中心的能源效率时发现，实际上服务器只有5%的时间在工作。在其他时间，服务器都处于 “休眠” 状态。就是说只有5%的消耗属于服务性能的消耗，其他都属于自己的无用消耗。</p><p>####什么是虚拟化：</p><p>虚拟化是指通过虚拟化技术奖一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间运行而互不影响，从而显著提高计算机的工作效率。</p><p>虚拟化使用软件的方法重新定义划分IT资源，可以实现IT资源的鼎泰分配、灵活调度、跨域共享，提高IT资源利用率，使IT资源能够真正成为社会基础设施，服务于各行各业中灵活多变的应用需求。</p><h4 id="虚拟化技术的应用价值："><a href="#虚拟化技术的应用价值：" class="headerlink" title="虚拟化技术的应用价值："></a>虚拟化技术的应用价值：</h4><p><strong>虚拟化前</strong></p><p><img src="C:%5CUsers%5Clenovo%5CDesktop%5C1576409487(1).png" alt="1576409487(1)"></p><ul><li><p><strong>资源浪费</strong></p><p>系统资源的利用率不高，</p><p>有的服务器长期空闲，</p><p>有的服务器超负荷为运转</p></li><li><p><strong>管理难度大</strong>（设备多）</p><p>服务器、路由、防火墙等设备数量众多，管理难度大。</p></li><li><p><strong>重复劳动</strong></p><p>经常性的重装、重做系统，调试网络设备等</p></li><li><p><strong>参数配置繁琐</strong></p><p>调整单台服务器CPU内存、硬盘大小等流程繁琐</p></li><li><p><strong>安全性差</strong></p><p>每台主机一个独立的操作系统，当安装一个完整的LAMP环境时，apache和mysql的资源是共享的，会造成安全性的问题。当Apache爆发漏洞时，可能会导致mysql的数据泄露。</p></li></ul><p><strong>虚拟化后：</strong></p><ul><li><p><strong>高利用率</strong></p><p>将分散、独立的服务器资源整合成虚拟资源池后，资源利用率大大提高</p></li><li><p><strong>自由配置</strong></p><p>在资源池范围内，可以自行添加虚拟机，更改虚拟机内存、存储空间等参数</p></li><li><p><strong>统一管理</strong></p><p>通过虚拟化平台能够清晰的查看服务器运行情况、硬件健康状况等信息</p></li><li><p><strong>更稳定</strong></p><p>虚拟化本身就是一个安全技术，通过虚拟化技术手段，提高系统稳定性，保证数据安全</p></li></ul><h4 id="虚拟化过程："><a href="#虚拟化过程：" class="headerlink" title="虚拟化过程："></a>虚拟化过程：</h4><p>给每个服务器上装一个(VMware)虚拟卡，通过虚拟化软件把孤立的、分散的服务器资源连接在一起，形成一个虚拟化资源池，将资源集中起来，然后相对的虚拟出多台服务器，通过虚拟化软件将虚拟化任务自动的分配在多台服务器上</p><p><img src="C:%5CUsers%5Clenovo%5CDesktop%5C1576411355(1).png" alt="1576411355(1)"></p><h4 id="虚拟化技术的分类："><a href="#虚拟化技术的分类：" class="headerlink" title="虚拟化技术的分类："></a>虚拟化技术的分类：</h4><ul><li><p>全虚拟化技术</p><p>完全虚拟化技术又叫硬件辅助虚拟化技术，最初所使用的的虚拟化技术就是全虚拟化技术，它在虚拟机（VM）和硬件之间加了一个软件层——Hyperyisor，或者叫做虚拟机监控器（VMM）</p><ul><li>hypervisor（虚拟机软件层/虚拟机监控机）</li></ul><p><img src="C:%5CUsers%5Clenovo%5CDesktop%5C1576467239(1).png" alt="1576467239(1)"></p></li><li><p>半虚拟化技术/准虚拟化技术（使用比较少）</p><p>半虚拟化技术，也叫准虚拟化技术。它就是在全虚拟化的基础上，把客户操作系统进行了修改，增加了一个专门的API，这个API可以将客户操作系统发出的指令进行最优化，即不需要Hypervisor耗费一定的资源进行翻译操作，因此Hypervisor的工作负担变得非常的小，因此整体的性能也有很大的提高。</p></li></ul><p><img src="C:%5CUsers%5Clenovo%5CDesktop%5C1576467741(1).png" alt="1576467741(1)"></p><h4 id="openstack云计算概念："><a href="#openstack云计算概念：" class="headerlink" title="openstack云计算概念："></a>openstack云计算概念：</h4><p><strong>云计算</strong>就是通过网络访问服务的一种模式。</p><p><strong>“云计算”</strong>可以理解为：通过互联网可以使用足够强大的计算机为用户提供的服务，这种服务的使用像可以统一的单位来描述。</p><h4 id="虚拟化和云计算比较"><a href="#虚拟化和云计算比较" class="headerlink" title="虚拟化和云计算比较"></a>虚拟化和云计算比较</h4><p><strong>虚拟化：</strong> 是一种技术存在，从1个物理硬件系统创建多个模拟环境</p><p><strong>云计算：</strong> 是一种服务模式存在，汇聚并自动化分配虚拟资源以供按需使用</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django初识</title>
      <link href="/2030/11/11/Django%E5%88%9D%E8%AF%86/"/>
      <url>/2030/11/11/Django%E5%88%9D%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h4 id="开始玩耍Django"><a href="#开始玩耍Django" class="headerlink" title="开始玩耍Django"></a>开始玩耍Django</h4><blockquote><p><em>Django</em>是一个开放源代码的<code>Web</code>应用框架，由<code>Python</code>写成。采用了<code>MVT</code>的框架模式；最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的，即是<code>CMS</code>（内容管理系统）软件</p><p>框架是以比利时的吉普赛爵士吉他手<code>Django Reinhardt</code>来命名的</p></blockquote><a id="more"></a><h5 id="django安装"><a href="#django安装" class="headerlink" title="django安装"></a>django安装</h5><blockquote><p><code>pip install django==2.0.4</code>(版本号)</p><p><code>pip install django</code>默认安装最新版本</p></blockquote><h5 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h5><blockquote><p><code>django-admin startproject myproject</code></p></blockquote><h5 id="开启开发服务器"><a href="#开启开发服务器" class="headerlink" title="开启开发服务器"></a>开启开发服务器</h5><blockquote><p><code>cd myproject</code>：进入项目目录</p><p><code>python manage.py runserver</code>：开启服务</p><p><code>python manage.py runserver 7000</code>：改变服务监听端口</p><p><code>python manage.py runserver 0:8000</code>：改变服务监听IP:端口</p></blockquote><h5 id="项目文件夹"><a href="#项目文件夹" class="headerlink" title="项目文件夹"></a>项目文件夹</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">manage.py：用来管理当前项目的一个命令行工具</span><br><span class="line">myproject/： 项目主文件夹</span><br><span class="line">myproject/__init__.py：空文件，用来指明当前的myproject为一个可导入的模块包</span><br><span class="line">myproject/settings.py：项目主要配置文件</span><br><span class="line">myproject/urls.py：项目主要路由配置文件</span><br><span class="line">myproject/wsgi.py：项目部署WSGI并发服务器时所需要的配置文件</span><br></pre></td></tr></table></figure><h5 id="Settings-py"><a href="#Settings-py" class="headerlink" title="Settings.py"></a>Settings.py</h5><blockquote><p>该文件是整个项目的主控文件，其中相关配置选项如下</p><p><code>https://docs.djangoproject.com/zh-hans/2.1/ref/settings/</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">- BASE_DIR: 当前项目工作目录，用来在每一次开启项目时动态找到相关资源路径</span><br><span class="line">- SECRET_KEY: 加密的hash值以及保护某些签名数据的关键密钥</span><br><span class="line">- DEBUG: 调试模式</span><br><span class="line">- ALLOWED_HOSTS: 有哪些主机或域名可以访问当前django站点，如设置为*代表全部可访问。</span><br><span class="line">- INSTALL_APPS: django项目中所有使用的应用名称，自创建子应用也要加到这里，不然ORM数据库无法被识别到！</span><br><span class="line">- MIDDLEWARE: django中间件，用来在request或reponse过程中添加功能，比如确保安全性，传输保存Session等</span><br><span class="line">- SecurityMiddleware: xss脚本过滤，一些安全设置</span><br><span class="line">- SessionMiddleware: session支持中间件，在每次用户访问django项目时，添加session对每一个浏览器</span><br><span class="line">- CommonMiddleware: 通用组件，比如为路由添加末尾斜杠</span><br><span class="line">- CsrfViewMiddleware: 防跨站请求伪造令牌，为客户端添加csrf_token密钥，在表单提交时需提交该值</span><br><span class="line">- AuthenticationMiddleware: admin用户组件，每个request对象都会被添加admin下的user属性</span><br><span class="line">- MessageMiddleware: 消息中间件 展示一些后台消息给前端</span><br><span class="line">- XFrameOptionsMiddleware: 防止欺骗点击攻击出现；自身页面被嵌入到他人页面中，点击欺骗</span><br><span class="line">- ROOT_URLCONF: 主路由配置文件，字符串填写url.py文件路径</span><br><span class="line">- TEMPLATES: 模板文件配置项</span><br><span class="line">- WSGI_APPLICATION: WSGI服务器配置项，找到当前django下的wsgi引入APP文件</span><br><span class="line">- DATABASES: 数据库配置项，默认使用SQLite3，一个本地文件数据库</span><br><span class="line">- AUTH_PASSWORD_VALIDATORS: 检查用户密码强度的验证程序列表，不过是针对admin界面下的用户，而非自定义</span><br><span class="line">- LANGUAGE_CODE: django所使用语言文件</span><br><span class="line">- TIME_ZONE: django所使用时区</span><br><span class="line">- USE_I18N: 国际化支持 <span class="number">18</span>表示Internationalization这个单词首字母I和结尾字母N之间的字母有<span class="number">18</span>个</span><br><span class="line">- USE_L10N: 是localization的缩写形式，意即在l和n之间有<span class="number">10</span>个字母</span><br><span class="line">- USE_TZ:开启了Time Zone功能，则所有的存储和内部处理，包括<span class="keyword">print</span>显示的时间将是是UTC时间格式</span><br><span class="line">- STATIC_URL: URL访问静态资源时的路径</span><br></pre></td></tr></table></figure><h4 id="来搞个Hello-World"><a href="#来搞个Hello-World" class="headerlink" title="来搞个Hello World"></a>来搞个Hello World</h4><h5 id="django创建子应用"><a href="#django创建子应用" class="headerlink" title="django创建子应用"></a>django创建子应用</h5><blockquote><p>项目和应用有啥区别？</p><p>应用是一个专门做某件事的网络应用程序：比如博客系统，或者公共记录的数据库，或者简单的投票程序</p><p>项目则是一个网站使用的配置和应用的集合。项目可以包含很多个<code>app</code>应用，应用可以被很多个项目使用</p></blockquote><ul><li><p><code>python manage.py startapp myapp</code></p><blockquote><p>创建子应用</p></blockquote></li></ul><h5 id="app目录"><a href="#app目录" class="headerlink" title="app目录"></a>app目录</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- admin.py: app在admin注册展示时需要的文件</span><br><span class="line">- views.py: app的功能视图函数文件</span><br><span class="line">- models.py: app需要使用数据库时的文件</span><br><span class="line">- urls.py: 当使用include路由分发时，每个app应该有他自己的子路由文件，这个是默认没有创建好的</span><br></pre></td></tr></table></figure><h5 id="视图函数"><a href="#视图函数" class="headerlink" title="视图函数"></a>视图函数</h5><blockquote><p>打开<code>app</code>下的<code>views.py</code>文件</p><p><code>Web</code>访问起始就是通过一个<code>URL</code>连接地址访问到服务器上的一个函数</p><p>在<code>views.py</code>中我们通过编写函数的形式，接收用户请求的<code>request</code>并返回一个<code>response</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每一个视图函数都需要有一个必须参数 request,用来接收用户访问时的请求内容</span></span><br><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">"&lt;h1&gt;Hello world&lt;/h1&gt;"</span>)</span><br></pre></td></tr></table></figure><ul><li><code>HttpResponse</code>函数用来向用户返回一个字符串</li></ul><h5 id="路由配置"><a href="#路由配置" class="headerlink" title="路由配置"></a>路由配置</h5><blockquote><p>创建好了一个可以在请求时返回<code>H1</code>标签的视图函数，但是现在通过浏览器还是访问不到</p><p>需要我们为这个<code>app</code>下的函数进行路由配置</p></blockquote><blockquote><p>第一种简单的路由配置，直接在主控路由文件下，找到这个视图函数</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myproject/urls.py</span></span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">from</span> myapp <span class="keyword">import</span> views</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls), <span class="comment">#admin控制界面路由</span></span><br><span class="line">    path(<span class="string">''</span>,views.index) </span><br><span class="line">    <span class="comment">#path函数第一个参数为访问地址，空字符串代表：当用户直接访问首页时</span></span><br><span class="line">    <span class="comment">#第二个参数代表访问该地址时对应的视图函数，我们引入了app下的views中的index视图函数</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li>接下来访问<code>127.0.0.1:8000</code>，那么你会看到一个非常大的<code>Hello world</code></li></ul><blockquote><p>以上将视图函数的查找直接写到主控路由并不是最好的办法</p><p>我们的项目通常会有非常多的路由配置项，如果都堆到这个文件中肯定是非常乱的，难以维护</p></blockquote><ul><li>我们可以在对应<code>app</code>下创建一个子路由控制文件，并在其中设置视图的路由配置</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myapp/urls.py</span></span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> views</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">""</span>,views.index)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><blockquote><p>现在虽然配置了<code>app</code>下的路由文件，但是访问时，是看不到对应视图的结果</p><p>这是因为默认的<code>url</code>查找动作将会从主控路由文件开始，我们还需要在主控路由文件下进行路由分发设置</p><p>让主控路由可以找到子<code>app</code>下的路由映射文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myproject/urls.py</span></span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path,include</span><br><span class="line"><span class="keyword">from</span> myapp <span class="keyword">import</span> views</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    <span class="comment">#path('',views.index)</span></span><br><span class="line">    path(<span class="string">''</span>,include(<span class="string">"myapp.urls"</span>)),</span><br><span class="line">    <span class="comment"># 函数 include() 允许引用其它 URLconfs</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li>接下来再次尝试，在浏览器中访问主机域名；如果可以看到的话，恭喜你，效果已经很棒了！</li></ul><h6 id="路由查找流程"><a href="#路由查找流程" class="headerlink" title="路由查找流程"></a>路由查找流程</h6><ol><li>查找主控路由文件下的<code>urlpatterns</code>全局变量，这是一个序列数据类型，其中每一个元素都是对应的一个路由匹配规则</li><li>如果在规则中查找到符合匹配规则的，则执行其中的对应执行函数</li><li>如果对应的不是一个执行函数，而是一个<code>include</code>路由包含，那么截断与此项匹配的<code>URL</code>的部分，并将剩余的路由字符串发送到<code>include</code>所包含的子路由文件中以供进一步处理</li><li>如果没有匹配到的任何结果，<code>django</code>默认抛出<code>Page not found (404)</code></li></ol><blockquote><p><strong>注意</strong>：<code>Django</code>的路由不考虑HTTP请求方式，仅根据<code>URL</code>进行路由，即，只要<code>URL</code>相同，无论<code>POST</code>、<code>GET</code>等哪种请求方式都指向同一个操作函数</p></blockquote><h6 id="path"><a href="#path" class="headerlink" title="path"></a>path</h6><blockquote><p><code>path</code>函数用来处理一个路由对应的视图映射</p></blockquote><ul><li><p><code>path(route, view, name)</code></p><blockquote><p><code>route</code>： 匹配规则，是一个字符串</p><p><code>view</code>：对应的视图函数</p><p><code>name</code>：未来我们会用到他，用来为匹配规则命名，这样方便日后修改路由而不影响全局下的路由使用</p></blockquote></li></ul><h6 id="re-path"><a href="#re-path" class="headerlink" title="re_path"></a>re_path</h6><blockquote><p><code>re_path</code>是<code>path</code>函数的加强版</p><p>可以在<code>re_path</code>函数的第一个位置的字符串参数，是一个标准<code>Python</code>正则表达式，其余参数与<code>path</code>相同</p></blockquote><blockquote><p><strong>注意</strong>：匹配模式的最开头不需要添加<code>/</code>，因为默认情况下，每个<code>url</code>都带一个最前面的<code>/</code>，既然大家都有的部分，就不用浪费时间特别写一个了，所以一定要注意在写路由映射关系时，记得加末尾的<code>/</code></p></blockquote><h5 id="模板页面"><a href="#模板页面" class="headerlink" title="模板页面"></a>模板页面</h5><blockquote><p>返回一个字符串这肯定是不行的，太<code>low</code>了，也不好看，现在来返回一个正式的<code>HTML</code>页面</p><p>并在<code>HTML</code>页面中加入模板变量，由视图函数动态传递值；</p></blockquote><ul><li>配置<code>django</code>中模板页面的保存路径，在项目目录下的<code>settings.py</code>文件中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myproject/settings.py</span></span><br><span class="line">TEMPLATES = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'BACKEND'</span>: <span class="string">'django.template.backends.django.DjangoTemplates'</span>,</span><br><span class="line">        <span class="string">'DIRS'</span>: [os.path.join(BASE_DIR,<span class="string">'template'</span>)], <span class="comment"># 就是这一行 设置静态模板路径</span></span><br><span class="line">        <span class="string">'APP_DIRS'</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">'OPTIONS'</span>: &#123;</span><br><span class="line">            <span class="string">'context_processors'</span>: [</span><br><span class="line">                <span class="string">'django.template.context_processors.debug'</span>,</span><br><span class="line">                <span class="string">'django.template.context_processors.request'</span>,</span><br><span class="line">                <span class="string">'django.contrib.auth.context_processors.auth'</span>,</span><br><span class="line">                <span class="string">'django.contrib.messages.context_processors.messages'</span>,</span><br><span class="line">            ],</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li><code>创建template</code>目录并在其中创建<code>index.html</code>文件</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>hi<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>&#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>在<code>HTML</code>页面中，我们并没有明确指出<code>H1</code>标签的内容；通过一个``来等待接收视图函数传来的数据，在<code>HTML</code>页面中这样的变量也叫做<strong>模板变量</strong>，双大括号为使用语法</p></blockquote><ul><li>接下来修改之前的视图函数，由视图函数传递变量给到<code>HTML</code>页面</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myapp/views.py</span></span><br><span class="line"><span class="keyword">from</span> django.shortcuts <span class="keyword">import</span> render</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="comment">#return HttpResponse("&lt;h1&gt;Hello world&lt;/h1&gt;")</span></span><br><span class="line">    content = &#123;</span><br><span class="line">        <span class="string">"message"</span>:<span class="string">"你好，世界"</span> <span class="comment">#此处的key值message对应页面中我们写的&#123;&#123; message &#125;&#125;</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> render(request,<span class="string">'index.html'</span>,content)</span><br></pre></td></tr></table></figure><h6 id="render"><a href="#render" class="headerlink" title="render"></a>render</h6><blockquote><p>render函数用来返回一个模板页面，并将一个字典组合成的模板变量传递到模板页面上，完成页面的渲染</p></blockquote><ul><li><p><code>render(request, template_name, context=None)</code></p><blockquote><p>返回一个HTTP响应</p></blockquote><blockquote><p><code>request</code>： 固定接收<code>request</code>请求</p><p><code>template_name</code>： 为一个可以找到的模板页面</p><p><code>context</code>： 模板页面所需模板变量</p></blockquote></li></ul><h6 id="模板变量"><a href="#模板变量" class="headerlink" title="模板变量"></a>模板变量</h6><blockquote><p>在<code>django</code>中的<code>HTML</code>页面，不光可以编写原本的标签等内容，还可以像<code>Vue</code>一样在页面中使用双大括号，来提前定义一些模板变量，之后动态的渲染到<code>HTML</code>模板页面中</p></blockquote><blockquote><p>模板变量可以由后台视图函数构建一个<strong>字典数据类型</strong>传递，</p><p>字典的<code>key</code>是模板变量名，<code>value</code>值该模板变量对应的数据</p><p>当然，模板变量的内容远不止此，还会再后面继续为大家叙述</p></blockquote><h5 id="静态文件"><a href="#静态文件" class="headerlink" title="静态文件"></a>静态文件</h5><blockquote><p>虽然有了模板页面，可以来展示一些标签的效果，但是整个HTML还是感觉很丑陋</p><p>我们还要继续引入一些类似<code>css、img</code>这样的静态资源，来装饰我们的页面</p><p>在<code>django</code>中模板页面的静态资源使用，不能像之前写<code>HTML</code>代码直接引入</p><p>需要我们首先在项目中创建目录保存对应的静态资源，该目录名常为<code>static</code></p></blockquote><ul><li>在settings中配置静态文件保存目录，<strong>添加</strong>如下内容</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">STATICFILES_DIRS = (</span><br><span class="line">    os.path.join(BASE_DIR, <span class="string">'static'</span>),</span><br><span class="line">)</span><br><span class="line"><span class="comment"># STATICFILES_DIRS 该配置项用来告诉django在查找静态资源时，应该访问哪个目录</span></span><br></pre></td></tr></table></figure><ul><li>在项目中创建<code>static</code>目录，<code>static</code>目录下创建专门保存图片的<code>img</code>目录，在里面存一张图片<code>1.jpg</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#此时的目录结构</span></span><br><span class="line">myproject/</span><br><span class="line">myproject/</span><br><span class="line">myapp/</span><br><span class="line">template/</span><br><span class="line">static/</span><br><span class="line">img/</span><br><span class="line"><span class="number">1.j</span>pg</span><br></pre></td></tr></table></figure><ul><li>有了图片，接下来在模板页面中去引入并使用它，打开<code>index.html</code>进行修</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line">    &#123;% load staticfiles %&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>hi<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>&#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">'&#123;% static "img/1.jpg" %&#125;'</span> <span class="attr">alt</span>=<span class="string">"图片"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>这里用到了一个特殊语法：&#123;% tag %&#125;这个叫静态标签，静态标签不同于模板变量，静态标签经常用来加载数据，或创建逻辑，比如之后我们要学到的&#123;% if %&#125;，使用静态标签可以方便我们在模板页面上实现某些只有在后台代码中才可以实现的逻辑功能</p></blockquote><blockquote><p>在页面中要引入静态资源：图片，<code>CSS</code>，<code>JS</code>文件在引入时都需要通过&#123;% static “path” %&#125;来进行引入</p></blockquote><blockquote><p>最后，需要使用静态标签<code>static</code>前使用&#123;% load staticfiles %&#125;标签进行静态资源路径的加载</p></blockquote><h5 id="模型数据库"><a href="#模型数据库" class="headerlink" title="模型数据库"></a>模型数据库</h5><blockquote><p>有了以上内容的修饰，现在感觉还是缺少一些什么，我们在视图函数中为前端页面返回的是一个提前定义好的变量，这显然在真正开发中是很少出现的，我们的数据大都来自于数据库中，那么现在需要我们在项目中加入数据库，并且在视图函数中通过对数据库的访问来拿到数据</p></blockquote><ul><li>创建数据库，这里使用项目自带的<code>SQLite3</code>数据库，默认已经是配置好的，接下来需要我们进入到<code>app</code>下的<code>models.py</code>文件中，编写一个类，这个类就对应数据库中的一张表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myapp/models.py</span></span><br><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create your models here.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Weather</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    weather = models.CharField(max_length=<span class="number">100</span>,verbose_name=<span class="string">"天气"</span>)</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Meta</span>:</span></span><br><span class="line">        verbose_name_plural = <span class="string">"天气"</span></span><br><span class="line">        <span class="comment"># 设置当前表名的一个可读的性更好的名字</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.weather</span><br></pre></td></tr></table></figure><blockquote><p>在这里我们使用到了<code>django</code>的<code>orm</code>映射关系用来创建数据库表，继承自<code>django</code>的<code>models.Model</code>类，</p><p><strong>一个类用来表示一张表，类中的一个属性代表一个字段，</strong></p></blockquote><blockquote><p>这里我们定义了一个类型为<code>CharField</code>，长度为<code>100</code>的字段，用来存储天气</p><p><code>models.CharField(max_length=100,verbose_name=&quot;天气&quot;)</code></p></blockquote><hr><blockquote><p>下面的<code>class Meta</code>是模型类的元类，用来设置当前表的一些属性；</p><p>这里我们使用<code>verbose_name_plural</code>属性设置当前表在<code>admin</code>后台查看时的名字</p></blockquote><blockquote><p>在这里我们还定义了一个属于实例的函数<code>__str__</code>，用来描述当前数据在返回时的默认展示结果，为<code>weather</code>字段的值</p></blockquote><blockquote><p><code>django</code>在创建模型类对应的数据表时，默认使用 <code>应用名</code>加<code>下划线</code>加<code>模型类名</code>作为表的名字；比如当前<code>Weather</code>表名为：<code>myapp_Weather</code></p></blockquote><blockquote><p><code>orm</code>映射关系，是<code>django</code>与数据库之间的一个桥梁，可以使开发者不再关注如何去编写<code>SQL</code>语句，直接通过一套<code>ORM</code>所提供的<code>API</code>接口即可方便对各种数据库进行交互</p></blockquote><ul><li>当某个子应用<code>APP</code>涉及到了数据库的使用时，要记得在<code>settings</code>文件中进行配置</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myproject/settings.py</span></span><br><span class="line">INSTALLED_APPS = [</span><br><span class="line">    <span class="string">'django.contrib.admin'</span>,</span><br><span class="line">    <span class="string">'django.contrib.auth'</span>,</span><br><span class="line">    <span class="string">'django.contrib.contenttypes'</span>,</span><br><span class="line">    <span class="string">'django.contrib.sessions'</span>,</span><br><span class="line">    <span class="string">'django.contrib.messages'</span>,</span><br><span class="line">    <span class="string">'django.contrib.staticfiles'</span>,</span><br><span class="line">    <span class="string">'myapp'</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li>接下来通过<code>manage.py</code>命令行管理工具提供的两条，创建我们所需要的数据</li></ul><blockquote><p><strong>注意</strong>：默认<code>django</code>本身就已经需要一些数据的创建，所以我们在初次执行以下两条命令时可能会看到很多数据表和字段的创建，不要惊讶，这是正常的</p></blockquote><blockquote><p><code>python manage.py migrate</code>：根据数据库迁移文件生成对应<code>SQL</code>语句并执行</p><p>初次执行是为了先把默认django需要的数据库创建出来</p></blockquote><blockquote><p><code>python manage.py makemigrations</code>：创建数据库迁移文件</p><p>这次执行是为了创建APP中Weather模型类的迁移文件</p></blockquote><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; python manage.py migrate</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>将新添加的模型类迁移文件生成对应<code>SQL</code>，实际创建出对应的<code>Weather</code>表</p></blockquote><ul><li>如果提示结果正常，那么代表相应的数据表已经创建好了，接下来就需要我们去到<code>django</code>为我们提供的<code>admin</code>（数据库管理界面）来进行相关表的操作了！</li></ul><h5 id="admin控制台"><a href="#admin控制台" class="headerlink" title="admin控制台"></a>admin控制台</h5><blockquote><p><code>admin</code>控制台是<code>django</code>为我们提供的一个非常便捷的用来管理数据库的界面</p><p>在主控路由文件下，其实你已经看到了它对应的路由设置：<code>path(&#39;admin/&#39;, admin.site.urls),</code></p></blockquote><blockquote><p>进入<code>admin</code>界面，初次访问连接：<code>127.0.0.1/admin</code>，会提示我们输入账号密码，这是因为<code>django</code>的<code>admin</code>界面是需要一个超级管理员来登陆访问的，所以还需要我们创建对应的<code>admin</code>界面下的超级用户</p></blockquote><ul><li>创建<code>admin</code>超级用户，使用<code>manage.py</code>命令行工具执行如下命令</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py createsuperuser</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Username (leave blank to use <span class="string">'lienze'</span>): root</span><br><span class="line">Email address:</span><br><span class="line">Password:</span><br><span class="line">Password (again):</span><br><span class="line">This password <span class="keyword">is</span> too short. It must contain at least <span class="number">8</span> characters.</span><br><span class="line">This password <span class="keyword">is</span> too common.</span><br><span class="line">This password <span class="keyword">is</span> entirely numeric.</span><br><span class="line">Password:</span><br><span class="line">Password (again):</span><br><span class="line">This password <span class="keyword">is</span> too common.</span><br><span class="line">This password <span class="keyword">is</span> entirely numeric.</span><br><span class="line">Password:</span><br><span class="line">Password (again):</span><br><span class="line">Superuser created successfully.</span><br></pre></td></tr></table></figure><blockquote><p>以上是我们创建超级用户的过程，非常坎坷；</p><p>可以看到，在输入太短（不满足8位），或是只包含数字的简单密码，超级用户的创建都是被拒绝的</p><p>所以我们把用户账号创建为<code>root</code>，而密码创建为<code>a1234567</code>，</p></blockquote><ul><li>接下来开启测试服务器，并通过创建好的超级用户登陆访问，如果幸运的话，你已经可以看到后台的<code>admin</code>界面啦</li></ul><blockquote><p><code>admin</code>界面已经展示出了默认<code>django</code>所使用的两张表，用户表和组表，用来保存当前管理后台的用户以及对应权限分组，可以点入用户表查看其中我们刚创建的<code>root</code>。</p></blockquote><h5 id="admin注册表"><a href="#admin注册表" class="headerlink" title="admin注册表"></a>admin注册表</h5><blockquote><p>问题还是有的，虽然<code>admin</code>界面已经可以登入，但是为什么看不到刚才创建的<code>Weather</code>表呢</p><p>这是因为默认的表创建之后，还需要通过对应app下的<code>admin.py</code>文件进行<code>admin</code>后台注册，只有注册在这个文件中的模型类对应的表才可以在<code>admin</code>界面所看到</p></blockquote><ul><li>在app下的admin.py文件中进行模型类的注册</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myapp/admin.py</span></span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> myapp <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line">admin.site.register(models.Weather)</span><br><span class="line"><span class="comment">#使用register函数接收模型类作为参数即可完成注册</span></span><br></pre></td></tr></table></figure><blockquote><p>注册成功之后，在服务器，通过浏览器访问<code>admin</code>界面，就可以看到创建好的<code>Weather</code>表了</p></blockquote><ul><li>鼠标点击进去之后，就可以看到对应的表数据界面；右上角提供了可以添加功能的选项，试试给这个表来一些数据吧，这里我们添加了三条数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">阴天，晴天，打雷了</span><br></pre></td></tr></table></figure><h5 id="视图操作模型"><a href="#视图操作模型" class="headerlink" title="视图操作模型"></a>视图操作模型</h5><blockquote><p>最终我们希望可以在视图函数中通过<code>orm</code>接口来访问到表中的数据，那么来打开视图文件吧：<code>views.py</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#myapp/views.py</span></span><br><span class="line"><span class="keyword">from</span> django.shortcuts <span class="keyword">import</span> render</span><br><span class="line"><span class="keyword">from</span> myapp <span class="keyword">import</span> models</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    </span><br><span class="line">    weathers = models.Weather.objects.all()</span><br><span class="line">    content = &#123;</span><br><span class="line">        <span class="string">"weathers"</span>:weathers,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> render(request, <span class="string">'index.html'</span>, content)</span><br></pre></td></tr></table></figure><ul><li>光返回是不行的，虽然我们绑定到了模板版变量的字典中，但是还得修改一下对应的要渲染的<code>HTML</code>页面哦：</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line">    &#123;% load staticfiles %&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>hi<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    &#123;% for weather in weathers %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>&#123;&#123; weather &#125;&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    &#123;% empty %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>没有任何天气<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>模板标签&#123;% for xxx in xxxs %&#125;可以用来在模板页面出迭代访问取出每一个数据</p><p>具体对于不同序列数据的访问我们会在后面详细为大家介绍</p><p>&#123;% empty %&#125;标签用来判断当循环访问数据为空时要做的事情，最后循环标签要有&#123;% endfor %&#125;标签进行结束；因为<code>HTML</code>中并没有像<code>Python</code>缩进这样的方式来控制代码块。</p></blockquote><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><blockquote><p>至此，我们的<code>HELLO WORLD</code>项目已经涵盖了<code>django</code>框架中的大部分常用的组件；</p><p><strong>路由</strong>、<strong>视图</strong>、<strong>模板</strong>、<strong>静态</strong>、<strong>模型</strong>，<strong>admin</strong></p><p>那么其中每一部分都还有很多内容等着我们去了解！</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二进制转十进制，十进制转二进制</title>
      <link href="/2030/11/05/%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6%EF%BC%8C%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6/"/>
      <url>/2030/11/05/%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6%EF%BC%8C%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="二进制介绍"><a href="#二进制介绍" class="headerlink" title="二进制介绍"></a>二进制介绍</h2><blockquote><p>二进制是计算技术中广泛采用的一种数制。二进制数据是用0和1两个数码来表示的数。它的基数为，进位规则是“逢二进一”，借位规则是“借一当二”，由18世纪德国数理哲学大师莱布尼兹发现。当前的计算机系统使用的基本上是二进制系统，数据在计算机中主要是以补码的形式存储的。计算机中的二进制则是一个非常微小的开关，用“开”来表示1，“关”来表示0。<br>20世纪被称作第三次科技革命的重要标志之一的计算机的发明与应用，因为数字计算机只能识别和处理由‘0’.‘1’符号串组成的代码。其运算模式正是二进制。19世纪爱尔兰逻辑学家乔治布尔对逻辑命题的思考过程转化为对符号”0’’.’’1’’的某种代数演算，二进制是逢2进位的进位制。0、1是基本算符。因为它只使用0、1两个数字符号，非常简单方便，易于用电子方式实现。</p></blockquote><a id="more"></a><h2 id="十进制介绍"><a href="#十进制介绍" class="headerlink" title="十进制介绍"></a>十进制介绍</h2><blockquote><p>十进制：600，3/5，-7.99……看着这些耳熟能详的数字，你有没有想太多呢？其实这都是全世界通用的十进制，即1.满十进一，满二十进二，以此类推……2.按权展开，第一位权为10^0，第二位10^1……以此类推，第N位10^（N-1），该数的数值等于每位位的数值*该位对应的权值之和。</p></blockquote><h3 id="十进制转二进制"><a href="#十进制转二进制" class="headerlink" title="十进制转二进制"></a>十进制转二进制</h3><blockquote><p>十进制转二进制：十进制数转换为二进制数时，由于整数和小数的转换方法不同，所以先将十进制数的整数部分和小数部分分别转换后，再加以合并。<br>下面就是方法，挺简单的</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">用15除以2，商为7，余数为1，</span><br><span class="line">再用7除以2，商为3，余数为1，</span><br><span class="line">再用3除以2，商为1，余数为1，</span><br><span class="line">再用1除以2，商为0，余数为1，</span><br><span class="line">最后吧余数倒过来排列就为二进制的1111（即商为0时的1，商为1时的1，商为3时的1，商为7时的1）</span><br></pre></td></tr></table></figure><h3 id="二进制转十进制"><a href="#二进制转十进制" class="headerlink" title="二进制转十进制"></a>二进制转十进制</h3><blockquote><p>以二进制的1111转十进制为例：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">把二进制的1111看成是十进制的1111即1*10^3 + 1*10^2 + 1*10^1 + 1</span><br><span class="line">然后把10变成2，即1*2^3 + 1*2^2 + 1*2^1 + 1=15</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 进制转换 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix 监控系统</title>
      <link href="/2030/10/30/Zabbix%20%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"/>
      <url>/2030/10/30/Zabbix%20%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="Zabbix-监控系统"><a href="#Zabbix-监控系统" class="headerlink" title="Zabbix 监控系统"></a>Zabbix 监控系统</h2><h4 id="什么是监控系统？"><a href="#什么是监控系统？" class="headerlink" title="什么是监控系统？"></a>什么是监控系统？</h4><a id="more"></a><p>例如：开车时的行车记录仪、班级里面的监控摄像头、医院使用的血压监测仪等等</p><p>在IT领域中，监控系统就是<strong>监控系统资源以及性能的硬件或者软件</strong></p><p><strong>监控软件</strong></p><ol><li>单一监控程序<ol><li>windows系统的任务管理</li><li>linux系统中的top、vmstat、iostat</li></ol></li><li>分布式监控程序</li></ol><h4 id="为什么需要监控系统？"><a href="#为什么需要监控系统？" class="headerlink" title="为什么需要监控系统？"></a>为什么需要监控系统？</h4><p>为用户提供稳定、高效、安全的服务</p><p>但是像zabbix和open-falcon只能监控某些方面。而为了业务高效运行还需要和APM也就是应用性能监控、全局链路调用追踪等一起实现。而安全性需要安全团队和相关系统紧密结合才行</p><h4 id="监控系统都有哪些功能？"><a href="#监控系统都有哪些功能？" class="headerlink" title="监控系统都有哪些功能？"></a>监控系统都有哪些功能？</h4><ol><li><strong>数据收集.</strong></li><li><strong>数据展示</strong></li><li><strong>告警策略</strong></li><li><strong>告警发送</strong></li><li><strong>事件管理</strong></li><li><strong>报表管理.</strong></li><li><strong>认证权限.</strong></li></ol><h4 id="开源监控系统现状"><a href="#开源监控系统现状" class="headerlink" title="开源监控系统现状"></a>开源监控系统现状</h4><ol><li>Nagios.<ul><li>1999年发布的初始版本。它可以监控网络、主机等设备。支持丰富的监控插件。用户可以根据自己的实际环境定义监控</li></ul></li><li>Cacti.<ul><li>2001年发布的。是一套基于<code>SNMP</code>和<code>RRDTool</code>的网络流量监控分析的系统</li><li><strong>RRDTool</strong>: 用来处理时间序列数据的套件</li><li><strong>SNMP</strong>: 简单网络管理协议</li></ul></li><li>Ganglia</li><li>Zabbix</li><li>Prometheus</li><li>Falcon</li><li>Grafana<ul><li>Grafana是可以美观的展示和分析监控数据的工具，收集数据并支持告警等功能</li></ul></li><li>Zenoss</li><li>Graphite</li><li>Open-falcon …<ul><li>小米公司开源的，高可用、可扩扎的开源监控解决方案</li></ul></li></ol><h4 id="监控系统可以干什么？"><a href="#监控系统可以干什么？" class="headerlink" title="监控系统可以干什么？"></a>监控系统可以干什么？</h4><ol><li>KPI聚类</li><li>瓶颈分析</li><li>KPI异常检测、定位</li><li>故障预测</li><li>容量预估</li></ol><h4 id="Zabbix-简介"><a href="#Zabbix-简介" class="headerlink" title="Zabbix 简介"></a>Zabbix 简介</h4><blockquote><p>市场上还有一款叫做<code>open-falcon</code>和zabbix类似，而且市场上也是在广泛使用，都是属于<strong>分布式监控程序</strong></p></blockquote><blockquote><p><strong>zabbix</strong> 是一个基于web界面的提供分布式系统监控的企业级的开源解决方案。</p></blockquote><blockquote><p><strong>zabbix</strong> 能监视各种网络参数， 保证服务器系统的安全稳定的运行，并提供灵活的通知机制以让SA快速定位并解决存在的各种问题。</p></blockquote><h5 id="了解zabbix"><a href="#了解zabbix" class="headerlink" title="了解zabbix"></a>了解zabbix</h5><p>我们通过zabbix能够监控到哪些硬件资源呢？理论上说，只要是与我饿们的业务相关的硬件资源，又应该被监控。比如主机、交换机、路由器、UPS等等。但是，监控她们的额前提是能与他们进行通讯，那么问题来了，由于硬件不同，导致我们无法使用统一的方法去监控他们，这个时候就需要监控程序有一定的通用性，或者说，监控程序需要能够与多种硬件设备通讯，才能满足我们的监控需求。所以zabbix如果想要能够全面的监控这些对象，则需要能够通过各种方法与他们通讯。</p><h5 id="Zabbix-的优点"><a href="#Zabbix-的优点" class="headerlink" title="Zabbix 的优点"></a>Zabbix 的优点</h5><ol><li>支持自动发现服务器和网络设置</li><li>支持底层自动发现</li><li>分布式的监控体系和集中式的web管理</li><li>支持主动监控和被动监控模式</li><li>服务器支持多种操作系统：<ol><li>linux</li><li>solaris</li><li>HP-UX</li><li>AIX</li><li>FreeBSD</li><li>OpenBSD</li><li>MAC …</li></ol></li><li><code>Agent客户端</code>支持多种操作系统：<ol><li>linux</li><li>Solaris</li><li>HP-UX</li><li>AIX</li><li>FreeBSD</li><li>Windows …</li></ol></li><li>基于SNMP、IPMI接口方式也可以 监控Agent</li><li>安全的用户认证及权限配置</li><li>基于WEB的管理方法，支持自由的自定义事件和邮件发送</li><li>高水平的业务视图监控资源，支持日志审计、资产管理等功能</li><li>支持高水平API二次开发、脚本监控、自Key定义、自动化运维整合调用</li></ol><h5 id="Zabbix-监控组件及流程"><a href="#Zabbix-监控组件及流程" class="headerlink" title="Zabbix 监控组件及流程"></a>Zabbix 监控组件及流程</h5><p>zabbix 主要有三大组件组成，分别是</p><ol><li><p><strong>Zabbix server端</strong></p><ol><li><code>Zabbix WEB GUI</code></li><li><code>Zabbix Datebase</code></li><li><code>Zabbix Server</code></li></ol></li></ol><ol start="2"><li><p><strong>Zabbix Proxy端</strong></p></li><li><p><strong>Zabbix Agent端</strong></p></li></ol><h5 id="zabbix的好处："><a href="#zabbix的好处：" class="headerlink" title="zabbix的好处："></a>zabbix的好处：</h5><p>占用资源少、可以获取CPU、内存、网卡、磁盘、日志等信息。</p><p>对于无法安装客户端的设备，zabbix支持通过<code>SNMP</code>获取监控数据</p><p>zabbix支持通过<code>IPMI</code>(智能平台管理接口)获取硬件的温度、风扇、硬盘、电源等</p><p>#####zabbix监控系统的意义</p><p>通过这些监控系统我们可以了解设备的繁忙程度、是否有异常的进程占用资源</p><p>比较常见的是：通过传感器获取设备的监控信息</p><h5 id="Zabbix-能监控哪些硬件资源呢？"><a href="#Zabbix-能监控哪些硬件资源呢？" class="headerlink" title="Zabbix 能监控哪些硬件资源呢？"></a>Zabbix 能监控哪些硬件资源呢？</h5><blockquote><p>如果理论上说，只要与我们业务相关的硬件资源，都可以被监控。例如：主机、交换机、路由器等等。但是监控的前提是能与他们进行通讯</p></blockquote><h5 id="Zabbix-支持哪些通讯方式呢？"><a href="#Zabbix-支持哪些通讯方式呢？" class="headerlink" title="Zabbix 支持哪些通讯方式呢？"></a>Zabbix 支持哪些通讯方式呢？</h5><ol><li><strong>Agent</strong>：通过专用的代理程序进行监控，与常见的master/agent模型类似。如果被监控对象支持对应的agent，推荐首选这种方式</li><li><strong>ssh/tenet</strong>：通过远程控制协议进行通讯，比如ssh或telnet</li><li><strong>SNMP</strong>:通过SNMP协议与被监控对象进行通讯，<code>SNMP</code>协议全称 Simple Network Mnaagement Protocol,被译为“简单网络管理协议”，通常来说，我们无法在路由器、交换机这种硬件上安装agent，但是这些硬件往往都支持SNMP协议、SNMP是一种比较久远的、通行的协议，大部分网络设备都支持这种协议，其实SNMP协议的工作方式也可以理解为master/agent的工作方式，只不过实在这些设备中内置了SNMP的agent而已，所以大部分网络设备都支持这种协议</li><li><strong>IPMI</strong>：通过IPMI接口进行监控，我们可以通过标准的IPMI硬件接口，监控被监控对象的物理特征，比如电压、温度、风扇状态、电源状态等等</li><li><strong>JMX</strong>：通过JMX进行监控，JMX全称 Java Management Extensions ，也就是Java管理扩展，监控JVM虚拟机时，使用这种方法也是非常不错的选择</li></ol><h5 id="Zabbix-监控流程"><a href="#Zabbix-监控流程" class="headerlink" title="Zabbix 监控流程"></a>Zabbix 监控流程</h5><h6 id="zabbix-核心组件"><a href="#zabbix-核心组件" class="headerlink" title="zabbix 核心组件"></a>zabbix 核心组件</h6><ul><li><strong>zabbix agent</strong>：部署在被监控主机上，负责被监控主机的数据，并将数据发送给zabbix server</li><li><strong>zabbix server</strong>：负责接收agent发送的报告信息，并且负责组织配置信息，统计信息，操作数据等</li><li><strong>zabbix database</strong>：用于储存所有zabbix的配置信息、监控数据的数据库</li><li><strong>zabbix web</strong>：zabbix的web界面，管理员通过web界面管理zabbix配置以及查看zabbix相关监控信息</li><li><strong>zabbix proxy</strong>：可选组件，用于分布式监控环境中，zabbix proxy代表server端，完成局部区域内的信息收集，最终统一发往server端</li></ul><ul><li>我们将zabbix agent 部署到被监控主机上，由agent采集数据，报告给负责控制中心主机，中心主机也就是master/agent模型中的master，负责监控的中心主机被称为zabbix serevr，zabbix server将从agent端接收到信息储存于zabbix的数据库中，我们把zabbix的数据库端称为zabbix database，如果管理员需要查看各种监控信息，则需要zabbix的GUI，zabbix的GUI是一种Web GUI，我们称之为zabbix web，zabbix web是使用PHP编写的，所以，如果想要使用zabbix web展示相关监控信息，需要依赖LAMP环境，不管 是zabbix server，或是zabbix web，他们都需要连接到zabbix database获取相关数据</li></ul><ul><li>当监控规模变得庞大时，我们可能有成千上万台设备需要监控，这时我们是否需要部署多套zabbix系统进行监控呢？如果部署多套zabbix监控系统。那么监控压力就会被分摊，但是，把这些监控的对象将会被尽量平均的分配到不同的监控系统中，这个时候，我们就无法通过统一的监控入口，去监控这些对象了。虽然分摊了监控压力，但是也增加了监控工作的复杂度？其实，zabbix天生就有处理这种问题的能力，因为zabbix支持这种分布式监控，我们可以把成千上万台的监控对象分成不同的区域，每个区域中设置一台代理主机，区域内的每个监控对象的信息被agent采集，提交给代理 主机，在这个区域内，代理主机的作用就好比zabbix server，我们称为这些代理主机为zabbix proxy，zabbix proxy再将收集到的信息统一提交给真正的zabbix server处理。这样，zabbix proxy不仅分摊了zabbix server的压力，同时，我们还能够通过统一的监控入口，监控所有的对象</li></ul><h5 id="zabbix-工作模式"><a href="#zabbix-工作模式" class="headerlink" title="zabbix 工作模式"></a>zabbix 工作模式</h5><blockquote><p> 我们都知道，agent端采集完数据主动发送给server端，这种模式我饿称之为<strong>主动模式</strong>，也就说对于agent端来说是主动的。</p></blockquote><blockquote><p>其实，agent端也可以不主动发送数据，而是等待server过来拉取数据，这种模式我们叫<strong>被动模式</strong></p></blockquote><blockquote><p>其实不管是主动模式还是被动模式，都是对于agent端来说的。而且，主动模式与被动模式可以同时存在，并不冲突。</p><p>管理员可以在agent端使用一个名为<code>zabbix_sender</code>的工具，测试是否能够从server端发送数据。</p><p>管理员也可以在server端使用一个名为<code>zabbix_get</code>的工具，测试是否能从agent端拉取数据</p></blockquote><h4 id="Zabbix-服务器搭建部署"><a href="#Zabbix-服务器搭建部署" class="headerlink" title="Zabbix 服务器搭建部署"></a>Zabbix 服务器搭建部署</h4><h5 id="安装描述"><a href="#安装描述" class="headerlink" title="安装描述"></a>安装描述</h5><p>简单地概念刚刚已经描述过，zabbix的几个常用的重要组件，在安装zabbix时，其实是在安装这些组件。</p><p>由于我们的监控规模也不大，所以此处将不会安装zabbix proxy ，我们需要安装如下组件：</p><ol><li><strong>Zabbix server</strong></li><li><strong>Zabbix database</strong></li><li><strong>Zabbix web</strong></li><li><strong>Zabbix agent</strong></li></ol><p>好了，接下来一个一个聊</p><p>安装的<code>zabbix server</code>版本为<code>3.0</code></p><p>因为zabbix3.X依赖的php版本 不能低于php5.4，而在centos6.8中，php默认版本为5.3</p><p>如果你想要使用centos6.X的操作系统。同时想要更加方便的升级php，可以使用Remi源升级PHP，</p><p>但是为了更加方便的使用yum源安装相关软件包，此处使用centos7安装<code>zabbix3.0.7</code></p><h5 id="安装-zabbix-server"><a href="#安装-zabbix-server" class="headerlink" title="安装 zabbix server"></a>安装 zabbix server</h5><p>为了方便安装，配置zabbix的官方yum源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://repo.zabbix.com/</span><br></pre></td></tr></table></figure><p>我们配置一下zabbix3.0的yum源</p><p><img src="/images/1577188749508.jpg" alt="1-1" title="本博客的主人最帅"></p><p>首先进入<code>/ect/yum.repo.d/</code>文件夹</p><p>查看一下 是否有<code>zabbix.repo</code>，如果没有创建一个并编写，如下图格式</p><p><img src="/images/1577189089487.jpg" alt="1-2" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zabbix]</span><br><span class="line">name=zabbix</span><br><span class="line">baseurl=http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure><p>同时，我们配置了<strong>base</strong>源与<strong>epel</strong>源，因为安装过程中会用到这些yum源。</p><p>没有配置好的话，会报出如下图的错：</p><p><img src="/images/1577235080635.jpg" alt="1-3" title="本博客的主人最帅"></p><p>所以在下载之前，先配置好base源和epel源</p><p>这里选择的是redhat7下x86_64的zabbix3.0版本的包。但是安装zabbix-server-mysql时报错，原因是缺少libiksemel.so.3()(64bit)和fping包。这是因为yum安装zabbix不仅需要配置zabbix包源，还需要配置好epel源和base源，base源我们有自带就不用说了。</p><p>这时我们需要配置epel源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install epel-release</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /etc/yum.repo.d/</span><br></pre></td></tr></table></figure><p>这里看到多了epel.repo这个文件，表明epel配置成功。</p><p>然后我们继续安装zabbix-server-mysql</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum -y install zabbix-server-mysql</span><br><span class="line"></span><br><span class="line">错误：软件包：zabbix-server-mysql-3.0.25-1.el7.x86_64 (zabbix)</span><br><span class="line">需要：libiksemel.so.3()(64bit)</span><br></pre></td></tr></table></figure><p>我们发现这里还有缺少依赖包libiksemel.so.3()(64bit)的问题。</p><p>我们通过下载zabbix源来解决这个问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm</span><br></pre></td></tr></table></figure><p>最后安装zabbix-server-mysql成功 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum -y install zabbix-server-mysql zabbix-get --skip-broken</span><br><span class="line"></span><br><span class="line">已安装:</span><br><span class="line">zabbix-server-mysql.x86_64 0:3.0.25-1.el7</span><br></pre></td></tr></table></figure><p>准备工作完毕，剩下的就是安装各个组件了，我们一个一个安装</p><p>先安装<strong>zabbix server</strong></p><p>由于我们使用mysql作为数据库，所以，在安装zabbix3.X的版本的server端时，需要安装zabbix-server-mysql包，在3.X的zabbix版本中，并没有单独的zabbix server端程序包，安装zabbix-server-mysql包即为了安装了server端包，同时，我们可以在服务器安装zabbix_get包，以便想agent端发起测试采集数据请求，所以，我们在server端安装如下;</p><p><img src="/images/1577189265125.jpg" alt="1-4" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install zabbix-server-mysql zabbix-get</span><br></pre></td></tr></table></figure><p>在安装的时候，我遇到了一个问题，</p><p>密密麻麻的英文很头疼，而且好多都不认识咋办？其实也不用全都理解，全都认识，认识关键字就行。例如：You could try using –skip-broken to work around the problem ，大概意思就是 ‘你可以使用 “–skip-broken” 来解决这个问题‘，所以只需要在代码后面加上就可以了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install zabbix-server-mysql zabbix-get --skip-broken</span><br></pre></td></tr></table></figure><p>还有一种解决办法，就是更新一下你的yum，因为你的yum版本低了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y update</span><br></pre></td></tr></table></figure><p>安装完成后，输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ql zabbix-server-mysql</span><br></pre></td></tr></table></figure><p>如果出现下图这样的情况，那就是你安装失败了。需要重新安装</p><p><img src="/images/1577235250247.jpg" alt="1-5" title="本博客的主人最帅"></p><p><img src="/images/1577235296648.jpg" alt="1-6" title="本博客的主人最帅"></p><p>重新安装还有可能碰到一种问题，</p><p>连上你同桌的WiFi就好了，因为你的网络丝毫不给你一分薄面！</p><p>之后重新下载一下就好了，出现Comlete就是现在好了，如下图</p><p>后面出现类似的问题，同样的方法解决就好了</p><p><img src="/images/1577235650800.jpg" alt="1-7" title="本博客的主人最帅"></p><p>之后继续配置，输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ql zabbix-server-mysql</span><br></pre></td></tr></table></figure><p><img src="/images/1577235837540.jpg" alt="1-8" title="本博客的主人最帅"></p><p>输入这行命令，看见create.sql.gz那就进入到这个文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/share/doc/zabbix-server-mysql-3.0.28</span><br></pre></td></tr></table></figure><p>之后解压create.sql.gz这个压缩文件，即可获得初始化sql脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunzip create.sql.gz</span><br></pre></td></tr></table></figure><p>之后输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll create.sql</span><br></pre></td></tr></table></figure><p><img src="/images/1577235977026.jpg" alt="1-9" title="本博客的主人最帅"></p><p>是这样的效果，就是正确的！</p><p>但是需要注意的是，此sql脚本中sql只会在对应的数据库中初始化zabbix所需要的数据库表，但是不会创建zabbix数据库，所以，创建zabbix数据库这一步骤，还是需要我们手动进行的。所以，此处我们先动手创建zabbix的数据库，过程如下：</p><p>进入数据库</p><p><img src="/images/1577236249847.jpg" alt="1-10" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create database zabbix charset 'utf8';</span><br><span class="line"></span><br><span class="line">grant all on zabbix.* to zabbix@'localhost' identified by '123456';</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><p>zabbix数据库初始化完成后，执行对应的sql初始化脚本，输入命令：</p><p><img src="/images/1577237348431.jpg" alt="1-11" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p -Dzabbix &lt; /usr/share/doc/zabbix-server-mysql-3.0.28/create.sql</span><br><span class="line"><span class="meta">#</span> /usr/share/doc/zabbix-server-mysql-3.0.28/create.sql 对应的是你create.sql所在的地点</span><br></pre></td></tr></table></figure><p>进入数据库，zabbix库，查看表，出现这些表，就是导入成功</p><p><img src="/images/1577237406737.jpg" alt="1-11" title="本博客的主人最帅"></p><h5 id="配置zabbix-server端并启动"><a href="#配置zabbix-server端并启动" class="headerlink" title="配置zabbix server端并启动"></a>配置zabbix server端并启动</h5><p>server端已经安装完毕，并且数据库也已经初始化，现在我们开始配置server端，编辑zabbix server端的配置文件</p><p><img src="/images/1577238444017.jpg" alt="1-11" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/zabbix/zabbix_server.conf</span><br></pre></td></tr></table></figure><p>此处列出我们可能会经常修改的参数，如下：</p><blockquote><p><code>LIstenPort=10051</code>  </p><p>服务器默认端口</p></blockquote><blockquote><p><code>SourceIP=</code></p><p>通过SourceIP参数可以指定服务器的源IP，当server端㕛多个IP地址时，我们可以指定服务器端使用固定的IP于agent端进行通讯，为了安全起见，agent端会基于IP进行一定的访问控制，也就是说agent端只允许指定IP以server端的身份菜鸡被监控主机的数据，如果IP不对应，租不允许采集被监控主机的数据，所以，当server端 有多个IP时，我们可以通过SourceIP参数，指定server端 通过哪个IP采集被监控主机的数据</p></blockquote><blockquote><p><code>LogType=file=file</code></p><p>通过LogType参数，可以指定通过哪种方式记录日志，此参数可以设置为三种值，system、file、console，system表示将日志发往syslog，file表示使用指定的文件 作为日志 文件，console表示将日志发往控制台，默认为file</p></blockquote><blockquote><p><code>LogFile=/var/log/zabbix/zabbix_server.log</code></p><p>当LogType设置为file时，通过LogFile参数设置日志文件位置</p></blockquote><blockquote><p><code>LogFileSize=0</code></p><p>指明日志文件达到 多大是自动滚动，单位为MB，如果设置LogFileSize为50时，表示日志大小达到 50MB滚动一次，设置为0表示日志文件不寄回滚动，所有入职保存在一个文件中</p></blockquote><blockquote><p><code>Debuglevel=3</code></p><p>通过DebugLevel参数可以定义日志的详细程度，即为日志级别</p></blockquote><blockquote><p><code>DBHost=localhost</code></p><p>通过DBHost参数设置zabbix数据库 所在的服务器IP，由于此处zabbix于mysql安装在同一个服务器上，所以此处设置为localhost</p></blockquote><blockquote><p><code>DBUser=zabbix</code></p><p>通过DBUser指定zabbix数据库用户名</p></blockquote><blockquote><p><code>DBPassword=</code></p><p>通过DBPassword指定zabbix数据库用户的密码</p></blockquote><blockquote><p><code>DBPort=3306</code></p><p>通过DBPort指定zabbix所在数据库服务监听的端口号</p></blockquote><blockquote><p><code>DBSocket=/var/lib/mysql/mysql.sock</code></p><p>如果数据库服务于server端在同一台服务器上，可以通过DBSocket指定数据库本地套接字文件位置，但是需要注意，即使设置了mysql套接字文件的位置，还是需要配合DBHost参数，否则在登录zabbix控制台时，可能会出现警告，在zabbix server的log中，也可能会出现无法连接数据库的提示</p></blockquote><p>根绝上述的配置参数的解释，根据具体需求进行实际配置即可。</p><p>配置完成后，启动zabbix服务端即可，输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start zabbix-server.service</span><br><span class="line"><span class="meta">#</span> 输入</span><br><span class="line">ss -tnl</span><br><span class="line"><span class="meta">#</span> 查看10051端口是否被监听</span><br></pre></td></tr></table></figure><p>启动后,10051端口已经被监听，如下图</p><p><img src="/images/1577238791164.jpg" alt="1-11" title="本博客的主人最帅"></p><h5 id="安装zabbix-web端"><a href="#安装zabbix-web端" class="headerlink" title="安装zabbix web端"></a>安装zabbix web端</h5><p>zabbix web 可以安装在单独的主机上，只要能连接到zabbix database所在的数据库即可。但是此处为了方便，我们将zabbix web与mysql以及 zabbix server 安装在同一台服务器上。</p><p>因为 zabbix web 需要lamp环境，所以，此处我们将会依赖到的环境先安装好。</p><p>代码如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml</span><br></pre></td></tr></table></figure><p>完成上述步骤后，安装zabbix web所需要的两个包，对应版本为3.0.7.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install zabbix-web zabbix-web-mysql --skip-broken</span><br></pre></td></tr></table></figure><p>查看刚才安装完成的zabbix-web程序包，可以看到，zabbix-web的web应用存放在/usr/share/zabbix中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ql zabbix-web</span><br></pre></td></tr></table></figure><p><img src="/images/1577239418954.jpg" alt="1-11" title="本博客的主人最帅"></p><p>zabbix还是比较贴心的，针对httpd，zabbix-web包中已经包含了对应zabbix文档路径的配置文件。</p><p>输入：</p><p><img src="/images/1577239584104.jpg" alt="1-11" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/httpd/conf.d/zabbix.conf</span><br></pre></td></tr></table></figure><p><img src="/images/1577239635853.jpg" alt="1-11" title="本博客的主人最帅"></p><p>以看到，针对zabbix web的文档路径，此文件中已经为我们准备了默认设置，如果不使用httpd的虚拟主机，只要把时区稍加改动即可直接使用</p><p>而此处，我们使用httpd的虚拟主机访问zabbix web ，所以，将配置文件爱你中的内容改为如下配置，同时将时区修改为<code>亚洲上海</code></p><p><img src="/images/1577240031191.jpg" alt="1-11" title="本博客的主人最帅"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&lt;VirtualHost 39.106.84.122&gt;</span><br><span class="line">servername zabbix.zhanglei.net</span><br><span class="line">documentroot /usr/share/zabbix</span><br><span class="line"></span><br><span class="line">        Alias /zabbix /usr/share/zabbix</span><br><span class="line"></span><br><span class="line">        &lt;Directory "/usr/share/zabbix"&gt;</span><br><span class="line">                Options FollowSymLinks</span><br><span class="line">                AllowOverride None</span><br><span class="line">                Require all granted</span><br><span class="line"></span><br><span class="line">                &lt;IfModule mod_php5.c&gt;</span><br><span class="line">                        php_value max_execution_time 300</span><br><span class="line">                        php_value memory_limit 128M</span><br><span class="line">                        php_value post_max_size 16M</span><br><span class="line">                        php_value upload_max_filesize 2M</span><br><span class="line">                        php_value max_input_time 300</span><br><span class="line">                        php_value max_input_vars 10000</span><br><span class="line">                        php_value always_populate_raw_post_data -1</span><br><span class="line">                        php_value date.timezone Asia/Shanghai</span><br><span class="line">                &lt;/IfModule&gt;</span><br><span class="line">        &lt;/Directory&gt;</span><br><span class="line">        </span><br><span class="line">        &lt;Directory "/usr/share/zabbix/conf"&gt;</span><br><span class="line">                Require all denied</span><br><span class="line">        &lt;/Directory&gt;</span><br><span class="line"></span><br><span class="line">        &lt;Directory "/usr/share/zabbix/app"&gt; </span><br><span class="line">                Require all denied</span><br><span class="line">        &lt;/Directory&gt; </span><br><span class="line"></span><br><span class="line">        &lt;Directory "/usr/share/zabbix/include"&gt; </span><br><span class="line">                Require all denied</span><br><span class="line">        &lt;/Directory&gt;</span><br><span class="line">    </span><br><span class="line">        &lt;Directory "/usr/share/zabbix/local"&gt;</span><br><span class="line">                Require all denied</span><br><span class="line">        &lt;/Directory&gt;</span><br><span class="line"></span><br><span class="line">&lt;/VirtualHost&gt;</span><br></pre></td></tr></table></figure><p>配置为完成后，启动httpd服务。</p><p><img src="/images/1577240159396.jpg" alt="1-11" title="本博客的主人最帅"></p><p>好了，zabbix web安装配置完成</p><p>访问 服务器IP/zabbix，就可以看到如下图的zabbix安装页面</p><p>配置好之后，别忘记把把<code>/usr/share/zabbix</code>复制到<code>/var/www/html</code>里面</p><p>之后，IP/zabbix/setup.php访问即可，就可出现如下图的样子。</p><p><img src="/images/1577246280547.jpg" alt="1-11" title="本博客的主人最帅"></p><h5 id="初始化zabbix-配置"><a href="#初始化zabbix-配置" class="headerlink" title="初始化zabbix 配置"></a>初始化zabbix 配置</h5><p>完成上述安装步骤后就可以看到zabbix安装页面。点击下一步</p><p>不出意外的话，你们也会这样。哈哈哈</p><p><img src="/images/1577246345326.jpg" alt="1-11" title="本博客的主人最帅"></p><p>按照错误的这四个参数。修改/etc/php.ini文件中的配置就行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/php.ini</span><br></pre></td></tr></table></figure><p><code>post_max_size=16M</code></p><p> <code>max_execution_time=300</code></p><p> <code>max_input_time=300</code></p><p> <code>date.timezone =Asia/Shanghai</code></p><p>找到这四个，直接把配置改了就好，和我的一样就行。</p><p>如果嫌找的麻烦，直接搜索，输入‘/’</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/你想搜索的关键字，或者全拼</span><br></pre></td></tr></table></figure><p>改好之后重新启动下服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart httpd.service</span><br></pre></td></tr></table></figure><p>之后再重新加载下页面，就会像如下图：</p><p><img src="/images/1577253128156.jpg" alt="1-11" title="本博客的主人最帅"></p><p>可以看到，zabbix检查的环境已经全部满足，所以点击下一步！</p><p><img src="/images/1577253184977.jpg" alt="1-11" title="本博客的主人最帅"></p><p>此处zabbix需要配置数据库连接，此处配置数据库的类型，IP，端口，数据库名，用户密码等信息，端口填写0表示使用默认端口(3306端口)</p><p>请确定概要信息无误，点击下一步</p><p><img src="/images/1577255155455.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577255204397.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577255235198.jpg" alt="1-11" title="本博客的主人最帅"></p><p>之后，就会进入登录页面，默认账号admin，密码zabbix</p><p><img src="/images/1577255289782.jpg" alt="1-11" title="本博客的主人最帅"></p><p>登录完成后，可以看到zabbix的仪表盘</p><p><img src="/images/1577255350824.jpg" alt="1-11" title="本博客的主人最帅"></p><p>全是英文，作为一个爱国的知识青年，肯定看不爽，所以 ，我们可以把它调成中文版</p><p><img src="/images/1577255416702.jpg" alt="1-11" title="本博客的主人最帅"></p><p>语言选择中文，点击 更新即可，蛋黄思思你可能无法在语言中看到中文的选项，如果无法找到中文选项，则代表你的配置文件中的中文选项显示属性为false</p><p><img src="/images/1577255448186.jpg" alt="1-11" title="本博客的主人最帅"></p><p>当然了，如果你没有这项选择，那么你可以修改下如下文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/share/zabbix/include/locales.ini.php</span><br></pre></td></tr></table></figure><p><img src="/images/1577255626516.jpg" alt="1-11" title="本博客的主人最帅"></p><p>找到中文对应的值，将显示属性设置为true即可，如上图所示</p><p>但是，你可能还会遇到中文乱码情况，如果遇到中文乱码，可以从Windows中挑选一个顺眼的中文字体，将对应字体放置到inux中 zabbix web的字体目录中，因为我们使用的是rpm包安装的zabbix web，所以zabbix web默认字体目录为 /usr/share/zabbix/fonts/，Windows中的字体文件后缀名如果为TTF，当我们把对应字体文件拷贝到zabbix字体目录是，需要修改其后缀名为小写的ttf（如果本来就是小写的则不用任何修改了），字体文件上传完毕后，修改/usr/share/zabbix/include/defines.inc.php配置文件，将下图中显示字体部分修改为刚才上传的字体文件对应的名称即可。</p><p>好了，上述操作完成后，zabbix控制台即显示中文了。</p><p>但是你可能会在访问zabbix控制台时，可能会发现如下提示：</p><p><img src="/images/1577255896543.jpg" alt="1-11" title="本博客的主人最帅"></p><p>如果出现图中的提示，可能是由如下几个原因引起的：</p><p>1、zabbix-server未正常启动</p><p>2、已经开启selinux，但是没有正常设置对应权限</p><p>3、zabbix-server未能正常连接数据库</p><p>4、zabbix.conf.php文件中$ZBX_SERVER参数对应的主机名不能正常解析</p><p>5、其他原因，需要查看zabbix server 日志</p><p>如果在访问zabbix控制台时并没有出现上述提示，忽略上述描述即可。</p><p>为了更加安全，我们不应该使用管理员的默认密码，所以，我们最好先修改管理员密码</p><p><img src="/images/1577256061549.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577256113248.jpg" alt="1-11" title="本博客的主人最帅"></p><p>好了。基本配置已经配置完成了，我们以后的监控工作就要围绕着这个web界面展开了！</p><h5 id="Zaabix-agent-安装"><a href="#Zaabix-agent-安装" class="headerlink" title="Zaabix agent 安装"></a>Zaabix agent 安装</h5><p>现在万事具备，就差agent端了，agent端安装也非常方便，直接<strong>被监控主机</strong>上安装如下两个包即可。</p><p><code>当然了，在安装之前，指定要把上面的准备工作全都做好，否则会出错的哦！</code></p><p>此处被管理主机 centos7，已经配置好了对应的zabbix源，agent版本可以跟server端版本  不一致，没有关系，安装即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y zabbix-agent zabbix-sender</span><br></pre></td></tr></table></figure><p>我们查看一下zabbix-agent都安装了什么文件，当然，最重要的就是zabbix_agentd.conf这个配置文件了</p><p><img src="/images/1577256337395.jpg" alt="1-11" title="本博客的主人最帅"></p><p>还记得我们在刚开始介绍zabbix时说过“主动模式”与“被动模式”吗？这两种模式的相关配置，都需要在zabbix_agentd.conf中定义，打开这个文件，我们来配置一下常用的agent端配置。首先，可以看到配置文件中有很多注释，打开配置文件，首先看到的就是”通用参数配置段”，我们可以在此配置段配置zabbix_agent进程的进程编号文件路径，存储日志方式，日志文件位置，日志滚动阈值等常用设定，细心如你一定已经发现，zabbix_agent配置文件的”通用配置段”中的参数大多数与zabbix_server配置文件中的常用参数意义相同，所以，此处不再过多赘述，如果没有特殊需要，保持默认即可。 </p><p><img src="/images/1577272480659.jpg" alt="1-11" title="本博客的主人最帅"></p><p>此处先说说我们马上会用到的两个配置，如下图红框中的注释所描述的，“被动模式配置段”与“主动模式配置段”</p><p><img src="/images/1577273106840.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577273063509.jpg" alt="1-11" title="本博客的主人最帅"></p><p>我们已经在最开始的概念介绍中，描述过，“主动模式”和“被动模式”都是对于agent端来说的，而且它们可以同时存在，，并不冲突。</p><p>我们先来看看“被动模式”的相关配置参数。</p><p>被动模式相关参数如下：</p><p>Sserver：用于指定允许哪台服务器拉去当前服务器的数据，当agent端工作于被动模式，则代表server端会主动拉取agent端数据，那么server端的IP必须与此参数的IP对应，此参数用于实现基于IP的访问控制，如果有多个IP，可以使用逗号隔开。</p><p>ListenPort：用于指定当agent端工作于被动模式所监听的端口号，默认端口号10050，也就是说，server端默认访问10050端口，从而拉取数据。</p><p>ListenIP：用于指定agent端工作于被动模式时所监听的IP地址，默认值为0.0.0.0，表示监听本机的所有IP地址。</p><p>StartAgents：用于指定预生成的agent进程数量。</p><p>主动模式</p><p>主动模式的常用参数如下：</p><p>ServerActive：此参数用于指定当agent端工作于主动模式时，将信息主动推送到哪台server上，当时有多个IP时，可以用逗号隔开。</p><p>Hostname：此参数用于指定当前主机的主机名，server端通过此参数对应的主机名识别当前主机。</p><p>RefreshActiveChescks：此参数用于指明agent端没多少秒主动将采集到的数据发往server端。</p><p>此处，我们同时设置“被动模式”与“主动模式”的如下参数，其他保持默认即可，修改完成后保存退出。</p><p>Server=47.96.230.50</p><p>ServerActive=47.96.230.50</p><p>Hostname=testzbx1.zsythink.net</p><p>配置文件修改完成后，启动agent端进程</p><p><img src="/images/1577273181431.jpg" alt="1-11" title="本博客的主人最帅"></p><p>好了，agent端也已经安装好了！</p><h4 id="在-Zabbix-中添加主机"><a href="#在-Zabbix-中添加主机" class="headerlink" title="在 Zabbix 中添加主机"></a>在 Zabbix 中添加主机</h4><p>在添加主机之前，我们先把工作场景描述清楚。然后再根据描述的工作场景进行演示</p><p>假设，我们想要使用zabbix监控一台linux服务器，那么，我们肯定要将这个服务器纳入zabbix的管理范围，而“添加主机”这个操作，就是将被监控的主机纳入zabbix管理范围的一个必须操作，如果我们有10台主机都需要呗zabbix监控呢？没错，这10台主机必须被添加到zabbix的监控列表中，在zabbix中，我们将被监控的对象称为“主机”，“主机”不一定是服务器，也可以是<code>路由器</code>，<code>交换机</code>等网络设备，而且，根据主机的属性、角色、特征的不同，我们还能够将主机分组。</p><p>比如，我们有10台服务器，10台服务器中，有3台window服务器，有7台linux服务器，那么，我们还可以按照操作系统的不同，将他们分成两组，Windows服务器组于linux服务器组，或者我们不按照操作系统对主机进行分组，而是根据服务器的角色对主机分组。</p><p>比如，一共10台服务器，3台是是提供ldap服务的，2台是提供web服务的，5台是提供数据库服务的，我们也可以把他们按照角色分成3组，ladp主机组、web主机组、db主机组，当然，我们也只是举个例子。</p><p>实际应用中，具体怎样分组，是根据实际需求视情况而定的，那么，为什么要将主机分组呢？这是为了方便管理，因为同一类主机需要被监控的指标很有可能 都是相同的，所以将他们分为一组方便管理，当然了，这就是后话，我们后面再聊！</p><p>上面一段话中，我们提到了两个zabbix的常用术语，“主机”与“主机组”，我们再来总结一遍：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、host（主机）：需要zabbix监控的对象，被称为主机，主机必须属于某个主机组。</span><br><span class="line"></span><br><span class="line">2、hostgroup（主机组）：“主机组”也被称为“主机群组”，是由具有相同属性、特征、角色的多个主机组成的逻辑单元。</span><br></pre></td></tr></table></figure><p>理解 上述两个术语，并且能够在zabbix中使用他们，就是我们所要达到的目的。</p><p>那么我们来看看怎样在zabbix添加一台主机，在动手添加主机之前。先说明下我们的环境。</p><p>我们已经将zabbix-server、zabbix-database、zabbix-web安装在了39.106.84.122上。</p><p>同时，我们将zabbix-agent安装在了47.97.172.176上。</p><p>所以此处，47.97.172.176就是被监控的对象 ，我们需要将176添加为zabbix主机。</p><p>首先呢，打开我们的zabbix web 控制台，看看都有那些“主机组”。</p><p>点击“配置“—-”主机群组“，可以看到，系统默认已经为我们准备了一些主机组，如果这些主机组不满足我们的需要，我们也可以创建新的主机组</p><p>点击下图中的“创建主机群组”按钮，即可创建主机组，但是，我们还不用深入研究主机组，此处只是让大家了解一下，对主机有一个初步的认识。</p><p><img src="/images/1577320713453.jpg" alt="1-11" title="本博客的主人最帅"></p><p>同样，点击<code>配置</code>—–<code>主机</code>，即可查看已经被加入zabbix主机列表的主机，可以看到，zabbix默认将zabbix server添加为了一台主机，以便 可以自己监控自己，但是此处，我们需要添加一台我们自己的主机，就是47.97.172.176，</p><p>点击<code>创建主机</code>，点击创建主机之前，可以选择左侧的<code>群组</code>下来菜单，以确定将要创建的主机所在的主机组，当然，我们也可以先不选主机组，直接点击<code>创建主机</code>按钮。</p><p><img src="/images/1577322582225.jpg" alt="1-11" title="本博客的主人最帅"></p><p>点击<code>创建主机</code>按钮之后，即可看见类似如下界面，为了更好的描述每个步骤，具体解释参靠下图后面的注释列表。</p><p><img src="/images/1577322873679.jpg" alt="1-11" title="本博客的主人最帅"></p><p><code>1</code>、我们可以在主机名的文本框中填写被监控主机的主机名称。</p><p><code>2</code>、<strong>可见名称</strong>一般使用剪短的、易读的、见名知义的名称表示主机即可。</p><p><code>3</code>、我们可以选择将要创建的主机属于哪个主机组，当然，如果没有合适的主机组，我们也可以直接在创建主机时，直接创建新的主机组，我上面说过，每个主机必须存在于某个主机组中，所以，主机组是必须的</p><p><code>4</code>、如果在三的<code>3</code>的位置上没有对应的、可用的、合适的主机组，我们可以直接在<strong>新的群组</strong>中创建当前主机需要的主机组。</p><p><code>5</code>、选择通过哪种接口监控当前主机，可选的方式有IPMI接口、JMX接口、SNMP接口、agent接口，我们说过，”主机”在zabbix中，可以是服务器，路由器，交换机等等硬件设备，有的硬件设备只支持某种接口，所以，当我们添加主机时，会让我们选择通过哪种合适的接口监控它，具体各接口的适用场景我们已经在第一篇介绍zabbix概念的文章中描述过，此处不再赘述，当然，如果一台主机能被多种接口所监控，也可以同时配置多个接口监控这台主机，但是当前，我们需要监控的主机是一台Linux服务器，而且已经安装了对应的agent端，所以，此处，我们只使用agent接口对当前主机进行监控，而使用agent接口时，可以通过IP连接到对应agent，也可以使用主机名连接到对应agent，而此处，我们选择使用IP地址连接到对应的agent，IP地址就是我们将要添加的主机的IP，47.97.172.176  ，对应端口为默认的10050，如果你想要使用主机名连接到对应的agent，那么需要保证主机名能够被正常解析到47.97.172.176上，此处不再赘述，如果有多个IP可以连接到对应agent，可以点击”添加”，添加一条新的IP。 </p><p><code>6</code>、对将要添加的主机进行描述，添加响应的描述信息即可。</p><p><code>7</code>、表示是否使用zabbix proxy监控当前主机，虽然上图中。此处翻译为“由agent代理程序检测”，但是实际是用于指定zabbix proxy的，与zabbix agent并没有关系，但是因为我们没有配置zabbix_proxy，所以此处保持默认即可</p><p>好了，按照上述界面中的配置进行设置以后，点击”添加”按钮，即可简单的添加一台主机，可以看到，47.97.172.176已经被添加到了主机列表中。 </p><p><img src="/images/1577323895393.jpg" alt="1-11" title="本博客的主人最帅"></p><p>而且，如果此时我们再次查看主机组，已经发现，TestHosts主机组已经被添加了，而且其中的成员已经包含了testzbx1主机。 </p><p><img src="/images/1577324037183.jpg" alt="1-11" title="本博客的主人最帅"></p><p>回到主机列表，可以看到我们刚才添加的testzbx1主机，但是testzbx1主机的”可用性”对应的4中接口都是灰色的。 </p><p><img src="/images/1577324150680.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577324218152.jpg" alt="1-11" title="本博客的主人最帅"></p><p>第二个图我们可以看见，何金存的主机已经成功的卑微监控了，</p><p>上图中，而ZBX就代表agent接口，虽然我们在添加主机时，配置了通过agent监控对应主机，但是，由于我们并没有配置监控主机的任何指标，所以，ZBX仍然是灰色的，也就是说，我们现在只是将192.168.1.107加入了zabbix的监控范围，但是并没有对它进行任何实际的监控，因为我们还没有配置任何”监控项”，至于怎样配置监控项，且听下回分解。 </p><h4 id="在Zabbix中添加监控项"><a href="#在Zabbix中添加监控项" class="headerlink" title="在Zabbix中添加监控项"></a>在Zabbix中添加监控项</h4><p>上面呢已经描述了zabbix添加主机，但是，我们还并没有对主机进行任何指标的实际监控那么现在，我们就来说说，具体怎样监控我们想要监控的指标。</p><p>首先，打开我们zabbix控制台，点击<code>配置</code>—<code>主机</code>，可以看到我们上次创建的主机，虽然我们为对应的被监控主机安装了agent，但是主机对应的ZBX仍然显示灰色，代表我们还没有任何监控项被检测到，那么现在，我们来为“何金存”主机添加一个监控项。</p><p><img src="/images/1577330551358.jpg" alt="1-11" title="本博客的主人最帅"></p><p>点击“何金存”主机上的<code>监控项</code>，如下图所示位置。</p><p><img src="/images/1577330697290.jpg" alt="1-11" title="本博客的主人最帅"></p><p>进入监控项配置界面后，可以根据一些条件，筛选出已经存在的一些控制项，但是我们并没有任何监控项，所以此处 ，我们直接点击<code>创建监控项</code>按钮。以便新建监控项。</p><p><img src="/images/1577330817857.jpg" alt="1-11" title="本博客的主人最帅"></p><p>假如，现在我们想要监控“何金存”这台主机的CPU的上下文切换此处，那么我们可以在此界面进行如下配置</p><p><img src="/images/1577330929623.jpg" alt="1-11" title="本博客的主人最帅"></p><p>首先，在名称文本框中设置监控项的名称，我们此处监控的指标cpu上下文切换次数，所以，命名次监控项为“cpu context swiyches”</p><p>因为我们在“何金存”这台主机上安装了zabbix agent，所以，此处类型保持默认，选择zabbix客户端。</p><p>在键值一栏中，我们可以选择对应的key，也就是说，我们通过哪个key，这些key都是zabbix自带的key，这些key一般都是系统级别的通用的监控项所能够用到的key，如果这些“键”不能满足我们的需求，我们则需要自定义key，这是后话，后面再聊，此处，我们选择system/cpu.switches</p><p><img src="/images/1577331010819.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577331030747.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577331048400.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577331062325.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577331117868.jpg" alt="1-11" title="本博客的主人最帅"></p><p>选择完可以看见，key的值已经自动填充到了“键值”的文本框中</p><p><img src="/images/1577331507814.jpg" alt="1-11" title="本博客的主人最帅"></p><p>说到这，我们可以通过命令行，来看下对应的“键”返回信息到底是什么样子的？</p><p>之前的我介绍过zabbix概念是已经说过：管理员可以在server端使用另一个名为zabbix_get的工具，测试是否能够从agent端拉取数据。</p><p><img src="/images/1577340453222.jpg" alt="1-11" title="本博客的主人最帅"></p><p>我们就是通过agent接口监控数据的，agent监听在10050端口上，此处保持默认即可。</p><p>而我们刚才也看到了，通过zabbix_get获取到的system.cpu.switches的数据，都是一些十进制的整数，所以，信息类型选择数字，数据类型选择十进制。</p><p>数据更新间隔表示每个多长时间获取一次监控项对应的数据，为了演示方便，能尽快获取到数据，我们设定位每隔30秒获取一次监控信息，此处表示每隔30秒获取一次47.97.172.176主机的cpu上下文切换次数 ，但是需要注意，在生产环境中，如果不是特别重要的、敏感的、迅速变化的数据，不要获取的这么频繁，因为如果我们的监控项变得特别多时，获取信息的时间间隔过于频繁会带来巨大的监控压力，同时对数据库的写入也是一种考验。</p><p>当然，我们也可以灵活的定义时间间隔，比如，周一到周五我们的业务量比较少，可以10分钟获取一次数据，而周六周日的业务量会剧增，为了实时监控，可以设置5分钟获取一次数据，这里只是举个例子，如果有类似的需求，可以通过“自定义事件间隔”配置段，添加不同时间段的不同检测频率。</p><p><img src="/images/1577341079573.jpg" alt="1-11" title="本博客的主人最帅"></p><p>因为我们每隔30秒就获取一次数据，那么这些数据都会变成历史，存入数据库中，通过上图中的开始数据文本框，可以设置历史数据的保存时长。</p><p>上图中，我们设置历史数据保存8天，趋势数据是什么意思呢？趋势数据就是每个小时收集到历史数。</p><p>从上图中，还可以看到有一个趋势数据保存天数，趋势数据是什么意思呢？趋势数据就是每个小时收集到的历史数据中的最大值、最小值，平均值以及每个小时收集的到的历史数据的数据量，所以，趋势数据每小时收集一次，数据量不会特别大，一般情况下，历史数据的保留时间都比趋势数据保留时间短很多，因为历史数据比较多，如果我们监控的主机非常多，而且监控的频率 特别频繁，那么数据库的压力则会变得非常大。</p><p>继续往下看，可以看到储存值于查看两个下拉框。</p><p><img src="/images/1577341472464.jpg" alt="1-11" title="本博客的主人最帅"></p><p>我们点开储存值下拉框，可以看到三个选项，不变、差量（每秒频率）、差量（简单变化）</p><p><img src="/images/1577341562547.jpg" alt="1-11" title="本博客的主人最帅"></p><p>那么这些值都是什么意思呢？</p><p><code>不变</code>：表示获取到的值是什么样子的，就在数据库中存储为什么样子。</p><p><code>差量（简单变化）</code>：表示本次收集的信息值 减去 上一次收集到的信息值 得出的差值</p><p><code>差量（每秒速率）</code>：表示本次收集到的值 减去 上次收集到的值以后，再除于两次收集信息的间隔时间。</p><p>而此处，我们监控的指标为cpu上下文切换次数，这是一个不断增长的整数值，所以，我们选择<strong>差量（每秒速率）</strong>最合适</p><p>这样发=我们就能 够监控到不同时间段内cpu上下文切换的频率了。</p><p>那么查看值 是什么意思呢？查看值可以改变监控数据的展示方式，以便监控人员更容易理解，此处我们保持默认即可，在实际用到是我们在做解释。</p><p><img src="/images/1577341940128.jpg" alt="1-11" title="本博客的主人最帅"></p><p>新的应用集  与  应用集  是什么意思呢？</p><p><img src="/images/1577341996936.jpg" alt="1-11" title="本博客的主人最帅"></p><p>我们可以把“应用集”理解为同一类型的监控项的集合，“应用集”英文原词为application，application为一组item（监控项）的集合，比如，我们有3个监控项，他们分别监控“磁盘使用率”，“磁盘写入速率”，“磁盘读取速率”，虽然他们监控指标不同，但是他们都是监控“磁盘”的监控项 ，所以，我们可以把他们归类为“磁盘”应用集，同理，如果有2个监控项，一个是监控nginx连接数量的，一个是监控nginx请求数量的，虽然他们监控的指标不同，但是他们都是监控nginx相关指标的，所以，我们可以把他们归为nginx应用集。</p><p>但是，由于我们没有创建过任何应用集，所以上图中，应用集选择框中没有任何可选择应用集，如果没有可选的合适的应用集，我们可以直接在“新的应用”文本框中填入要创建的应用集名称，那么对应应用集会自动被创建当前监控项 也会自动归类为这个应用集。</p><p><img src="/images/1577342433074.jpg" alt="1-11" title="本博客的主人最帅"></p><p>继续聊，”填入主机资产纪录栏位”我们后面再聊。 </p><p>描述信息栏填写关于这个监控项的相关描述。 </p><p>“已启用”默认被勾选，表示此监控项被创建后，立即生效，即创建此监控项后立即开始监控。 </p><p>好了，监控项的配置我们已经解释的七七八八了，示例配置如下，点击添加按钮, 注：为了更快的获取演示效果，此处将数据更新间隔设置为5秒，但是生产环境中请仔细考虑具体设置为多少秒比较适合生产环境的需求。 </p><p><img src="/images/1577349633413.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577342566211.jpg" alt="1-11" title="本博客的主人最帅"></p><p>点击添加按钮以后，可以看到，何金存主机的第一个监控项已经被添加，而且处于已用状态。</p><p><img src="/images/1577342709516.jpg" alt="1-11" title="本博客的主人最帅"></p><p>点击监控项旁边的“应用集”</p><p><img src="/images/1577342794093.jpg" alt="1-11" title="本博客的主人最帅"></p><p>可以看到，应用集中已经存在了cpu应用集，而且这个应用集中已经存在一个监控项，就是我们刚才创建的”cpu context switches”监控项。 </p><p><img src="/images/1577343339745.jpg" alt="1-11" title="本博客的主人最帅"></p><p>从对应的主机组中找到对应的主机，</p><p><img src="/images/1577344402324.jpg" alt="1-11" title="本博客的主人最帅"></p><p>点击过滤按钮之后，应该可以看到我们刚才创建的监控项，已经存在了部分数据，如果你刚刚创建完监控项，不要着急立马查看“监控项”数据，因为他可能需要一段时间收集数据。</p><p>但是，如果超出正常收集数据的时间后，很长时间以内仍然无法收集到数据，那么有可能 是因为agent端与server端时间不同步引起的，请确定你的agent端与server端的时间是同步的。</p><p>过程中出现了一个问题</p><p><img src="/images/1577348901660.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577348933997.jpg" alt="1-11" title="本博客的主人最帅"></p><p>这个问题，检查两处，如果其他问题也是首先想这两处。</p><p>1、防火墙是否关闭</p><p>2、进入/etc/zabbix/zabbix_agentd.conf配置文件，找到<code>Server</code>，把“127.0.0.1”改成监控服务器IP</p><p><img src="/images/1577349156980.jpg" alt="1-11" title="本博客的主人最帅"></p><p>好，接着往下看啊</p><p>可以看到，“cpu context switches”这个监控项已经存在数据，我们点击对应的“图形”连接</p><p><img src="/images/1577349426989.jpg" alt="1-11" title="本博客的主人最帅"></p><p>点击上图中的<code>图形</code>连接，可以看到如下界面，zabbix已经监控到了对应的cpu上下文切换频率，并且绘制出了对应的“图形”</p><p><img src="/images/1577351286152.jpg" alt="1-11" title="本博客的主人最帅"></p><p>如果没有图形就按照下图来操作即可。操作完之后还是没有图形，那就是没数据。</p><p><img src="/images/1577349916527.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577349869444.jpg" alt="1-11" title="本博客的主人最帅"></p><p><img src="/images/1577349793762.jpg" alt="1-11" title="本博客的主人最帅"></p><p>我们已经为主机添加了第一个监控项，并且已经成功监控到了对应的数据，好了，我们已经入门了。 </p><p>本文参考网站  –  <a href="http://www.zsythink.net/archives/447" target="_blank" rel="noopener">http://www.zsythink.net/archives/447</a> </p>]]></content>
      
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>上传码云</title>
      <link href="/2030/10/26/%E4%B8%8A%E4%BC%A0%E7%A0%81%E4%BA%91/"/>
      <url>/2030/10/26/%E4%B8%8A%E4%BC%A0%E7%A0%81%E4%BA%91/</url>
      
        <content type="html"><![CDATA[<h3 id="【上传码云】命令"><a href="#【上传码云】命令" class="headerlink" title="【上传码云】命令"></a>【上传码云】命令</h3><blockquote><p>第一步，从自己的码云分支上拉下分支</p></blockquote><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://git.oschina.net/shixunone-project/shixunone-nextcloud.git</span><br><span class="line"># https://git.oschina.net/shixunone-project/shixunone-nextcloud.git -&gt; 是你从码云项目上复制下来的</span><br></pre></td></tr></table></figure><blockquote><p>第二步，进入到下载下来的分支项目上</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd shixunone-nextcloud</span><br></pre></td></tr></table></figure><blockquote><p>第三步，没有想上传的 django 项目的，就创建一个。有 你想传的 django 项目的话，就直接拉到这个文件夹即可</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">django-admin startproject textpro1 （自己定义一个django项目名）</span><br></pre></td></tr></table></figure><blockquote><p>第四步，将 django 项目添加到码云</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add 自己定义的django项目名</span><br></pre></td></tr></table></figure><blockquote><p>第五步，将项目提交到码云</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &quot;这里的文字随便编写&quot;</span><br></pre></td></tr></table></figure><blockquote><p>第六步，直接将项目推送到码云</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下如何关闭某个被占用的端口</title>
      <link href="/2030/10/25/Linux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%85%B3%E9%97%AD%E6%9F%90%E4%B8%AA%E8%A2%AB%E5%8D%A0%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3/"/>
      <url>/2030/10/25/Linux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%85%B3%E9%97%AD%E6%9F%90%E4%B8%AA%E8%A2%AB%E5%8D%A0%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="【-Linux-】如何关闭某个被占用的端口"><a href="#【-Linux-】如何关闭某个被占用的端口" class="headerlink" title="【 Linux 】如何关闭某个被占用的端口"></a>【 Linux 】如何关闭某个被占用的端口</h3><a id="more"></a><blockquote><p>1）查找被占用的端口</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">abloume@ubuntu:~$ netstat -tln | grep 8000</span><br><span class="line">tcp        0      0 192.168.2.106:8000      0.0.0.0:*               LISTEN</span><br></pre></td></tr></table></figure><blockquote><p>2）查看被占用端口的PID</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">abloume@ubuntu:~$ lsof -i :8000</span><br><span class="line">COMMAND  PID  USER   FD   TYPE  DEVICE  SIZE/OFF NODE NAME</span><br><span class="line">python3  6072 root   4u   IPv4  612939  0t0  TCP *:irdmi (LISTEN)</span><br></pre></td></tr></table></figure><blockquote><p>3）kill 掉该进程</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abloume@ubuntu:~$ kill 6072 # 6027 -&gt; 进程号PID</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VUE中父子组件传参</title>
      <link href="/2030/10/15/VUE%E4%B8%AD%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E4%BC%A0%E5%80%BC/"/>
      <url>/2030/10/15/VUE%E4%B8%AD%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E4%BC%A0%E5%80%BC/</url>
      
        <content type="html"><![CDATA[<h3 id="父子组件传值通过-props-实现，这种方式只能由父向子传递，子组件不能更新父组件内的datapro"><a href="#父子组件传值通过-props-实现，这种方式只能由父向子传递，子组件不能更新父组件内的datapro" class="headerlink" title="父子组件传值通过 props 实现，这种方式只能由父向子传递，子组件不能更新父组件内的datapro"></a>父子组件传值通过 props 实现，这种方式只能由父向子传递，子组件不能更新父组件内的datapro</h3><a id="more"></a><h4 id="子组件传值通过-emit-实现"><a href="#子组件传值通过-emit-实现" class="headerlink" title="子组件传值通过 emit 实现"></a>子组件传值通过 emit 实现</h4><blockquote><p>父组件给子组件传参：通过 props 方法传值,先定义一个子组件，在父组件中，引入子组件。这一步很简单，想必大家都会吧，这一步就不说了，直接上代码<br>父组件写法：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">      &lt;template&gt;</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        &lt;div&gt;父组件&lt;/div&gt;</span><br><span class="line">        &lt;child :message=&quot;parentMsg&quot;&gt;&lt;/child&gt;  </span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">import child from &apos;./child&apos; //引入child组件</span><br><span class="line">export default &#123;</span><br><span class="line">components: &#123;</span><br><span class="line">            child</span><br><span class="line">        &#125;，</span><br><span class="line">    data() &#123;</span><br><span class="line">            return &#123;</span><br><span class="line">                parentMsg: &apos;father&apos; </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;style&gt;&lt;/style&gt;</span><br></pre></td></tr></table></figure><blockquote><p>子组件写法：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        &lt;div&gt;&#123;&#123;message&#125;&#125;&lt;/div&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">export default &#123;</span><br><span class="line">    props: [&quot;message&quot;]</span><br><span class="line">&#125;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;style&gt;&lt;/style&gt;</span><br></pre></td></tr></table></figure><h4 id="子组件给父组件传参：通过-emit-方法传值"><a href="#子组件给父组件传参：通过-emit-方法传值" class="headerlink" title="子组件给父组件传参：通过 emit 方法传值"></a>子组件给父组件传参：通过 emit 方法传值</h4><blockquote><p>vue文档中是这么解释的：如果子组件想要改变数据呢？这在vue中是不允许的，因为vue只允许单向数据传递，这时候我们可以通过触发事件来通知父组件改变数据，从而达到改变子组件数据的目的.<br>子组件写法</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  &lt;template&gt;</span><br><span class="line">    &lt;div @click=&quot;up&quot;&gt;&lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">methods: &#123;</span><br><span class="line">          up() &#123;</span><br><span class="line">          this.$emit(&apos;upup&apos;,&apos;hehe&apos;); //主动(dispatch)触发upup方法，&apos;hehe&apos;为向父组件传递的数据</span><br><span class="line">          &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>父组件写法：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &lt;child @upup=&quot;change&quot; :msg=&quot;msg&quot;&gt;&lt;/child&gt; //监听子组件触发的upup事件,然后调用change方法</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">methods: &#123;</span><br><span class="line">          change(msg) &#123;</span><br><span class="line">          this.msg = msg;</span><br><span class="line">          &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue中Axios配置</title>
      <link href="/2030/10/11/Vue%E4%B8%ADAxios%E9%85%8D%E7%BD%AE/"/>
      <url>/2030/10/11/Vue%E4%B8%ADAxios%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="Vue中Axios配置"><a href="#Vue中Axios配置" class="headerlink" title="Vue中Axios配置"></a>Vue中Axios配置</h2><a id="more"></a><pre><code>导入：在vue文件main.js中写入（需要安装cnpm install --save axios）import axios from &apos;axios&apos;Vue.prototype.axios = axios  在 build 文件夹中的 webpack.base.conf用const createLintingRule = () =&gt; ({// test: /\.(js|vue)$/,// loader: &apos;eslint-loader&apos;,// enforce: &apos;pre&apos;,// include: [resolve(&apos;src&apos;), resolve(&apos;test&apos;)],// options: {// formatter: require(&apos;eslint-friendly-formatter&apos;),// emitWarning: !config.dev.showEslintErrorsInOverlay// }})替换第一种方法:proxyTable: {    &apos;/api&apos;: {  //使用&quot;/api&quot;来代替&quot;http://f.apiplus.c&quot;     target: &apos;http://127.0.0.1:8000/&apos;, //源地址     changeOrigin: true, //改变源     pathRewrite: {       &apos;^/api&apos;: &apos;&apos; //路径重写       }   } }第二种方法：用Django的第三方包 django-cors-headers 来解决跨域问题操作步骤：1.pip install django-cors-headers2.在settings.py中添加&apos;corsheaders.middleware.CorsMiddleware&apos;,在SessionMiddleware和CommonMiddleware的中间#允许谁请求3.在settings.py中添加CORS_ORIGIN_ALLOW_ALL = True</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Md语法入门1</title>
      <link href="/2030/10/10/MD%E8%AF%AD%E6%B3%95/"/>
      <url>/2030/10/10/MD%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="MD语法入门"><a href="#MD语法入门" class="headerlink" title="MD语法入门"></a>MD语法入门</h1><p>md即markdown文件的基本常用编写语法,是一种快速标记、快速排版语言，现在很多前段项目中的说明文件readme等都是用.md文件编写的，而且很多企业也在在鼓励使用这种编辑方式，特别作为一个前端从业者更要学会使用这种语言。下面就简单和大家分享一些.md基本语法</p><a id="more"></a><h3 id="一、基本符号：-gt"><a href="#一、基本符号：-gt" class="headerlink" title="一、基本符号：* - + . &gt;"></a>一、基本符号：* - + . &gt;</h3><p>基本上所有的markdown标记都是基于这四个符号或组合，需要注意的是，如果以基本符号开头的标记，注意基本符号后有一个用于分割标记符和内容的空格。</p><h3 id="二、标题"><a href="#二、标题" class="headerlink" title="二、标题"></a>二、标题</h3><ol><li><p>前面带#号，后面带文字，分别表示h1-h6,只到h6，而且h1下面会有一条横线</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br><span class="line">#### 四级标题</span><br><span class="line">##### 五级标题</span><br><span class="line">###### 六级标题</span><br></pre></td></tr></table></figure></li><li><p>相当于标签闭合</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题 #</span><br><span class="line">## 二级标题 ##</span><br><span class="line">### 三级标题 ###</span><br><span class="line">#### 四级标题 ####</span><br><span class="line">##### 五级标题 #####</span><br><span class="line">###### 六级标题 #####</span><br></pre></td></tr></table></figure></li></ol><p>效果如下：</p><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6><h3 id="三、列表"><a href="#三、列表" class="headerlink" title="三、列表"></a>三、列表</h3><ol><li>无序列表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//形式一</span><br><span class="line">+ a</span><br><span class="line">+ b</span><br><span class="line">+ c</span><br><span class="line">//形式二</span><br><span class="line">- d</span><br><span class="line">- e</span><br><span class="line">- f</span><br><span class="line">//形式三</span><br><span class="line">* g</span><br><span class="line">* h</span><br><span class="line">* i</span><br></pre></td></tr></table></figure></li></ol><p>以上三种形式，效果是这样的：</p><ul><li>a</li><li>b</li><li>c</li></ul><ul><li>d</li><li>e</li><li>f</li></ul><ul><li><p>g</p></li><li><p>h</p></li><li><p>i</p><blockquote><p>注意，数字后面的点只能是英文的点</p></blockquote></li></ul><blockquote><p>今天有点累，接下来的语法在我的个人博客里面，喜欢可以收藏一下。方便随时观看 <a href="https://wangxiaopeng.top" title="创作你的创作" target="_blank" rel="noopener">老渔夫爱吃锅包肉</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> MD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>创建一个新的 Vue 项目</title>
      <link href="/2030/10/09/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84vue%E9%A1%B9%E7%9B%AE/"/>
      <url>/2030/10/09/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84vue%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="创建一个新的-Vue-项目"><a href="#创建一个新的-Vue-项目" class="headerlink" title="创建一个新的 Vue 项目"></a>创建一个新的 Vue 项目</h2><a id="more"></a><pre><code>- Vue init webpack 项目名- 一路 yes 加 空格- Npm run dev 启动项目- vue中路由去“#”：mode: &apos;history&apos;,</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>django与vue上传照片，通过 sqllite3 手动上传照片配置：</title>
      <link href="/2030/10/08/My-New-Post/"/>
      <url>/2030/10/08/My-New-Post/</url>
      
        <content type="html"><![CDATA[<h3 id="django与vue上传照片，通过-sqllite3-手动上传照片配置："><a href="#django与vue上传照片，通过-sqllite3-手动上传照片配置：" class="headerlink" title="django与vue上传照片，通过 sqllite3 手动上传照片配置："></a>django与vue上传照片，通过 sqllite3 手动上传照片配置：</h3><a id="more"></a><blockquote><p>第一步：</p></blockquote><ul><li>在项目文件夹中创建一个保存照片的文件夹，推荐用 ‘media’，因为后面会用到，现在记住了，后面也方便写。之后在 media 文件夹中再创建一个 ‘img’ 文件夹，负责保存照片</li></ul><blockquote><p>第二步：</p></blockquote><ul><li>在 settings 中配置：代码如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">MEDIA_ROOT = os.path.join(BASE_DIR,&apos;media&apos;)</span><br><span class="line"># 通过 ImageField 上传文件，会自动到‘medtia’文件夹中</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>第三步：</p></blockquote><ul><li>创建表时，创建问价字段选择 ImageField 。</li><li>ImageField 其中有个必写的字段，那就是 ‘upload_to’，这个字段后面填的是数据库存储照片时的地址。代码如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = models.ImageField(upload_to=&apos;img&apos;) </span><br><span class="line"># 这就是上面我们在 media 文件夹中创建 img 文件夹的原因</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>第四步：</p></blockquote><ul><li>配置路由，方便我们在vue中渲染数据</li><li>代码如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from django.urls import path,re_path # 这个是我们创建django项目时自带的，只有后面的re_path是我们后加的</span><br><span class="line">from . import settings</span><br><span class="line">from django.views.static import serve</span><br><span class="line">re_path(&apos;^medtia/(?P&lt;path&gt;.*)/$&apos;,serve,&#123;&apos;document_root&apos;:settings.MEDTIA_ROOT&#125;)</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>在 vue 中我们该如何操作呢？</p></blockquote><ul><li><p>看下面的代码吧：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;input type=&apos;file&apos; id=&apos;img&apos;&gt;</span><br><span class="line">&apos;&apos;&apos;在文件框中，用 id 属性绑定&apos;&apos;&apos;</span><br></pre></td></tr></table></figure></li><li><p>下面的方法中，提取获取到的文件地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">let img = document.getElementById(&apos;img&apos;).files[0]</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>OK！完成，收工</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>uwsgi + nginx + django部署</title>
      <link href="/2030/08/20/uwsgi%20+%20nginx%20+%20django%E9%83%A8%E7%BD%B2/"/>
      <url>/2030/08/20/uwsgi%20+%20nginx%20+%20django%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h2 id="uwsgi-nginx-django"><a href="#uwsgi-nginx-django" class="headerlink" title="uwsgi + nginx + django"></a>uwsgi <strong>+</strong> nginx <strong>+</strong> django</h2><a id="more"></a><h4 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a><strong>nginx</strong>配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">user root;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">error_log  /usr/local/nginx/logs/error.log warn;</span><br><span class="line">pid        /run/nginx.pid;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">    # multi_accept on;</span><br><span class="line">&#125;</span><br><span class="line">http &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80; # 监听端口</span><br><span class="line">        server_name 47.96.189.157; # 访问路径名称</span><br><span class="line">        charset utf-8; # 编码</span><br><span class="line">        include /usr/local/nginx/conf/mime.types;</span><br><span class="line">        access_log /home/qwe/rening/rening/nginx.log;</span><br><span class="line">        location / &#123;</span><br><span class="line">            include /usr/local/nginx/conf/uwsgi_params;</span><br><span class="line">            uwsgi_connect_timeout 30;</span><br><span class="line">            uwsgi_pass  0.0.0.0:8000; # 反向代理的UWSGI端口</span><br><span class="line">        &#125;</span><br><span class="line">        location /static/ &#123;</span><br><span class="line">            alias /home/qwe/rening/static/; # 项目的静态资源路径,固定写法</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="uwsgi配置"><a href="#uwsgi配置" class="headerlink" title="uwsgi配置"></a><strong>uwsgi</strong>配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[uwsgi]</span><br><span class="line">#使用nginx连接时使用，Django程序所在服务器地址</span><br><span class="line">socket= 0.0.0.0:8000</span><br><span class="line">#项目目录</span><br><span class="line">chdir=/home/qwe/rening</span><br><span class="line">module=rening.wsgi:application</span><br><span class="line">#项目中wsgi.py文件的目录，相对于项目目录</span><br><span class="line">wsgi-file=rening/wsgi.py</span><br><span class="line"># 进程数</span><br><span class="line">processes=1</span><br><span class="line"># 线程数</span><br><span class="line">threads=2</span><br><span class="line"># uwsgi服务器的角色</span><br><span class="line">master=true</span><br><span class="line">py-autoreload=1</span><br></pre></td></tr></table></figure><h4 id="django文件配置"><a href="#django文件配置" class="headerlink" title="django文件配置"></a><strong>django</strong>文件配置</h4><blockquote><p>子应用文件夹中添加<strong>uwsgi.ini</strong>文件，里面参考<strong>uwsgi配置</strong></p></blockquote><h4 id="启动nginx命令"><a href="#启动nginx命令" class="headerlink" title="启动nginx命令"></a>启动nginx命令</h4><blockquote><p>进入到nginx文件夹, 输入</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./nginx</span><br></pre></td></tr></table></figure><h4 id="启动uwsgi命令"><a href="#启动uwsgi命令" class="headerlink" title="启动uwsgi命令"></a>启动uwsgi命令</h4><blockquote><p>进入项目文件夹, 输入</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uwsgi -d --ini uwsgi.ini</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB存储引擎</title>
      <link href="/2030/07/15/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E(1)/"/>
      <url>/2030/07/15/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E(1)/</url>
      
        <content type="html"><![CDATA[<h3 id="InnoDB存储引擎"><a href="#InnoDB存储引擎" class="headerlink" title="InnoDB存储引擎"></a>InnoDB存储引擎</h3><p>InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有：<br>1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合<br>2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的<br>3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上<br>4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键<br>5、InnoDB被用在众多需要高性能的大型数据库站点上<br>InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件</p><a id="more"></a><p><strong>MyISAM存储引擎</strong><br>MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但<strong>不支持事物</strong>。MyISAM主要特性有：<br>1、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持<br>2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成<br>3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16<br>4、最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上<br>5、BLOB和TEXT列可以被索引<br>6、NULL被允许在索引的列中，这个值占每个键的0~1个字节<br>7、所有数字键值以高字节优先被存储以允许一个更高的索引压缩<br>8、每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快<br>9、可以把数据文件和索引文件放在不同目录<br>10、每个字符列可以有不同的字符集<br>11、有VARCHAR的表可以固定或动态记录长度<br>12、VARCHAR和CHAR列可以多达64KB<br>使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex）</p><p><strong>MEMORY存储引擎</strong><br>MEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有：<br>1、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度<br>2、MEMORY存储引擎执行HASH和BTREE缩影<br>3、可以在一个MEMORY表中有非唯一键值<br>4、MEMORY表使用一个固定的记录长度格式<br>5、MEMORY不支持BLOB或TEXT列<br>6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引<br>7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表）<br>8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享<br>9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE）</p><h2 id="Archive引擎"><a href="#Archive引擎" class="headerlink" title="Archive引擎"></a>Archive引擎</h2><p>Archive存储引擎只支持Insert和Select操作，在MySQL5.1之前也不支持索引。Archive引擎会缓存所有的写操作并利用zlib对插入的行进行压缩，所以比MyISAM表的磁盘I/O少。但是每次select查询都需要执行全表扫描。所以Archive表适合日志和数据采集类应用，这类应用做数据分析时往往需要权标骚婊。或者在一些需要更快速的insert操作的场合下也可以使用。</p><p>Archive引擎支持行级锁和专用的缓冲区，所以可以实现高并发的插入。在一个查询开始直到返回表中存在的所有行数之前，Archive引擎会组织其他的select执行，以实现一致性读。另外，也实现了批量插入在完成之前对读操作是不可见的。这种机制模仿了事物和MVCC的一些特性，但Archive引擎不是一个事物型的引擎，而是一个针对高速插入和压缩做了优化的简单引擎。</p><h3 id="2-面向列的存储引擎"><a href="#2-面向列的存储引擎" class="headerlink" title="2 面向列的存储引擎"></a>2 面向列的存储引擎</h3><p>MySQL默认是面向行的，每一行的数据时一起存储的，服务器的传也是以行为单位处理的。而在大数据量处理时，可能面向列的方式效率更高。如果不需要整行的数据，面向列的方式可以传输更少的数据。如果每一列都单独村吃醋，那么压缩的效率也会更高。I</p><p>Infobright是最有名的面向列的存储引擎。在非常大的数据量时（数十TB），该引擎工作良好。Infobright是为数据分析和数据仓库应用设计的。数据高度压缩，按照块进行排序，每个块都对应有一组员数据。在处理查询时，访问元数据可以决定跳过该块进行排序，每个块都对应有一组元数据。在处理查询时，访问元数据可决定跳过该块，甚至可能只需要元数据就可以满足查询的需求。但该引擎不支持索引，不过在这么大的数据量级，即使有索引页很难发挥作用，而且块结构也会一种准索引（quasi-index）。Infobright需要对MySQL服务器做定制，因为一些地方需要修改以适应面向列的存储需要。如果查询无法在存储层使用面向列的模式执行，则需要在服务器层转换成按行处理，这个过程会很慢。Infobright有社区版和商业版两种。</p><p>另外一个面向列的存储引擎是Calpont公司的InfiniDB，也有社区版和商业版。InfiniDB可以在一组机器集群间做分布式查询，但目前还没有哦生产环境的应用案例。</p><h4 id="3-社区存储引擎"><a href="#3-社区存储引擎" class="headerlink" title="3 社区存储引擎"></a>3 社区存储引擎</h4><p>如果要列举所有社区提供的引擎可能会有三位数。但是很大部分影响力有限，只有极少数人在使用。在这里举例一些，但都没有在生产环境中应用过，慎用。</p><p>① Aria：之前的名字是Maria，是MySQL创建者计划用来替代MyISAM的一款引擎。MariaDB包含了该引擎，之前计划开发的很多特性因为在MariaDB服务层实现，所以引擎层就取消了。在2013~2014年Aria就是解决了MyISAM的崩溃安全回复问题，当然还有一些特性是MyISAM不具备的，例如 数据的缓存（MyISAM只能缓存索引）。</p><p>② Groonga：这是一款全文索引引擎，号称可以提供准确而高效的全文索引。</p><p>③ OQGraph：该引擎由uOpen Query研发，支持图操作（例如查找两点之间最短的路径），用SQL很难实现该类操作。</p><p>④ Q4M：该引擎在MySQL内部实现了队列操作，这也是SQL很难实现的操作。</p><p>⑤ SphinxSE：该引擎为Sphinx全文索引搜索服务提供了SQL接口。</p><p>⑥ Spider：该引擎可以将数据切分成不同的分区，比较高效透明的实现了分片（shard），并且可以针对分片执行并行查询（可以是分布式的分片）。</p><p>⑦ VPForMySQL：改引擎支持垂直分区，通过一系列的代理存储引擎是新。垂直分区指的是可以将表分成不同列的这，并且单独存储。但对于查询来说，看到的还是一张表。改引擎和Spider的作者是同一人。</p><h3 id="转换表的引擎"><a href="#转换表的引擎" class="headerlink" title="转换表的引擎"></a>转换表的引擎</h3><p>下面接受三种Mysql 数据库将表的存储引擎转换成另外一种引擎。每种方法都有优缺点。</p><p>ALTER TABLE<br>将表的一个引擎修改为另个引擎最简单的办法就是是用alter table 语句，需要执行很长时间。Mysql会按行讲源数据复制到另一新表当中，在复制期间可能会消耗系统所有的I/O能力，同时原表会加上锁。所以在繁忙的表上执行此操作要下心。<br>如果转换表的存储引擎将会丢失和原引擎相关的所有特性。如，将一张InnoDB表转换为MyISAM，然后转换InnoDB，原InnoDB上的所有外键将会丢失。</p><p>导入和导出<br>为了更好的控制转换过程，可是使用mysqldump 工具将数据导入文件中，然后修改文件中的create table 语句中的存储引擎选项，mysqldump 工具默认会在create table 中加上drop 语句。</p><p>创建和查询<br>第三种装换技术综合了第一种的高效和第二种方法的中的安全，不需要导出真个表的数据。而是先创建一个新的存储引擎的表。然后利用 Insert 。。。。select 语句来导出，</p><p>Mysql常见索引有：主键索引、唯一索引、普通索引、全文索引、组合索引</p><p>PRIMARY KEY（主键索引）  ALTER TABLE <code>table_name</code> ADD PRIMARY KEY ( <code>col</code> ) </p><p>UNIQUE(唯一索引)     ALTER TABLE <code>table_name</code> ADD UNIQUE (<code>col</code>)</p><p>INDEX(普通索引)     ALTER TABLE <code>table_name</code> ADD INDEX index_name (<code>col</code>)</p><p>FULLTEXT(全文索引)      ALTER TABLE <code>table_name</code> ADD FULLTEXT ( <code>col</code> )<br>组合索引   ALTER TABLE <code>table_name</code> ADD INDEX index_name (<code>col1</code>, <code>col2</code>, <code>col3</code> ) </p><p>Mysql各种索引区别：<br>普通索引：最基本的索引，没有任何限制<br>唯一索引：与”普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。<br>主键索引：它 是一种特殊的唯一索引，不允许有空值。<br>全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。<br>组合索引：为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。创建复合索引时应该将最常用（频率）作限制条件的列放在最左边，依次递减。</p><p>where  字段从左往右顺序，数据量最少的字段放在最左边，因为这样查询次数会最少</p>]]></content>
      
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sed</title>
      <link href="/2030/07/15/sed(1)/"/>
      <url>/2030/07/15/sed(1)/</url>
      
        <content type="html"><![CDATA[<h2 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h2><p>　　sed（流处理编辑器），处理文本的过程如下：</p><a id="more"></a><p>　　1、从文本或者管道中读入一行内容到模式空间（临时缓冲区）</p><p>　　2、使用sed命令处理，重复第1步，直到文件处理完毕</p><p>　　3、输出到屏幕</p><p>　　注意两点：</p><p>　　1、sed一次处理一行的内容</p><p>　　2、sed默认的不改变文件内容</p><h2 id><a href="#" class="headerlink" title></a></h2><h2 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h2><p>　　</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# cat -n data.txt``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="使用sed的格式"><a href="#使用sed的格式" class="headerlink" title="使用sed的格式"></a>使用sed的格式</h2><p>　　命令行格式：将包含sed的命令写在命令行中执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$ ``sed` `[options] ``'command'` `files`</span><br></pre></td></tr></table></figure><p>　　</p><p>　　脚本格式：将sed的命令写在一个脚本中，然后执行的时候，指定sed脚本的路径即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$ ``sed` `-f scriptfile files`</span><br></pre></td></tr></table></figure><p>　　上面这两个命令中，files都是要进行处理的文件。</p><h2 id="命令行格式"><a href="#命令行格式" class="headerlink" title="命令行格式"></a>命令行格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$``sed` `[options] ``&apos;command&apos;` `files`</span><br></pre></td></tr></table></figure><p>　　options可以使用下面这几个值：</p><p>　　　　-e：可以指定多个command</p><p>　　　　-n：与p（print）命令合用时，表示只显示被选中的行，而不是显示所有的行，然后被选中的行会显示两次。</p><p>　　　　-i：将sed的操作结果更新到文件中，因为默认的是不会操作文件本身的。</p><p>　　command：行定位（正则）+ sed命令，首先会通过正则行定位，选中要进行操作的行，然后执行sed命令</p><h2 id="行定位"><a href="#行定位" class="headerlink" title="行定位"></a>行定位</h2><h3 id="选择1行，可以使用两种方式："><a href="#选择1行，可以使用两种方式：" class="headerlink" title="　　选择1行，可以使用两种方式："></a>　　选择1行，可以使用两种方式：</h3><p>　　　　1、n；　　　　选中1行，n表示行号</p><p>　　　　2、/root/　　使用正则表达式，注意要包含在/…./之间</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #打印第5行``[root@localhost ``test``]``# sed -n "5 p" data.txt``Maecheal    男  30  Washington      America` `[root@localhost ``test``]``# #打印匹配"China"的记录``[root@localhost ``test``]``# sed -n "/china/ p" data.txt``[root@localhost ``test``]``# sed -n "/China/ p" data.txt``小红        女  20  BeiJing         China``小明        男  22  ChongQing       China``花花        女  30  HeBei           China`</span><br></pre></td></tr></table></figure><p>　　</p><h3 id="选择多行，同样有两种方式："><a href="#选择多行，同样有两种方式：" class="headerlink" title="　　选择多行，同样有两种方式："></a>　　选择多行，同样有两种方式：</h3><p>　　　　1、x,y；　　　　选中行号在x~y之间的行</p><p>　　　　2、/小红/, /山本/    选择匹配两个正则表达式之间的行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #打印第3~6行``[root@localhost ``test``]``# cat -n data.txt | sed -n "3,6 p"``     ``3  花花        女  30  HeBei           China``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan` `[root@localhost ``test``]``# #打印“Jane”的行，到“贝爷”之间的行``[root@localhost ``test``]``# sed -n "/Jane/, /贝爷/ p" data.txt``Jane        女  29  Los Angeles     America``Maecheal    男  30  Washington      America``山本        男  25  Nagasaki        Japan``村上春树    男  40  Hiroshima       Japan``贝爷        男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　　　</p><h3 id="不选择某一行或者某几行"><a href="#不选择某一行或者某几行" class="headerlink" title="　　不选择某一行或者某几行"></a>　　不选择某一行或者某几行</h3><p>　　　　在后面加 ！ 即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #打印除了第4行以外的所有行``[root@localhost ``test``]``# cat -n data.txt | sed -n "4! p"``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `[root@localhost ``test``]``# #打印除3-7行之外的行``[root@localhost ``test``]``# cat -n data.txt | sed -n "3,7! p"``     ``1 小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``8  贝爷        男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　 </p><h3 id="间隔几行选择"><a href="#间隔几行选择" class="headerlink" title="　　间隔几行选择"></a>　　间隔几行选择</h3><p>　　　　使用x~y格式，首先打印第x行，然后每个y行，就打印一次</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #打印第3行，之后，每隔2行，就打印一次``[root@localhost ``test``]``# cat -n data.txt | sed -n "3~2 p"``     ``3  花花        女  30  HeBei           China``     ``5  Maecheal    男  30  Washington      America``     ``7  村上春树    男  40  Hiroshima       Japan`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="操作命令"><a href="#操作命令" class="headerlink" title="操作命令"></a>操作命令</h2><p>　　sed有几个基本的操作命令，分别是下面几个：</p><p>　　1、-a (append，添加，在行后追加）</p><p>　　2、-i（insert，插入，在行前插入）</p><p>　　3、-d（delete，删除行）</p><p>　　4、-c（chage，替换）</p><p>　　5、-s（subsitute，替换）</p><h2 id="a-增加行"><a href="#a-增加行" class="headerlink" title="-a 增加行"></a>-a 增加行</h2><p>　　</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #在第3行后面增加一行“---------------”``[root@localhost ``test``]``# cat -n data.txt | sed "3a -------------"``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``-------------``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `     ` `[root@localhost ``test``]``# #在3~5行的每一行后面加一行“==========”``[root@localhost ``test``]``# cat -n data.txt | sed "3,5a =========="``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``==========``     ``4  Jane        女  29  Los Angeles     America``==========``     ``5  Maecheal    男  30  Washington      America``==========``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch`  `[root@localhost ``test``]``# #在每一行后面增加一行“===========”``[root@localhost ``test``]``# cat -n data.txt | sed "a =========="``     ``1  小红        女  20  BeiJing         China``==========``     ``2  小明        男  22  ChongQing       China``==========``     ``3  花花        女  30  HeBei           China``==========``     ``4  Jane        女  29  Los Angeles     America``==========``     ``5  Maecheal    男  30  Washington      America``==========``     ``6  山本        男  25  Nagasaki        Japan``==========``     ``7  村上春树    男  40  Hiroshima       Japan``==========``     ``8  贝爷        男  35  Paris           Franch``==========` `[root@localhost ``test``]``# #在行末增加一行“-------------------”``[root@localhost ``test``]``# sed '$a -------------------------' data.txt``小红        女  20  BeiJing         China``小明        男  22  ChongQing       China``花花        女  30  HeBei           China``Jane        女  29  Los Angeles     America``Maecheal    男  30  Washington      America``山本        男  25  Nagasaki        Japan``村上春树    男  40  Hiroshima       Japan``贝爷        男  35  Paris           Franch``-------------------------`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="i-插入行"><a href="#i-插入行" class="headerlink" title="-i 插入行"></a>-i 插入行</h2><p>　　-i插入行和增加行的操作一样，区别是a是在行之后增加，i是在行之前插入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #在第3行之前增加一行“---------------”``[root@localhost ``test``]``# cat -n data.txt | sed "3i --------------"``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``--------------``     ``3  花花        女  30  HeBei           China``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `[root@localhost ``test``]``# #在第3~5行的每一行之前插入一行"==========="``[root@localhost ``test``]``# cat -n data.txt | sed "3,5i ==========="``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``===========``     ``3  花花        女  30  HeBei           China``===========``     ``4  Jane        女  29  Los Angeles     America``===========``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch``[root@localhost ``test``]``# #在每一行之前插入一行"==========="``[root@localhost ``test``]``# cat -n data.txt | sed "i ==========="``===========``     ``1  小红        女  20  BeiJing         China``===========``     ``2  小明        男  22  ChongQing       China``===========``     ``3  花花        女  30  HeBei           China``===========``     ``4  Jane        女  29  Los Angeles     America``===========``     ``5  Maecheal    男  30  Washington      America``===========``     ``6  山本        男  25  Nagasaki        Japan``===========``     ``7  村上春树    男  40  Hiroshima       Japan``===========``     ``8  贝爷        男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="c-替换行"><a href="#c-替换行" class="headerlink" title="-c 替换行"></a>-c 替换行</h2><p>　　替换行，是指，将指定行，整行内容都替换为指定内容，注意-s是指替换行中的一部分内容。</p><p>　　注意，区间替换的时候，是整体替换，而不是逐行替换。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #将第2行替换为"hello shell"``[root@localhost ``test``]``# cat -n data.txt | sed "2c hello world"``     ``1  小红        女  20  BeiJing         China``hello world``     ``3  花花        女  30  HeBei           China``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `[root@localhost ``test``]``# #尝试将第2~5行的每一行都替换为"hello world"，但是实际操作后会将2-5行整体替换``[root@localhost ``test``]``# cat -n data.txt | sed "2,5c hello world"``     ``1  小红        女  20  BeiJing         China``hello world``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `[root@localhost ``test``]``# #将每一行都替换为“hello world”``[root@localhost ``test``]``# cat -n data.txt | sed "c hello world"``hello world``hello world``hello world``hello world``hello world``hello world``hello world``hello world`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="d-删除行"><a href="#d-删除行" class="headerlink" title="-d 删除行"></a>-d 删除行</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #删除第4行``[root@localhost ``test``]``# cat -n data.txt | sed "4d"``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `[root@localhost ``test``]``# #删除第4-6行``[root@localhost ``test``]``# cat -n data.txt | sed "4,6d"``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch` `[root@localhost ``test``]``# #删除所有行（无意义）``[root@localhost ``test``]``# cat -n data.txt | sed "d"`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="s-替换行的部分内容"><a href="#s-替换行的部分内容" class="headerlink" title="-s 替换行的部分内容"></a>-s 替换行的部分内容</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #将字符a替换为X``[root@localhost ``test``]``# sed 's/a/X/' data.txt``小红        女  20  BeiJing         ChinX``小明        男  22  ChongQing       ChinX``花花        女  30  HeBei           ChinX``JXne        女  29  Los Angeles     America``MXecheal    男  30  Washington      America``山本        男  25  NXgasaki        Japan``村上春树    男  40  HiroshimX       Japan``贝爷        男  35  PXris           Franch`</span><br></pre></td></tr></table></figure><p>　　注意，在替换的时候，只替换了一次，即只替换第一个匹配的内容。如果要将满足条件的内容都替换，就需要加上g</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# sed &apos;s/a/X/g&apos; data.txt``小红        女  20  BeiJing         ChinX``小明        男  22  ChongQing       ChinX``花花        女  30  HeBei           ChinX``JXne        女  29  Los Angeles     AmericX``MXecheXl    男  30  WXshington      AmericX``山本        男  25  NXgXsXki        JXpXn``村上春树    男  40  HiroshimX       JXpXn``贝爷        男  35  PXris           FrXnch`</span><br></pre></td></tr></table></figure><p>　　 </p><h2 id="sed试题"><a href="#sed试题" class="headerlink" title="sed试题"></a>sed试题</h2><p>　　1、在文件的第8行下面增加一行“hello world”，并且hello world前面要有4个空格</p><p>　　</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# ifconfig eth0``eth0      Link encap:Ethernet  HWaddr 00:0C:29:21:0C:0F``          ``inet addr:192.168.228.153  Bcast:192.168.228.255  Mask:255.255.255.0``          ``inet6 addr: fe80::20c:29ff:fe21:c0f``/64` `Scope:Link``          ``UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1``          ``RX packets:27644 errors:0 dropped:0 overruns:0 frame:0``          ``TX packets:14175 errors:0 dropped:0 overruns:0 carrier:0``          ``collisions:0 txqueuelen:1000``          ``RX bytes:22947297 (21.8 MiB)  TX bytes:1135056 (1.0 MiB)` `[root@localhost ``test``]``# ifconfig eth0 | sed -n '/inet addr:/ p'``          ``inet addr:192.168.228.153  Bcast:192.168.228.255  Mask:255.255.255.0` `[root@localhost ``test``]``# ifconfig eth0 | sed -n '/inet addr:/ p' | sed 's/.*inet addr://'``192.168.228.153  Bcast:192.168.228.255  Mask:255.255.255.0` `[root@localhost ``test``]``# ifconfig eth0 | sed -n '/inet addr:/ p' | sed 's/.*inet addr://' | sed 's/B.*$//'``192.168.228.153`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="高级sed操作"><a href="#高级sed操作" class="headerlink" title="高级sed操作"></a>高级sed操作</h2><p>　　包括以下内容：</p><p>　　　　1、{command1; command2; command 3}多个sed命令，使用“；”分开</p><p>　　　　2、n表示跳1行</p><p>　　　　3、&amp;表示前面已经匹配的字符串内容，反向引用，不用再写一次正则表达式</p><p>　　　　　　</p><h2 id="多个sed命令"><a href="#多个sed命令" class="headerlink" title="多个sed命令"></a>多个sed命令</h2><p>　　使用花括号{   }将多个sed命令包含在一起，多个sed之间用；分开</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# cat -n data.txt``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch``[root@localhost ``test``]``# cat -n data.txt | sed '&#123;3,5 d; s/China/Chinese/&#125;'``     ``1  小红        女  20  BeiJing         Chinese``     ``2  小明        男  22  ChongQing       Chinese``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="跳行"><a href="#跳行" class="headerlink" title="跳行"></a>跳行</h2><p>　　打印奇数行和偶数行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #打印奇数行``[root@localhost ``test``]``# cat -n data.txt | sed -n '1~2 p'``     ``1  小红        女  20  BeiJing         China``     ``3  花花        女  30  HeBei           China``     ``5  Maecheal    男  30  Washington      America``     ``7  村上春树    男  40  Hiroshima       Japan``[root@localhost ``test``]``# cat -n data.txt | sed -n '&#123;p; n&#125;'``     ``1  小红        女  20  BeiJing         China``     ``3  花花        女  30  HeBei           China``     ``5  Maecheal    男  30  Washington      America``     ``7  村上春树    男  40  Hiroshima       Japan``[root@localhost ``test``]``#``[root@localhost ``test``]``# #打印偶数行``[root@localhost ``test``]``# cat -n data.txt | sed -n '2~2 p'``     ``2  小明        男  22  ChongQing       China``     ``4  Jane        女  29  Los Angeles     America``     ``6  山本        男  25  Nagasaki        Japan``     ``8  贝爷        男  35  Paris           Franch``[root@localhost ``test``]``# cat -n data.txt | sed -n '&#123;n; p&#125;'``     ``2  小明        男  22  ChongQing       China``     ``4  Jane        女  29  Los Angeles     America``     ``6  山本        男  25  Nagasaki        Japan``     ``8  贝爷        男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　可以使用多个n来进行跳过</p><h2 id="amp-反向引用"><a href="#amp-反向引用" class="headerlink" title="&amp;反向引用"></a>&amp;反向引用</h2><p>　　&amp;表示前面已经匹配的字符串内容，反向引用，不用再写一次正则表达式</p><p>　　在男或者女之前加一个gender单词</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[男|女]/gender:[男|女]/&apos;``     ``1  小红        gender:[男|女]  20  BeiJing         China``     ``2  小明        gender:[男|女]  22  ChongQing       China``     ``3  花花        gender:[男|女]  30  HeBei           China``     ``4  Jane        gender:[男|女]  29  Los Angeles     America``     ``5  Maecheal    gender:[男|女]  30  Washington      America``     ``6  山本        gender:[男|女]  25  Nagasaki        Japan``     ``7  村上春树    gender:[男|女]  40  Hiroshima       Japan``     ``8  贝爷        gender:[男|女]  35  Paris           Franch``[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[男|女]/gender:&amp;/&apos;``     ``1  小红        gender:女  20  BeiJing         China``     ``2  小明        gender:男  22  ChongQing       China``     ``3  花花        gender:女  30  HeBei           China``     ``4  Jane        gender:女  29  Los Angeles     America``     ``5  Maecheal    gender:男  30  Washington      America``     ``6  山本        gender:男  25  Nagasaki        Japan``     ``7  村上春树    gender:男  40  Hiroshima       Japan``     ``8  贝爷        gender:男  35  Paris           Franch`</span><br></pre></td></tr></table></figure><p>　　</p><p>　　案例1：将2.txt中的所有字母都变为大写</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# cat -n data.txt``     ``1  小红        女  20  BeiJing         China``     ``2  小明        男  22  ChongQing       China``     ``3  花花        女  30  HeBei           China``     ``4  Jane        女  29  Los Angeles     America``     ``5  Maecheal    男  30  Washington      America``     ``6  山本        男  25  Nagasaki        Japan``     ``7  村上春树    男  40  Hiroshima       Japan``     ``8  贝爷        男  35  Paris           Franch``[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[A-Z]/\l&amp;/g&apos;``     ``1  小红        女  20  beijing         china``     ``2  小明        男  22  chongqing       china``     ``3  花花        女  30  hebei           china``     ``4  jane        女  29  los angeles     america``     ``5  maecheal    男  30  washington      america``     ``6  山本        男  25  nagasaki        japan``     ``7  村上春树    男  40  hiroshima       japan``     ``8  贝爷        男  35  paris           franch``[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[a-z]/\u&amp;/g&apos;``     ``1  小红        女  20  BEIJING         CHINA``     ``2  小明        男  22  CHONGQING       CHINA``     ``3  花花        女  30  HEBEI           CHINA``     ``4  JANE        女  29  LOS ANGELES     AMERICA``     ``5  MAECHEAL    男  30  WASHINGTON      AMERICA``     ``6  山本        男  25  NAGASAKI        JAPAN``     ``7  村上春树    男  40  HIROSHIMA       JAPAN``     ``8  贝爷        男  35  PARIS           FRANCH`</span><br></pre></td></tr></table></figure><h2 id="r-复制指定文件插入到匹配行"><a href="#r-复制指定文件插入到匹配行" class="headerlink" title="-r 复制指定文件插入到匹配行"></a>-r 复制指定文件插入到匹配行</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# cat A.txt``111111``222222``333333``[root@localhost ``test``]``# cat B.txt``AAAAAAA``BBBBBBB``CCCCCCC`</span><br></pre></td></tr></table></figure><p>　　</p><p>　　将A.txt中的内容，插入到B.txt的第2行后面</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #将A.txt中的内容插入到B.txt中的第2行后面``[root@localhost ``test``]``# sed &apos;2 r A.txt&apos; B.txt``AAAAAAA``BBBBBBB``111111``222222``333333``CCCCCCC``[root@localhost ``test``]``# #将A.txt中的内容插入到B.txt中包含CCCCCC的行后面``[root@localhost ``test``]``# sed &apos;/CCCCCC/ r A.txt&apos; B.txt``AAAAAAA``BBBBBBB``CCCCCCC``111111``222222``333333``[root@localhost ``test``]``# #将A.txt中的内容插入B.txt中每一行的后面``[root@localhost ``test``]``# sed &apos;r A.txt&apos; B.txt``AAAAAAA``111111``222222``333333``BBBBBBB``111111``222222``333333``CCCCCCC``111111``222222``333333`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="w-复制匹配行，拷贝到指定文件中"><a href="#w-复制匹配行，拷贝到指定文件中" class="headerlink" title="-w 复制匹配行，拷贝到指定文件中"></a>-w 复制匹配行，拷贝到指定文件中</h2><p>　　对于1.txt中选中的行，保存到文件2.txt中，会首先清空2.txt的内容，然后将选中的行拷贝出来，再保存到B.txt中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #将A.txt中的2-4行，写到C.txt中，注意会先清空C.txt``[root@localhost ``test``]``# sed &apos;2,4 w C.txt&apos; A.txt``111111``222222``333333``[root@localhost ``test``]``# cat C.txt``222222``333333`</span><br></pre></td></tr></table></figure><p>　　</p><h2 id="q-提前退出sed"><a href="#q-提前退出sed" class="headerlink" title="-q 提前退出sed"></a>-q 提前退出sed</h2><p>　　sed的处理流程是：从文件中读入一行，然后sed处理一行，一直到文件结束为止。</p><p>　　使用q，可以让sed提前结束，不用读到文件结束。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[root@localhost ``test``]``# #打印前3行``[root@localhost ``test``]``# sed '3 q' data.txt``小红        女  20  BeiJing         China``小明        男  22  ChongQing       China``花花        女  30  HeBei           China``[root@localhost ``test``]``#``[root@localhost ``test``]``# #找到第1个Japan``[root@localhost ``test``]``# sed '/Japan/ q' data.txt``小红        女  20  BeiJing         China``小明        男  22  ChongQing       China``花花        女  30  HeBei           China``Jane        女  29  Los Angeles     America``Maecheal    男  30  Washington      America``山本        男  25  Nagasaki        Japan`</span><br></pre></td></tr></table></figure><p>　　</p>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL的Innodb引擎</title>
      <link href="/2030/06/15/mysql_innodb/"/>
      <url>/2030/06/15/mysql_innodb/</url>
      
        <content type="html"><![CDATA[<h4 id="Innodb-介绍"><a href="#Innodb-介绍" class="headerlink" title="Innodb 介绍"></a>Innodb 介绍</h4><blockquote><p>InnoDB引擎的优点是支持兼容ACID的事务，以及参数完整性（即对外键的支持）。<br>Oracle公司2005年10月收购了Innovase；mysql5.5.5之后数据库的默认存储引擎为InnoDB</p></blockquote><a id="more"></a><h6 id="Innodb-的特点"><a href="#Innodb-的特点" class="headerlink" title="Innodb 的特点"></a>Innodb 的特点</h6><blockquote><p>1.支持事务，支持4个事务隔离级别，支持多版本读。<br>2.行级锁定（更新时一般是锁定当前行），通过索引实现，全表扫描仍然会是表锁，注意间隙锁的影响。<br>3.读写阻塞与事务隔离级别相关。<br>4.具有非常高效的缓存特性：能缓存索引，也能缓存数据。<br>5.整个表和主键以Cluster方式存储，组成一个平衡树。<br>6.所有Secondary Index都会保存主键信息。<br>7.支持分区，表空间，类似oracle数据库。<br>8.支持外键约束，5.5之前不支持全文索引，5.5之后支持外键索引。<br>9.和Myisam引擎比，Innodb对硬件资源要求比较高</p></blockquote><p>InnoDB:支持行级锁(row-level locking)和表级锁,默认为行级锁。</p><h6 id="Innodb-引擎适用的生产业务场景"><a href="#Innodb-引擎适用的生产业务场景" class="headerlink" title="Innodb 引擎适用的生产业务场景"></a>Innodb 引擎适用的生产业务场景</h6><blockquote><p>1、需要事务支持的业务（具有较好的事务特性）<br>2、行级锁定对高并发有很好的适应能力，但需要确保查询时通过索引完成。<br>3、数据读写及更新都较为频繁的场景，如：bbs，sns，微博，微信等。<br>4、数据一致性要求较高的业务，例如：充值转账，银行卡转账。<br>5、硬件设备内存较大，可以利用Innodb较好的缓存能力来提高内存利用率，尽可能减少磁盘IO。</p><p>innodb_buffer_pool_size = 2048M<br>innodb_buffer_pool_size = 64M  #InnoDB使用一个缓冲池来保存索引和原始数据，设置越大，在存取表里面数据时所需要的磁盘I/O越少。强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。<br>16G内存多实例差不多给2G</p></blockquote><h4 id="Innodb存储引擎"><a href="#Innodb存储引擎" class="headerlink" title="Innodb存储引擎"></a>Innodb存储引擎</h4><blockquote><p>Innodb是事务型数据库的首选引，支持事物安全表(ACID)</p><blockquote><p>事务的ACID属性：即原子性、一致性、隔离性、持久性</p><blockquote><p>a.原子性：原子性也就是说这组语句要么全部执行，要么全部不执行，如果事务执行到一半出现错误，数据库就要回滚到事务开始执行的地方。</p></blockquote></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">实现：主要是基于MySQ日志系统的redo和undo机制。事务是一组SQL语句，里面有选择，查询、删除等功能。每条语句执行会有一个节点。例如，删除语句执行后，在事务中有个记录保存下来，这个记录中储存了我们什么时候做了什么事。如果出错了，就会回滚到原来的位置，redo里面已经存储了我做过什么事了，然后逆向执行一遍就可以了。</span><br></pre></td></tr></table></figure><blockquote><blockquote><blockquote><p> b.一致性：事务开始前和结束后，数据库的完整性约束没有被破坏。(eg:比如A向B转账，不可能A扣了钱，B却没有收到)<br>c.隔离性：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰；</p></blockquote></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">如果不考虑隔离性则会出现几个问题：</span><br><span class="line">                                 a、脏读：是指在一个事务处理过程里读取了另一个未提交的事务中的数据（当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致）；（读取了另一个事务未提交的脏数据）</span><br><span class="line">                                 aa、不可重复读：在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了；（读取了前一个事务提交的数据，查询的都是同一个数据项）</span><br><span class="line">                                 aaa、虚读（幻读）：是事务非独立执行时发生的一种现象（eg:事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样）；（读取了前一个事务提交的数据，针对一批数据整体）</span><br></pre></td></tr></table></figure><blockquote><blockquote><blockquote><p>d.持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚</p></blockquote></blockquote></blockquote><h6 id="MySQL数据库为我们提供的四种隔离级别："><a href="#MySQL数据库为我们提供的四种隔离级别：" class="headerlink" title="MySQL数据库为我们提供的四种隔离级别："></a>MySQL数据库为我们提供的四种隔离级别：</h6><blockquote><p>1、Serializable（串行化）：可避免脏读、不可重复读、幻读的发生；</p><p>2、Repeatable read（可重复读）：可避免脏读、不可重复读的发生；</p><p>3、Read committed（读已提交）：可避免脏读的发生；</p><p>4、Read uncommitted（读未提交）：最低级别，任何情况都无法保证；</p><blockquote><p>从1—-4隔离级别由高到低，级别越高，执行效率越低</p></blockquote></blockquote><p>InnoDB的存储文件有两个，后缀名分别是 .frm和 .idb；其中 .frm是表的定义文件， .idb是表的数据文件。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL的MEMORY引擎</title>
      <link href="/2030/06/15/mysql_memory/"/>
      <url>/2030/06/15/mysql_memory/</url>
      
        <content type="html"><![CDATA[<h4 id="MEMORY-介绍"><a href="#MEMORY-介绍" class="headerlink" title="MEMORY 介绍"></a>MEMORY 介绍</h4><blockquote><p>MEMORY存储引擎创建的表数据只能保存在内存。</p><p>memoery存储引擎是在内存中来创建表，每个memory表只实际对应一个磁盘文件格式是.frm.  该引擎的表访问非常得快，因为数据是放在内存中，且默认是hash索引，但服务关闭，表中的数据就会丢失掉。</p><p>MySQL宕机、硬件故障或者意外掉电，都会造成MEMORY引擎表丢失数据。所以，MEMORY表中的数据来源于其他表(可落盘永久保存)用于只读适用，或者用于临时工作起到数据周转。</p><p>服务器需要足够的内存来维护所有在同一时间使用的memory表，当不再需要时，要释放，应执行 delete from 或 truncate table 或删除表drop table。</p><p>每个memory表放置的数据量大小，受到max_heap_table_size系统变量的约束，初始值是16MB. 通过max_rows 子句指定表的最大行数。</p></blockquote><a id="more"></a><h4 id="MEMORY-引擎的特点"><a href="#MEMORY-引擎的特点" class="headerlink" title="MEMORY 引擎的特点"></a>MEMORY 引擎的特点</h4><blockquote><p>memeory存储引擎使用hash索引对于等值查找是很高效的</p><p>比较容易丢失数据 </p></blockquote><h4 id="MEMORY-引擎适用的生产业务场景"><a href="#MEMORY-引擎适用的生产业务场景" class="headerlink" title="MEMORY 引擎适用的生产业务场景"></a>MEMORY 引擎适用的生产业务场景</h4><blockquote><p>临时使用、不重要的数据，例如网站的会话管理和缓存。可接受数据丢失<br>可以用于存储在分析中产生的中间表<br>使用memroy存储引擎的表一定要是可以再生的或者是不需要的</p></blockquote><blockquote><p>小结：据保存在ram(内存)中，访问速度快，但对表的大小有限制，要确保数据是可以恢复的，常用于更新不太频繁的小表，用以快速访问。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql MEMORY引擎 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL存储引擎如何选择</title>
      <link href="/2030/06/15/mysql_select/"/>
      <url>/2030/06/15/mysql_select/</url>
      
        <content type="html"><![CDATA[<h4 id="定义以及作用"><a href="#定义以及作用" class="headerlink" title="定义以及作用"></a>定义以及作用</h4><blockquote><p>数据库引擎是用于存储、处理和保护数据的核心服务。</p><p>利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。 </p><p>使用数据库引擎创建用于联机(客户端与服务端能够实时通信。由客户机发起，直到服务器确认。)事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）。</p></blockquote><a id="more"></a><h4 id="Mysql的存储引擎有哪些："><a href="#Mysql的存储引擎有哪些：" class="headerlink" title="Mysql的存储引擎有哪些："></a>Mysql的存储引擎有哪些：</h4><blockquote><p>InnoDB</p><blockquote><p>这是MySQL 5.5或更高版本的默认存储引擎。它提供了事务安全(ACID兼容)表，支持外键引用完整性约束。它支持提交、回滚和紧急恢复功能来保护数据。它还支持行级锁定。当在多用户环境中使用时，它的“一致非锁定读取”提高了性能。它将数据存储在集群索引中，从而减少了基于主键的查询的I/O。</p></blockquote></blockquote><blockquote><p>MyISAM</p><blockquote><p>该存储引擎管理非事务性表，提供高速存储和检索，支持全文搜索。</p></blockquote></blockquote><blockquote><p>MEMORY</p><blockquote><p>提供内存中的表，以前称为堆。它在RAM中处理所有数据，以便比在磁盘上存储数据更快地访问。用于快速查找引用和其他相同的数据。</p></blockquote></blockquote><h4 id="修改数据库引擎"><a href="#修改数据库引擎" class="headerlink" title="修改数据库引擎"></a>修改数据库引擎</h4><blockquote><p>方式壹：</p><blockquote><p>修改配置文件my.ini</p><p>将mysql.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=Innodb,重启服务，数据库默认的引擎修改为Innodb</p></blockquote></blockquote><blockquote><p>方式贰：</p><blockquote><p>在建表得时候指定</p><p>create table table_name(你的各个字段名)type=MyISAM;</p></blockquote></blockquote><blockquote><p>方式叁：</p><blockquote><p>建表后更改</p><p>alert table table_name type=Innodb;</p></blockquote></blockquote><h4 id="如何查看是否修改成功-查看当前数据库的引擎"><a href="#如何查看是否修改成功-查看当前数据库的引擎" class="headerlink" title="如何查看是否修改成功(查看当前数据库的引擎)"></a>如何查看是否修改成功(查看当前数据库的引擎)</h4><blockquote><p>方式壹：</p><blockquote><p>show table status from table_name;</p></blockquote></blockquote><blockquote><p>方拾贰：</p><blockquote><p>show create table table_name;</p></blockquote></blockquote><blockquote><p>方式叁：</p><blockquote><p>使用数据库管理工具(具体自己去问度娘)<br>注意：不同版本之间有可能命令有些不同</p></blockquote></blockquote><h4 id="MyISAM、InnoDB和MEMORY引擎之间的区别"><a href="#MyISAM、InnoDB和MEMORY引擎之间的区别" class="headerlink" title="MyISAM、InnoDB和MEMORY引擎之间的区别:"></a>MyISAM、InnoDB和MEMORY引擎之间的区别:</h4><blockquote><p>InnoDB存储引擎</p><blockquote><p>InnoDB给MySQL的表提供了事务处理、回滚、崩溃修复能力和多版本并发控制的事务安全。在MySQL从3.23.34a开始包含InnnoDB。它是MySQL上第一个提供外键约束的表引擎。而且InnoDB对事务处理的能力，也是其他存储引擎不能比拟的。靠后版本的MySQL的默认存储引擎就是InnoDB。</p><p>InnoDB存储引擎总支持AUTO_INCREMENT。自动增长列的值不能为空，并且值必须唯一。MySQL中规定自增列必须为主键。在插入值的时候，如果自动增长列不输入值，则插入的值为自动增长后的值；如果输入的值为0或空（NULL），则插入的值也是自动增长后的值；如果插入某个确定的值，且该值在前面没有出现过，就可以直接插入。</p><p>InnoDB还支持外键（FOREIGN KEY）。外键所在的表叫做子表，外键所依赖（REFERENCES）的表叫做父表。父表中被字表外键关联的字段必须为主键。当删除、更新父表中的某条信息时，子表也必须有相应的改变，这是数据库的参照完整性规则。</p><p>InnoDB中，创建的表的表结构存储在.frm文件中（我觉得是frame的缩写吧）。数据和索引存储在innodb_data_home_dir和innodb_data_file_path定义的表空间中。</p><p>InnoDB的优势在于提供了良好的事务处理、崩溃修复能力和并发控制。缺点是读写效率较差，占用的数据空间相对较大。</p></blockquote></blockquote><blockquote><p>MyISAM存储引擎</p><blockquote><p>MyISAM是MySQL中常见的存储引擎，曾经是MySQL的默认存储引擎。MyISAM是基于ISAM引擎发展起来的，增加了许多有用的扩展。</p><p>MyISAM的表存储成3个文件。文件的名字与表名相同。拓展名为frm、MYD、MYI。其实，frm文件存储表的结构；MYD文件存储数据，是MYData的缩写；MYI文件存储索引，是MYIndex的缩写。</p><p>基于MyISAM存储引擎的表支持3种不同的存储格式。包括静态型、动态型和压缩型。其中，静态型是MyISAM的默认存储格式，它的字段是固定长度的；动态型包含变长字段，记录的长度不是固定的；压缩型需要用到myisampack工具，占用的磁盘空间较小。</p><p>MyISAM的优势在于占用空间小，处理速度快。缺点是不支持事务的完整性和并发性。</p></blockquote></blockquote><blockquote><p>MEMORY存储引擎</p><blockquote><p>MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且数据全部放在内存中。这些特性与前面的两个很不同。</p><p>每个基于MEMORY存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为frm类型。该文件中只存储表的结构。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。值得注意的是，服务器需要有足够的内存来维持MEMORY存储引擎的表的使用。如果不需要了，可以释放内存，甚至删除不需要的表。</p><p>MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。</p><p>注意，MEMORY用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于MEMORY的表的生命周期很短，一般是一次性的</p></blockquote></blockquote><h4 id="怎样选择合理的存储引擎"><a href="#怎样选择合理的存储引擎" class="headerlink" title="怎样选择合理的存储引擎"></a>怎样选择合理的存储引擎</h4><blockquote><p>InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）。 </p><p>MyISAM：插入数据快，空间和内存使用比较低。如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性、并发性要求比 较低，也可以使用。</p><p>MEMORY：所有的数据都在内存中，数据的处理速度快，但是安全性不高。如果需要很快的读写速度，对数据的安全性要求较低，可以选择MEMOEY。它对表的大小有要求，不能建立太大的表。所以，这类数据库只使用在相对较小的数据库表。</p><p>注意，同一个数据库也可以使用多种存储引擎的表。如果一个表要求比较高的事务处理，可以选择InnoDB。这个数据库中可以将查询要求比较高的表选择MyISAM存储。如果该数据库需要一个用于查询的临时表，可以选择MEMORY存储引擎。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Mysql存储引擎如何选择 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL的MyISAM引擎</title>
      <link href="/2030/05/08/mysql_myisam/"/>
      <url>/2030/05/08/mysql_myisam/</url>
      
        <content type="html"><![CDATA[<h4 id="MyISAM-介绍"><a href="#MyISAM-介绍" class="headerlink" title="MyISAM 介绍"></a>MyISAM 介绍</h4><blockquote><p>myisam引擎是MySQL关系数据库系统的默认储存引擎（mysql 5.5.5之前）。这种MySQL表存储结构从旧的ISAM代码扩展出许多有用的功能。在新版本的Mysql中，Innodb引擎由于其对事务参照完整性，以及更高的并发性等优点开始逐步取代Myisam引擎。<br>MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。</p><p>MySQL的MyISAM存储引擎支持压缩表空间，压缩后的表空间会减少，但是压缩后的表是只读的，不能插入和更新数据，如果需要更新，则需要解压后更新，再压缩 。</p><p>每一个myisam的表都对应于硬盘上的三个文件。这三个文件有一样的文件名，但是有不同的扩展名指示其类型用途：.frm文件保存表的定义，这个文件并不是myisam引擎的一部分，而是服务器的一部分；.MYD保存表的数据；.MYI是表的索引文件。.MYD和.MYI是MyISAM的关键点。</p></blockquote><a id="more"></a><h4 id="MyASAM-引擎的特点"><a href="#MyASAM-引擎的特点" class="headerlink" title="MyASAM 引擎的特点"></a>MyASAM 引擎的特点</h4><blockquote><p>1.不支持事务（事务是指逻辑上的一组操作，组成这组操作的各个单元，要么全成功要么全失败）<br>2.表级锁定，数据更新时锁定整个表：其锁定机制是表级锁定，这虽然可以让锁定的实现成本很小但是也同时大大降低了其并发性能。<br>3.读写互相阻塞：不仅会在写入的时候阻塞读取，myisam还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读。<br>4.只会缓存索引：myisam可以通过key_buffer_size缓存索引，以大大提高访问性能，减少产品IO，但是这个缓存区只会缓存索引，而不会缓存数据。<br>key_buffer_size = 16M<br>5.读取速度较快，占用资源相对少。<br>6.不支持外键约束，但支持全文索引。</p></blockquote><h4 id="MyISAM-引攀适用的生产业务场景，"><a href="#MyISAM-引攀适用的生产业务场景，" class="headerlink" title="MyISAM 引攀适用的生产业务场景，"></a>MyISAM 引攀适用的生产业务场景，</h4><blockquote><p>1.不需要事务支持的业务（例如转账就不行）。<br>2.一般为读数据比较多的应用，读写都频繁场景不适合，读多或者写多的都适合。<br>3.读写并发访问相对较低的业务（纯读纯写高并发也可以）（锁定机制问题）<br>4.数据修改相对较少的业务（阻塞问题）。<br>5.以读为主的业务，例如：数据库系统表、www， blog ，图片信息数据库，用户数据库，商品库等业务。<br>6.对数据一致性要求不是非常高的业务（不支持事务）。<br>7.硬件资源比较差的机器可以用 MyiSAM （占用资源少）<br>8.使用读写分离的 MySQL 从库可以使用 MyISAM。</p></blockquote><blockquote><p>小结：单一对数据库的操作都可以使用MyiSAM，所谓单一就是尽量纯读，或纯写 ( insert . update , delete ）等</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker</title>
      <link href="/2030/03/30/Docker%E7%AE%A1%E7%90%86/"/>
      <url>/2030/03/30/Docker%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是Docker"><a href="#什么是Docker" class="headerlink" title="什么是Docker"></a>什么是Docker</h2><ul><li><h6 id="Docker是世界领先的软件容器平台。"><a href="#Docker是世界领先的软件容器平台。" class="headerlink" title="Docker是世界领先的软件容器平台。"></a>Docker是世界领先的软件容器平台。</h6></li><li><p>Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docke最初实现是基于LXC。也就是说docker是宿主机上的一个独立隔离的进程。</p></li><li><p>Docker能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。</p></li><li><p>用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。</p></li></ul><a id="more"></a><h2 id="Docker与传统虚拟化方式区别："><a href="#Docker与传统虚拟化方式区别：" class="headerlink" title="Docker与传统虚拟化方式区别："></a>Docker与传统虚拟化方式区别：</h2><p>两者不同之处在于，传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整的操作系统，然后在该系统上运行所需应用进程。而docker容器内的应用进程直接直接运行于宿主机的内核，容器没有自己的内核，也没有自己的硬件虚拟。</p><!--Docker并不是模拟一套操作系统，而是对进程进行隔离，相当于在一个正常的进程外面套了一层保护罩，对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离--><h4 id="Docker对比传统虚拟机总结-："><a href="#Docker对比传统虚拟机总结-：" class="headerlink" title="Docker对比传统虚拟机总结 ："></a>Docker对比传统虚拟机总结 ：</h4><p>​    ![](C:\Users\张xiao\Pictures\Saved Pictures\docker.jpg)</p><h2 id="Docker的好处："><a href="#Docker的好处：" class="headerlink" title="Docker的好处："></a>Docker的好处：</h2><ul><li>Docker的镜像提供了除了内核外完整的运行环境，从而确保了应用运行环境的一致性。——一致的运行环境</li><li>可以做到秒级甚至毫秒级的启动速度，节约时间。——快速的启动速度</li><li>避免公用的服务器，资源会容易收到其他用户的影响。——隔离性</li><li>可以很轻易的移植到另一个平台上运行，不用担心运行环境的变化而导致应用无法正常运行。——迁移方便</li></ul><h3 id="Docker的三个基本概念："><a href="#Docker的三个基本概念：" class="headerlink" title="Docker的三个基本概念："></a>Docker的三个基本概念：</h3><h4 id="镜像-容器-仓库"><a href="#镜像-容器-仓库" class="headerlink" title="镜像  容器   仓库**"></a>镜像  容器   仓库**</h4><p> 先来一句话总结下这三个之间的关系：镜像是Docker运行容器的前提，仓库是存放镜像的场所，可见镜像更是Docker的核心</p><h4 id="1-镜像"><a href="#1-镜像" class="headerlink" title="1.镜像"></a>1.镜像</h4><p>Docker的镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序，库，资源，配置等文件外，还包含了一些为运行时准备的一些配置参数（匿名卷，环境变量，用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。</p><p>镜像就是一堆只读层的统一视角，下面这张图会帮你更好的理解：</p><p>![](C:\Users\张xiao\Pictures\Saved Pictures\1100338-20181010205425698-1711765011.png)</p><p>镜像构造时，会一层层构建，前一层是后一层的基础。除了最下面一层外，其他层都会有一个指针指向父层。每一层构建完之后就不会在发生改变，后一层上的任何改变都只会发生在自己这一层。比如，删除前一层的文件，实际并不会真正的删除前一层的文件，而是仅在当前层标记为已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。</p><p>Docker镜像分层存储的特征还使得镜像的复用，定制变得更加容易。我们可以用Dockerfile将之前构建好的镜像作为基础层，定制自己所需的内容，构造新的镜像。</p><h4 id="2-容器"><a href="#2-容器" class="headerlink" title="2.容器"></a>2.容器</h4><p>容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一的区别就是容器最上一层是可读可写的。</p><p>也就是说：容器=镜像+读写层。但是这个定义并没有说出容器是否运行。</p><p>接下来说下运行态的容器：</p><p>一个运行时态的容器=一个可读写的统一文件系统加上隔离的进程空间和对应包含的子进程。</p><p>一个运行时的容器是这样的：</p><p>![](C:\Users\张xiao\Pictures\Saved Pictures\p.jpg)</p><p>它的所有都是建立在文件系统隔离系统之上的（Read Write File Systemctl），一个容器中的进程会对文件进行增删改查操作，这些改变都将应用于可读可写层（前面也提到了，容器就是镜像+读写层，所以对这一层读写层的改变不会影响原镜像的存储层。）</p><p>![](C:\Users\张xiao\Pictures\Saved Pictures\write.jpg)</p><p>可以运行一下命令来验证以上所说：</p><p><code>docker run centos touch 1.txt</code></p><p>为了将这些零星的数据整合起来，提出了镜像层(image layer)的概念。下面这张图片就是一个镜像层。</p><p>![](C:\Users\张xiao\Pictures\Saved Pictures\layer.jpg)</p><p>元数据（metadata）就是关于这个层的额外信息，它不仅能够让Docker获取运行和构建时的信息，还包括父层的层次信息。需要注意，只读层和读写层都包含元数据。 </p><p>除此之外，每一层都包含了一个指向父层的指针，如果一个层没有指针，说明它处于最底层。</p><p>![](C:\Users\张xiao\Pictures\Saved Pictures\zhizhen.jpg)</p><h4 id="Docker容器和镜像命令："><a href="#Docker容器和镜像命令：" class="headerlink" title="Docker容器和镜像命令："></a>Docker容器和镜像命令：</h4><p><code>docker create &lt;image-id&gt;</code></p><p>docker create 命令为指定的镜像（image）添加了一个可读层，构成了一个新的容器。注意，这个容器并没有运行。 </p><p><code>docker start &lt;container-id&gt;</code></p><p>docker start命令为容器文件系统创建了一个进程隔离空间。注意，每一个容器只能够有一个进程隔离空间。 </p><p><code>docker run &lt;image-id&gt;</code></p><p>docker run 命令先是利用镜像创建了一个容器，然后运行这个容器。这个命令非常的方便 ,docker run 命令先是利用镜像创建了一个容器，然后运行这个容器。这个命令非常的方便 。</p><p><code>docker ps</code></p><p>docker ps 命令会列出所有运行中的容器。这隐藏了非运行态容器的存在，如果想要找出这些容器，我们需要使用下面这个命令。 </p><p><code>docker ps –a</code></p><p>docker ps –a命令会列出所有的容器，不管是运行的，还是停止的。 </p><p><code>docker images</code></p><p>docker images命令会列出了所有顶层（top-level）镜像。实际上，在这里我们没有办法区分一个镜像和一个只读层，所以我们提出了top-level镜像。只有创建容器时使用的镜像或者是直接pull下来的镜像能被称为顶层（top-level）镜像，并且每一个顶层镜像下面都隐藏了多个镜像层。 </p><p><code>docker rm &lt;container-id&gt;</code></p><p>docker rm命令会移除构成容器的可读写层。注意，这个命令只能对非运行态容器执行。</p><p><code>docker rmi &lt;image-id&gt;</code></p><p>docker rmi 命令会移除构成镜像的一个只读层。你只能够使用docker rmi来移除最顶层（top level layer）（也可以说是镜像），你也可以使用-f参数来强制删除中间的只读层。 </p><p><code>docker commit &lt;container-id&gt;</code></p><p>docker commit命令将容器的可读写层转换为一个只读层，这样就把一个容器转换成了不可变的镜像。 </p><p><code>docker build</code></p><p>docker build命令非常有趣，它会反复的执行多个命令。 </p><p>![](C:\Users\张xiao\Pictures\Saved Pictures\for.jpg)</p><p>我们从上图可以看到，build命令根据Dockerfile文件中的FROM指令获取到镜像，然后重复地1）run（create和start）、2）修改、3）commit。在循环中的每一步都会生成一个新的层，因此许多新的层会被创建。 </p><h3 id="关于Docker中的网络"><a href="#关于Docker中的网络" class="headerlink" title="关于Docker中的网络"></a>关于Docker中的网络</h3>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reids持久化</title>
      <link href="/2030/03/26/redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2030/03/26/redis%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="什么叫持久化？"><a href="#什么叫持久化？" class="headerlink" title="什么叫持久化？"></a>什么叫持久化？</h2><p>用一句话可以将持久化概括为：将数据（如内存中的对象）保存到可永久保存的存储设备中。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、 XML 数据文件中等等。</p><a id="more"></a><blockquote><p>从应用层与系统层理解持久化</p></blockquote><p>同时，也可以从应用层和系统层这两个层面来理解持久化：</p><p><strong>应用层</strong>：如果关闭( <code>Close</code> )你的应用然后重新启动则先前的数据依然存在。</p><p><strong>系统层</strong>：如果关闭( <code>Shutdown</code> )你的系统（电脑）然后重新启动则先前的数据依然存在。</p><p>说白了，就是在指定的时间间隔内,将内存当中的数据快照写入磁盘,它恢复时是拷快照文件直接读到内存</p><p>什么意思呢?  我们都知道, 内存当中的数据, 如果我们一断电,那么数据必然会丢失,但是玩过redis的同学应该都知道,我们一关机之后再启动的时候数据是还在的,所以它必然是在redis启动的时候重新去加载了持久化的文件</p><p><strong>redis提供两种方式进行持久化</strong></p><p>一种是RDB持久化默认,</p><p>另一种 AOF (append only file) 持久化.</p><h2 id="Redis-为什么要持久化？"><a href="#Redis-为什么要持久化？" class="headerlink" title="Redis 为什么要持久化？"></a>Redis 为什么要持久化？</h2><p>Redis 中的数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis 支持各种不同方式的排序。与 Memcached 一样，为了保证效率，数据都是缓存在内存中。</p><p>对，数据都是缓存在内存中的，当你重启系统或者关闭系统后，缓存在内存中的数据都会消失殆尽，再也找不回来了。所以，为了让数据能够长期保存，就要将 Redis 放在缓存中的数据做持久化存储。</p><h2 id="redis持久化的意义，在于故障恢复"><a href="#redis持久化的意义，在于故障恢复" class="headerlink" title="redis持久化的意义，在于故障恢复"></a>redis持久化的意义，在于故障恢复</h2><p>比如你部署了一个redis，作为cache缓存，当然也可以保存一些较为重要的数据</p><p>如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据</p><p>如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的</p><h2 id="1-RDB"><a href="#1-RDB" class="headerlink" title="1.RDB"></a>1.RDB</h2><p><strong>是什么？</strong></p><p>原理是redis会单独创建(fork函数)（复制）一个与当前进程一模一样的子进程来进行持久化,这个子线程的所有数据(变量,环境变量,程序,程序计数器等)都和原进程一模一样,会先将数据写入到一个临时文件中,待持久化结束了,再用这个临时文件替换上次持久化好的文件,整个过程中,主进程不进行任何的IO操作,（用到了fork子进程来进行持久化）这就确保了极高的性能</p><p><strong>1.这个持久化文件在哪里</strong></p><p>vi /usr/local/redis/etc/redis.conf</p><p>找dbfilename dump.rdb</p><p>默认就是dump.rdb</p><p>dir ./  (包括很多例如redis实例，只要是redis产生的实例都会丢到)</p><p>./   =====  哪里启动，哪里生成。</p><p>注意：</p><p>要么写死目录</p><p>要么启动的位置就在同一个地方，地方不一样可能造成数据丢失。</p><p><strong>2.他是什么时候fork子进程，或者什么时候触发rdb持久化机制</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>/usr/local/redis/bin/redis-cli</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.</span>SHUTDOWN</span><br></pre></td></tr></table></figure><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20191217092426326.png" alt="image-20191217092426326" style="zoom:50%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf <span class="comment">## 开启redis</span></span><br></pre></td></tr></table></figure><p>shutdown时,如果没有开启aof,会触发</p><p>配置文件中默认的快照配置</p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20191217092743078.png" alt="image-20191217092743078" style="zoom:50%;"><p>执行命令save成者bgsave ,</p><p>save是只管保存,其他不管,全部阻塞  </p><p>redis会在后台异步进行快照操作,</p><p>同时可以响应客户端的请求(默认调用bgsave来进行持久化)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f ./dump.rdb</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf </span><br><span class="line"><span class="comment">## 开启redis</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-cli  </span><br><span class="line"><span class="comment">## 连接客户端</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set k1 v1</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save     <span class="comment">## dump.rdb  是只管保存,其他不管,全部阻塞</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bgsave   <span class="comment">## dump.rdb  redis会在后台异步进行快照操作</span></span><br></pre></td></tr></table></figure><p>执行flushall命令但是里面是空的,无意义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FLUSHALL   <span class="comment">## 清空</span></span><br></pre></td></tr></table></figure><p><strong>在redis.conf中rdb持久化策略</strong></p><p>集群save 900 1                ##  900秒之内执行了一次增删改操作就会触发 ， 查不算</p><p>save 300 10             </p><p>save 60    10000  </p><p>默认配置</p><p>redis 性能调优</p><p>集群  master节点肯定会把rdb</p><p>实际上关不掉的在主从复制上</p><p>要么就是就写一个save</p><p>要么就注掉</p><h2 id="2-aof"><a href="#2-aof" class="headerlink" title="2.aof"></a>2.aof</h2><p>执行set k1 v1 </p><p>保存命令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set k1 v1</span><br><span class="line">set k2 v1   </span><br><span class="line"><span class="comment">## 保存到文件中  保存的是命令</span></span><br></pre></td></tr></table></figure><p><strong>是什么？</strong></p><p>原理是将Reids的操作日志以追加的方式写入文件,读操作是不记录的</p><p><strong>1.这个持久化文件在哪里</strong></p><p>产生的位置还是 ./dir </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/redis/etc/redis.conf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendfilename <span class="string">"appendonly.aof"</span>   <span class="comment">## 文件名</span></span><br></pre></td></tr></table></figure><p> redis 默认关闭，开启需要手动把no改为yes</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-cli</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set k1 v1</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHUTDOWN</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf </span><br><span class="line"><span class="comment">## 开启redis</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll</span><br></pre></td></tr></table></figure><p>‘*’  开头代表下面有两组命令</p><p>$  字符串的长度</p><p>日志追加的方式保存到文件里。</p><p><strong>2.触发机制（根据配置文件配置项）</strong></p><p>AOF_FSYNC_NO:表示等操作系统进行数据缓存同步到磁盘(快,持久化没保证) —–不能配置不可控 </p><p>AOF_FSYNC_ALWAYS: 同步持久化,每次发生数据变更时,立即记录到磁盘(慢,安全) —-消耗性能</p><p>AOF_FSYNC_EVERYSEC: 表示每秒同步一次(默认值很快,但可能会丢失一秒以内的数据)–所以默认</p><h2 id="同步策略"><a href="#同步策略" class="headerlink" title="同步策略"></a>同步策略</h2><p>在了解同步策略之前，需要先来了解两个三方法flushAppendOnlyFile、write和save：</p><ul><li>redis的服务器进程是一个事件循环，文件事件负责处理客户端的命令请求，而时间事件负责执行serverCron函数这样的定时运行的函数。在处理文件事件执行写命令，使得命令被追加到aof_buf中，然后在处理时间事件执行serverCron函数会调用flushAppendOnlyFile函数进行文件的写入和同步</li><li>write：根据条件，将aof_buf中的缓存写入到AOF文件</li><li>save：根据条件，调用fsync或fdatasync函数将AOF文件保存到磁盘</li></ul><p>下面来介绍Redis支持的三种同步策略：</p><ul><li>AOF_FSYNC_NO：不保存（write和read命令都由主进程执行）</li><li>AOF_FSYNC_EVERYSEC：每一秒钟保存一次（write由主进程完成，save由子进程完成）</li><li>AOF_FSYNC_ALWAYS：每执行一个命令保存一次（write和read命令都由主进程执行）</li></ul><p><strong>AOF_FSYNC_NO</strong><br>在这种策略下，每次flushAppendOnlyFile函数被调用的时候都会执行一次write方法，但是不会执行save方法。</p><p>只有下面三种情况下才会执行save方法：</p><ul><li>Redis被关闭</li><li>AOF功能被关闭</li><li>系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行）</li></ul><p>这三种情况下的save操作都会引起Redis主进程阻塞，并且由于长时间没有执行save命令，所以save命令执行的时候，阻塞时间会很长</p><p><strong>AOF_FSYNC_EVERYSEC</strong><br>在这种策略下，save操作原则上每隔一秒钟就会执行一次， 因为save操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。</p><p>其实根据Redis的状态，每当 flushAppendOnlyFile函数被调用时，write命令和save命令的执行又分为四种不同情况：</p><p><img src="https://lebron-youdao-img.oss-cn-hangzhou.aliyuncs.com/AOF%20everysec.png" alt="AOF everysec"></p><p>根据以上图知道，在AOF_FSYNC_EVERYSEC策略下， 如果在情况1时发生故障停机， 那么用户最多损失小于2秒内所产生的数据；而如果在情况2时发生故障停机，堆积了很多save命令，那么用户损失的数据是可以超过 2 秒的。</p><p>AOF_FSYNC_ALWAYS<br>在这种模式下，每次执行完一个命令之后，write和save命令都会被执行。</p><p>另外，因为save命令是由Redis主进程执行的，所以在save命令执行期间，主进程会被阻塞。</p><p>三种策略的优缺点<br>AOF_FSYNC_NO策略虽然表面上看起来提升了性能，但是会存在每次save命令执行的时候相对长时间阻塞主进程的问题。并且数据的安全性的不到保证，如果Redis服务器突然宕机，那么没有从AOF缓存中保存到硬盘中的数据都会丢失。</p><p>AOF_FSYNC_ALWAYS策略的安全性的到了最大的保障，理论上最多丢失最后一次写操作，但是由于每个写操作都会阻塞主进程，所以Redis主进程的响应速度受到了很大的影响。</p><p>AOF_FSYNC_EVERYSEC策略是比较建议的配置，也是Redis的默认配置，相对来说兼顾安全性和性能。</p><h2 id="AOF执行流程"><a href="#AOF执行流程" class="headerlink" title="AOF执行流程"></a>AOF执行流程</h2><ul><li>所有的写命令都会追加到aof_buf（缓冲区）中。</li><li>可以使用不同的策略将AOF缓冲区中的命令写到AOF文件中。</li><li>随着AOF文件的越来越大，会对AOF文件进行重写。</li><li>当服务器重启的时候，会加载AOF文件并执行AOF文件中的命令用于恢复数据。</li></ul><p>简单分析一下AOF执行流程中的一些问题：</p><ul><li><p>因为Redis为了效率，使用单线程来响应命令，如果每次写命令都追加写硬盘的操作，那么Redis的响应速度还要取决于硬盘的IO效率，显然不现实，所以Redis将写命令先写到AOF缓冲区。</p></li><li><p>写道缓冲区还有一个好处是可以采用不同的策略来实现缓冲区到硬盘的同步，可以让用户自行在安全性和性能方面做出权衡。</p></li></ul><h2 id="3-aof重写机制"><a href="#3-aof重写机制" class="headerlink" title="3.aof重写机制"></a>3.aof重写机制</h2><p>我们以日志的方式,记录我们的命令记录到文件当中</p><p>如果我操作的特别频繁，文件肯定会特别大。</p><p>我写100万数据，持久化文件也会特别大</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-cli</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FLUSHALL  <span class="comment">## 清空数据</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keys *   <span class="comment">## 查看是否有数据</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INCR lock   <span class="comment">## 加操作</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit    <span class="comment">## 退出</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi appendonly.aof  <span class="comment">## 查看文件</span></span><br></pre></td></tr></table></figure><p>记录着</p><p>我可以直接执行一条命令set lock 11</p><p>重写就是将重复的剔除掉瘦身</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/redis/bin/redis-cli</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BGREWRITEAOF  <span class="comment">##手动调用重写命令</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit  <span class="comment">## 退出</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi dump.rdb</span><br></pre></td></tr></table></figure><p>是因为我这个版本是5.0的</p><p>当AOF文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当AOF文件大小的增长率大于该配置项时自动开启重写(这里指超过原大小的100%) .</p><p>auto-aof-rewrite-percentage 100</p><p>当AOF文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写,当AOF文件大小大于该配置项时自动开启重写</p><p>auto-aof-rewrite-min-size 64mb</p><p>incr lock </p><p>重写就是将重复的剔除掉瘦身</p><h2 id="4-redis4-0后混合持久化机制"><a href="#4-redis4-0后混合持久化机制" class="headerlink" title="4.redis4.0后混合持久化机制"></a>4.redis4.0后混合持久化机制</h2><p><strong>开启混合持久化</strong></p><p>4.0 版本是 像set lock 11</p><p>4.0版本的混合持久化默认关闭的,通过aof-use-rdb-preamble配置参数控制, yes则表示开启, no表示禁用, 5.0之后默认开启。</p><p>混合持久化是通过bgrewriteaof完成的,不同的是当开启混合持久化时, fork出的子进程先将共享的内存副本全量 以RDB方式写入aof文件,然后在将重写缓冲区的增量命令以AOF方式写入到文件,写入完成后通知主进程更新统计信息,并将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。</p><p>简单的说:新的AOF文件前半段是 RDB格式的全量数据后半段是AOF格式的增量数据,</p><p>优点:混合持久化结合了RDB持久化和AOF持久化的优点由于绝大部分都是RDB格式,加载速度快,同时结合 AOF,增量的数据以AOF方式保存了,数据更少的丢失.</p><p>缺点:兼容性差,一旦开启了混合持久化,在4.0之前版本都不识别该aof文件,同时由于前部分是RDB格式,阅读性较差</p><p>二进制方式存储  更小</p><p>什么时候下会自动重写</p><p>看</p><p>auto-aof-rewrite-percentage</p><p>auto-aof-rewrite-min-size</p><h2 id="小总结："><a href="#小总结：" class="headerlink" title="小总结："></a>小总结：</h2><p><strong>1.redis提供了rdb持久化方案，为什么还要aof？</strong></p><p>rdb 是跟据save触发持久化，所以会照成数据的丢失</p><p>aof持久化是1秒执行一次</p><p>在数据aof</p><p>在性能rdb高于aof</p><blockquote><p>优化数据丢失问题，rdb会丢失最后一次快照后的数据，aof丢失不会超过2秒的数据</p></blockquote><p><strong>2.如果aof和rdb同时存在，听谁的？</strong></p><p>aof数据准确率更高</p><p><strong>3.rdb和aof优势劣势</strong></p><p>rdb适合大规模的数据恢复,对数据完整性和一致性不高，在一定间隔时间做一次备份,如果redis意外宕机的话,就会丢失最后一次快照后的所有操作</p><p>aof根据配置项而定</p><p>1.官方建议两种持久化机制同时开启,如果两个同时开启优先使用aof久化机制</p><p>在生产环境中用集群，哨兵什么的</p><p>主机开aof</p><p><strong>性能建议（这里只针对单机版redis持久化做性能建议）：</strong></p><p>因为RDB文件只用作后备用途,只要15分钟备份一次就够了,只保留save 900 1这条规则. 因为开启aof持久化安全。</p><p>如果Enalbe AOF, 好处是在最恶劣情况下也只会丢失不超过两秒数据,启动脚本较简单只load自己的AOF文件就可以了.</p><p>代价一是带来了持续的IO,二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。</p><p>只要硬盘许可,应该尽量减少AOF rewrite的频率, AOF重写的基础大小默认值64M太小了,可以设到5G以上.默认超过原大小100%大小时重写可以改到适当的数值。</p><p>看硬盘</p><img src="C:\Users\Lenovo\Desktop\20191127113644133169.png" alt="20191127113644133169" style="zoom: 50%;"><p>1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。</p><p>2）AOF关闭或者AOF文件不存在时，加载RDB文件。</p><p>3）加载AOF/RDB文件成功后，Redis启动成功。</p><p>4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。</p><p><img src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=762237719,3005011713&fm=15&gp=0.jpg" alt="img"></p><p>1.从主进程中fork出子进程，并拿到fork时的AOF文件数据写到一个临时AOF文件中</p><p>2.在重写过程中，redis收到的命令会同时写到AOF缓冲区和重写缓冲区中，这样保证重写不丢失，重写过程中的命令</p><p>3.重写完成后通知主进程，主进程会将AOF缓冲区中的数据追加到子进程生成的文件中</p><p>4.redis会原子的将旧文件替换为新文件，并开始将数据写入到新的aof文件上</p><ul><li>执行bgrewriteaof命令的时候，如果当前有进程正在执行AOF重写，那么直接返回；如果有进程正在执行bgsave，那么等待bgsave执行完毕再执行AOF重</li><li>Redis主进程会fork一个子进程执行AOF重写。</li><li>AOF重写过程中，不影响Redis原有的AOF过程，包括写消息到AOF缓存以及同步AOF缓存中的数据到硬盘。</li><li>AOF重写过程中，主进程收到的写操作还会将命令写到AOF重写缓冲区，注意和AOF缓冲区分开。</li><li>由于AOF重写过程中原AOF文件还在陆续写入数据，所以AOF重写子进程只会拿到fork子进程时的AOF文件进行重写。</li><li>子进程拿到原AOF文件中的数据写道一个临时的AOF文件中。</li><li>子进程完成AOF重写后会发消息给主进程，主进程会把AOF重写缓冲区中的数据写道AOF缓冲区，并且用新的AOF文件替换旧的AOF文件。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>Redis 默认开启RDB持久化方式，在指定的时间间隔内，执行指定次数的写操作，则将内存中的数据写入到磁盘中。</li><li>RDB 持久化适合大规模的数据恢复但它的数据一致性和完整性较差。</li><li>Redis 需要手动开启AOF持久化方式，默认是每秒将写操作日志追加到AOF文件中。</li><li>AOF 的数据完整性比RDB高，但记录内容多了，会影响数据恢复的效率。</li><li>Redis 针对 AOF文件大的问题，提供重写的瘦身机制。</li><li>若只打算用Redis 做缓存，可以关闭持久化。</li><li>若打算使用Redis 的持久化。建议RDB和AOF都开启。其实RDB更适合做数据的备份，留一后手。AOF出问题了，还有RDB。</li></ol><h4 id="RDB和AOF的优缺点"><a href="#RDB和AOF的优缺点" class="headerlink" title="RDB和AOF的优缺点"></a>RDB和AOF的优缺点</h4><hr><p>RDB的优缺点：</p><ul><li>一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数 据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</li><li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。</li><li>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li><li>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</li><li>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</li><li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li></ul><p>AOF的优缺点：</p><ul><li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。</li><li>AOF 日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损。 如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据 一致性的问题。</li><li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。 因此在进行rewrite切换时可以更好的保证数据安全性。</li><li>AOF以一个格式清晰、易于理解的日志文件用于记录所有的修改操作， 非常适合做灾难性的误删除的紧急恢复。 比如有人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条flushall命令给删了，然后再将该aof文件放回去，就可以通过恢复机制，自动恢复所有数据。</li><li>对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li><li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低， 因为 AOF 一般会配置成每秒 fsync 一次日志文件。</li><li>类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。</li></ul><h4 id="如何选择？"><a href="#如何选择？" class="headerlink" title="如何选择？"></a>如何选择？</h4><hr><p>RDB和AOF如何选择？</p><ul><li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</li><li>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</li><li>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Reids </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reids主从</title>
      <link href="/2030/03/15/%E5%A4%9A%E7%BA%A7redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
      <url>/2030/03/15/%E5%A4%9A%E7%BA%A7redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h2 id="Reids主从"><a href="#Reids主从" class="headerlink" title="Reids主从"></a>Reids主从</h2><p><strong>参考链接：</strong></p><a id="more"></a><p><a href="https://www.cnblogs.com/leeSmall/p/8398401.html" target="_blank" rel="noopener">Redis主从复制和哨兵 参考1</a></p><p><a href="https://www.cnblogs.com/chenhuabin/p/10048854.html" target="_blank" rel="noopener">Redis主从复制和哨兵 参考2</a></p><p><a href="https://www.cnblogs.com/lxx666/articles/10693844.html" target="_blank" rel="noopener">Redis主从架构和主从从架构集群搭建详细步骤</a></p><p><a href="https://www.cnblogs.com/wade-luffy/p/9639986.html" target="_blank" rel="noopener">Redis主从复制原理</a></p><p><a href="http://doc.redisfans.com/topic/replication.html" target="_blank" rel="noopener">Redis复制官方文档翻译</a></p><blockquote><p>​    主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。</p><p>​    默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。</p></blockquote><h3 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h3><ol><li><p><strong>数据冗余：</strong>主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</p></li><li><p><strong>故障恢复：</strong>当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</p></li><li><p><strong>负载均衡：</strong>在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</p></li><li><p><strong>高可用基石：</strong>主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</p></li></ol><h3 id="主从拓扑结构"><a href="#主从拓扑结构" class="headerlink" title="主从拓扑结构"></a>主从拓扑结构</h3><p>​    <strong>一主一从：</strong></p><p><img src="C:%5CUsers%5Casus%5CDesktop%5C1539768-20181201112713274-1680086476.png" alt="1539768-20181201112713274-1680086476"></p><p>　　这一结构主要用于主节点故障从节点，当主节点的“写”命令并发高且需要持久化，可以只在从节点开启AOF（主节点不需要），这样即保证了数据的安全性，也避免持久化对主节点的影响。<br>　　<br>​    <strong>一主多从：</strong></p><p><img src="C:%5CUsers%5Casus%5CDesktop%5C1539768-20181201112740108-1961344396.png" alt="1539768-20181201112740108-1961344396"></p><p>　　这一结构主要针对“读”较多的场景，“读”由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定。<br>　　<br>​    <strong>树状主从:</strong></p><p><img src="C:%5CUsers%5Casus%5CDesktop%5C1539768-20181201112824130-1051891659.png" alt="1539768-20181201112824130-1051891659"></p><p>　　这一结构是对一主多从的补充，主节点只推送一次数据到slave1和slave2，再由从slave2推送到slave3和 slave4，减轻主节点推送的压力。</p><h2 id="主从复制的实现原理"><a href="#主从复制的实现原理" class="headerlink" title="主从复制的实现原理"></a>主从复制的实现原理</h2><p>主从复制过程大体可以分为3个阶段：<strong>连接建立阶段（即准备阶段）</strong>、<strong>数据同步阶段</strong>、<strong>命令传播阶段</strong>；</p><h3 id="连接建立阶段"><a href="#连接建立阶段" class="headerlink" title="连接建立阶段"></a>连接建立阶段</h3><h4 id="step1：保存主节点信息"><a href="#step1：保存主节点信息" class="headerlink" title="step1：保存主节点信息"></a>step1：保存主节点信息</h4><p>​    从节点服务器内部维护了两个字段，即<strong>masterhost</strong>和<strong>masterport</strong>字段，用于存储主节点的<strong>ip</strong>和<strong>port</strong>信息。</p><p>​    <strong>slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。</strong></p><h4 id="step2：建立socket连接"><a href="#step2：建立socket连接" class="headerlink" title="step2：建立socket连接"></a>step2：建立socket连接</h4><p>​    <strong>从节点每秒1次调用复制定时函数replicationCron()</strong>，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。</p><p><strong>如果连接成功：</strong></p><p>​    <strong>从节点：</strong>为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。</p><p>​    <strong>主节点：</strong>接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。</p><h4 id="step3：发送ping命令"><a href="#step3：发送ping命令" class="headerlink" title="step3：发送ping命令"></a>step3：发送ping命令</h4><p>​    从节点成为主节点的客户端之后，发送ping命令进行首次请求，<strong>目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。</strong></p><p><strong>从节点发送ping命令后，可能出现3种情况：</strong></p><ol><li><p>返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。</p></li><li><p>超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。</p></li><li><p>返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。</p></li></ol><h4 id="step4：身份验证"><a href="#step4：身份验证" class="headerlink" title="step4：身份验证"></a>step4：身份验证</h4><p>如果从节点中设置了<strong>masterauth</strong>选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。</p><p>从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。</p><p>如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。</p><h4 id="step5：发送从节点端口信息"><a href="#step5：发送从节点端口信息" class="headerlink" title="step5：发送从节点端口信息"></a>step5：发送从节点端口信息</h4><p>身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；<strong>该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。</strong></p><h3 id="数据同步阶段"><a href="#数据同步阶段" class="headerlink" title="数据同步阶段"></a>数据同步阶段</h3><p>主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。</p><p>具体执行的方式是：从节点向主节点发送<strong>psync命令</strong>，开始同步。</p><p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为<strong>全量复制和部分复制</strong>。</p><blockquote><p>在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。</p></blockquote><h3 id="命令传播阶段"><a href="#命令传播阶段" class="headerlink" title="命令传播阶段"></a>命令传播阶段</h3><p>​    数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p><p>​    在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。</p><p><strong>PS：</strong></p><p>​    <strong>延迟与不一致：</strong>命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p><p>​    <strong>repl-disable-tcp-nodelay no：</strong>该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。</p><h3 id="【数据同步阶段】全量复制和部分复制"><a href="#【数据同步阶段】全量复制和部分复制" class="headerlink" title="【数据同步阶段】全量复制和部分复制"></a>【数据同步阶段】全量复制和部分复制</h3><p>在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；</p><p>在Redis2.8以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。</p><ol><li>全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。</li><li>部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。</li></ol><h4 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h4><p><strong>Redis通过psync命令进行全量复制的过程如下：</strong></p><ol><li><p>从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；</p></li><li><p>主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。</p></li><li><p>主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。</p></li><li><p>主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。</p></li><li><p>如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。</p></li></ol><p><strong>通过全量复制的过程可以看出，全量复制是非常重型的操作：</strong></p><ol><li><p>主节点通过<strong>bgsave</strong>命令<strong>fork</strong>子进程进行<strong>RDB</strong>持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；</p></li><li><p>主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗。</p></li><li><p>从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗。</p></li></ol><h4 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h4><p>​    由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。</p><p>​    部分复制的实现，依赖于三个重要的概念：复制偏移量，复制积压缓冲区，服务器运行ID</p><h5 id="offset-复制偏移量"><a href="#offset-复制偏移量" class="headerlink" title="offset 复制偏移量"></a>offset 复制偏移量</h5><p>​        在主从复制的Master(主节点)和Slave(从节点)双方都会各自维持一个offset，代表的是<strong>主节点向从节点传递的字节数</strong>；Master成功发送N个字节的命令后会将Master的offset加上N，Slave在接收到N个字节命令后同样会将Slave的offset增加N。Master和Slave如果状态是一致的那么它的的offset也应该是一致的。</p><p>​        offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。</p><h5 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h5><p>  复制积压缓冲区是由<strong>Master(主节点)维护的一个固定长度的FIFO队列(先进先出)</strong>，默认大小1MB；当主节点开始有从节点时创建，它的作用是缓存已经传播出去的命令。当Master进行命令传播时，不仅将命令发送给所有Slave，还会将命令写入到复制积压缓冲区里面。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。</p><p>​        除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。</p><p>​        由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。</p><p><strong>从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：</strong></p><ul><li><strong>如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；</strong></li><li><strong>如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。</strong></li></ul><h5 id="runid-服务器运行ID"><a href="#runid-服务器运行ID" class="headerlink" title="runid 服务器运行ID"></a>runid 服务器运行ID</h5><p>​        每个Redis服务器(无论主从)在启动时都会自动生成一个表明自己身份的随机ID(每次启动都不一样)，由40个随机的十六进制字符组成。在PSYNC中发送的这个ID是指之前连接的Master的ID，如果没保存这个ID，PSYNC命令会使用<strong>”PSYNC ? -1”</strong> 这种形式发送给Master，表示需要全量复制。</p><p>​        每个Redis节点，在启动时都会自动生成一个随机ID，由40个随机的十六进制字符组成；</p><p>runid用来唯一识别一个Redis节点。<strong>通过info Server命令，可以查看节点的runid。</strong></p><p>​        主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；</p><p><strong>主节点根据runid判断能否进行部分复制：</strong></p><ul><li><p>如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；</p></li><li><p>如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。</p></li></ul><h3 id="PSYNC命令"><a href="#PSYNC命令" class="headerlink" title="PSYNC命令"></a>PSYNC命令</h3><p>  Redis在2.8版本提供了PSYNC命令来带代替SYNC命令，为Redis主从复制提供了部分复制的能力。</p><h4 id="PSYNC命令格式"><a href="#PSYNC命令格式" class="headerlink" title="PSYNC命令格式"></a>PSYNC命令格式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PSYNC &lt;runid&gt; &lt;offset&gt;</span><br><span class="line"><span class="meta">#</span> runid:主服务器ID</span><br><span class="line"><span class="meta">#</span> offset:从服务器最后接收命令的偏移量</span><br></pre></td></tr></table></figure><p>  <strong>PSYNC执行过程中比较重要的概念有3个：runid、offset（复制偏移量）以及复制积压缓冲区。</strong></p><h4 id="psync命令的执行"><a href="#psync命令的执行" class="headerlink" title="psync命令的执行"></a>psync命令的执行</h4><p><img src="C:%5CUsers%5Casus%5CDesktop%5C990532-20180913134017449-1623896661.png" alt="990532-20180913134017449-1623896661"></p><ol><li><p>首先从节点根据当前状态，决定如何调用psync命令：</p><ul><li>如果从节点之前未执行过<strong>slaveof</strong>或最近执行了<strong>slaveof no one</strong>，则从节点发送命令为<strong>psync ? -1</strong>，向主节点请求全量复制；</li><li>如果从节点之前执行了<strong>slaveof</strong>，则发送命令为 <strong>psync <runid> <offset> **，其中</offset></runid></strong>runid<strong>为上次复制的主节点的</strong>runid<strong>，</strong>offset**为上次复制截止时从节点保存的复制偏移量。</li></ul></li><li><p>主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：</p><ul><li>如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；</li><li>如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；</li><li>如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复<strong>+FULLRESYNC <runid> <offset></offset></runid></strong>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。</li></ul></li></ol><h3 id="【命令传播阶段】心跳机制"><a href="#【命令传播阶段】心跳机制" class="headerlink" title="【命令传播阶段】心跳机制"></a>【命令传播阶段】心跳机制</h3><p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。</p><h4 id="主-gt-从：PING"><a href="#主-gt-从：PING" class="headerlink" title="主-&gt;从：PING"></a>主-&gt;从：PING</h4><p>每隔指定的时间，<strong>主节点会向从节点发送PING命令</strong>，这个PING命令的作用，主要是为了让从节点进行超时判断。</p><p>PING发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是10s。</p><h4 id="从-gt-主：REPLCONF-ACK"><a href="#从-gt-主：REPLCONF-ACK" class="headerlink" title="从-&gt;主：REPLCONF ACK"></a>从-&gt;主：REPLCONF ACK</h4><p>在命令传播阶段，<strong>从节点会向主节点发送REPLCONF ACK命令，</strong>频率是每秒1次；</p><p><strong>命令格式为：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLCONF ACK &#123;offset&#125;# offset指从节点保存的复制偏移量。</span><br></pre></td></tr></table></figure><p><strong>REPLCONF ACK命令的作用包括：</strong></p><ol><li><p><strong>实时监测主从节点网络状态：</strong>该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1。</p></li><li><p><strong>检测命令丢失：</strong>从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。</p></li></ol><ul><li><strong>注意：offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。</strong></li></ul><ol start="3"><li><strong>辅助保证从节点的数量和延迟：</strong>Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。</li></ol><p>　　</p><h2 id="开启主从复制"><a href="#开启主从复制" class="headerlink" title="开启主从复制"></a>开启主从复制</h2><p>从节点开启主从复制，有3种方式：</p><ul><li>配置文件：在从服务器的配置文件中加入：<strong>slaveof <masterip> <masterport></masterport></masterip></strong></li><li>启动命令：redis-server启动命令后加入： <strong>–slaveof <masterip> <masterport></masterport></masterip></strong></li><li>客户端命令：Redis服务器启动后，直接通过客户端执行命令：<strong>slaveof <masterip> <masterport></masterport></masterip></strong>，则该Redis实例成为从节点。</li></ul><h3 id="修改配置文件方法："><a href="#修改配置文件方法：" class="headerlink" title="修改配置文件方法："></a>修改配置文件方法：</h3><h4 id="1-配置从服务配置文件redis-conf"><a href="#1-配置从服务配置文件redis-conf" class="headerlink" title="1. 配置从服务配置文件redis.conf"></a>1. 配置从服务配置文件redis.conf</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">slaveof 192.168.1.9 6379    #添加属于某台主机的从 服务</span><br><span class="line">masterauth 123456       #从服务连接主服的密码（访问主服务器的密码）</span><br><span class="line">slave-read-only yes     #从服务只读，不可在命令行写入数据</span><br><span class="line"></span><br><span class="line">5.0.4以后：</span><br><span class="line">replicaof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line">replica-read-only yes</span><br></pre></td></tr></table></figure><h4 id="2-重新启动从服务即实现主从连接"><a href="#2-重新启动从服务即实现主从连接" class="headerlink" title="2. 重新启动从服务即实现主从连接"></a>2. 重新启动从服务即实现主从连接</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. ./bin/redis-cli# 启动redis客户端</span><br><span class="line">2. 输入 info replication # 查看与复制相关的状态，了解主从节点的当前状态</span><br></pre></td></tr></table></figure><p><strong>输入info replication 后显示的内容：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> Replication</span><br><span class="line">role:slave      # 表示此台服务器是主是从</span><br><span class="line">master_host:39.107.38.62     # 主服务器ip</span><br><span class="line">master_port:6379        # 主服务器端口号</span><br><span class="line">master_link_status:up       # 与主服务器是否连接成功 up为成功 down失败</span><br><span class="line">master_last_io_seconds_ago:9</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:808</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_replid:ea5230cc485f9c6f372b2c89a65613fb075aff8b</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:808</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:15</span><br><span class="line">repl_backlog_histlen:794</span><br></pre></td></tr></table></figure><h4 id="遇到的报错："><a href="#遇到的报错：" class="headerlink" title="遇到的报错："></a>遇到的报错：</h4><h5 id="1-Error-condition-on-socket-for-SYNC-Connection-refused"><a href="#1-Error-condition-on-socket-for-SYNC-Connection-refused" class="headerlink" title="1. Error condition on socket for SYNC: Connection refused"></a>1. Error condition on socket for SYNC: Connection refused</h5><p>  <strong>出现原因</strong>：</p><p>  ​    redis主服务器绑定了127.0.0.1，跨服务器IP的访问就会失败，只能本机才能访问，外部请求会被过滤。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">1. 主服务器绑定ip: bind 39.107.38.62</span><br><span class="line">3. bind 0.0.0.0</span><br><span class="line">2. 注释bind  # 会报下面的错↓</span><br></pre></td></tr></table></figure><h5 id="2-‘-DENIED-Redis-is-running-in-protected-mode-because-protected-mode-is-enabled-no-bind-address-was-specified-no-authentication-password-is-requested-to-clients-In-this-mode-connections-are-only-accepted-from-the-loopback-interface-If-you-want-to-connec"><a href="#2-‘-DENIED-Redis-is-running-in-protected-mode-because-protected-mode-is-enabled-no-bind-address-was-specified-no-authentication-password-is-requested-to-clients-In-this-mode-connections-are-only-accepted-from-the-loopback-interface-If-you-want-to-connec" class="headerlink" title="2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec"></a>2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec</h5><p>   <strong>出现原因</strong>：</p><p>   ​    处于保护模式，只能本地链接。没有绑定ip 没有设置验证密码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">1. 主服务器绑定ip： bind 39.107.38.62</span><br><span class="line">2. 设置主服务器访问密码：requirepass 12345</span><br></pre></td></tr></table></figure><h5 id="3-error-READONLY-You-can’t-write-against-a-read-only-replica"><a href="#3-error-READONLY-You-can’t-write-against-a-read-only-replica" class="headerlink" title="3. (error) READONLY You can’t write against a read only replica."></a>3. (error) READONLY You can’t write against a read only replica.</h5><p>​    <strong>出现原因</strong>：</p><p>​        从库只可读不可写</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">1. 设置slave-read-only no # 代表不限于只读</span><br></pre></td></tr></table></figure><h2 id="断开主从复制"><a href="#断开主从复制" class="headerlink" title="断开主从复制"></a>断开主从复制</h2><p>​    通过<strong>slaveof <masterip> <masterport></masterport></masterip></strong>命令建立主从复制关系以后，可以通过slaveof no one断开。</p><p>从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Reids </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql事务</title>
      <link href="/2030/03/04/mysql%E4%BA%8B%E5%8A%A1%E7%89%B9%E6%80%A7%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
      <url>/2030/03/04/mysql%E4%BA%8B%E5%8A%A1%E7%89%B9%E6%80%A7%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h3 id="1-1-2、事务的特性"><a href="#1-1-2、事务的特性" class="headerlink" title="1.1.2、事务的特性"></a>1.1.2、事务的特性</h3><ol><li><p>原子性</p><blockquote><p>事务中的全部操作在数据库中是不可分割的，要么全部完成，要么全都不完成</p></blockquote></li><li><p>一致性</p><blockquote><p>几个并行执行的事务，其执行结果必须与按某一顺序串行执行的结果相一致</p></blockquote></li><li><p>隔离性</p><blockquote><p>事务的执行不受其他事务的干扰，事务执行的中间结果对其他事务必须是透明的</p></blockquote></li><li><p>持久性</p><blockquote><p>一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作</p></blockquote></li></ol><a id="more"></a><p><img src="https://pic2.zhimg.com/80/v2-59ea2f0769e4e9ffbcdce938d306fae9_hd.png" alt="img"> </p><h3 id="1-1-3、事务隔离级别"><a href="#1-1-3、事务隔离级别" class="headerlink" title="1.1.3、事务隔离级别"></a>1.1.3、事务隔离级别</h3><ol><li><p><strong>未提交读：脏读（READ UNCOMMITTED）</strong></p><ol><li>事务2查询到的数据是事务1中修改但未提交的数据，但因为事务1回滚了数据</li><li>所以事务2查询的数据是不正确的，因此出现了脏读的问题</li></ol></li></ol><h3 id="READ-UNCOMMITTED（读未提交）"><a href="#READ-UNCOMMITTED（读未提交）" class="headerlink" title="READ UNCOMMITTED（读未提交）"></a>READ UNCOMMITTED（读未提交）</h3><p> 该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为<strong>脏读</strong>。 </p><p> 两个命令行客户端分别为A，B；不断改变A的隔离级别，在B端修改数据。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">将A的隔离级别设置为read uncommitted(未提交读)</span><br><span class="line">A：SET @@session.transaction_isolation = &apos;READ-UNCOMMITTED&apos;;</span><br><span class="line">创建一张test</span><br><span class="line">create database test;</span><br><span class="line"></span><br><span class="line">use test;</span><br><span class="line"></span><br><span class="line">create table test(id int primary key);</span><br><span class="line"></span><br><span class="line">insert into test(id) values(1);</span><br><span class="line"></span><br><span class="line">A：启动事务，此时数据为初始状态</span><br><span class="line">start transaction;</span><br><span class="line"></span><br><span class="line">B：启动事务，更新数据，但不提交</span><br><span class="line">start transaction;</span><br><span class="line">update test set id = 2 where id = 1;</span><br><span class="line"></span><br><span class="line">A：再次读取数据，发现数据已经被修改了，这就是所谓的“脏读</span><br><span class="line">select * from test;</span><br><span class="line"></span><br><span class="line">B:回滚事务</span><br><span class="line">rollback;</span><br><span class="line"></span><br><span class="line">A:再次读数据，发现数据变回初始状态</span><br><span class="line">select * from test;</span><br></pre></td></tr></table></figure><ol><li><p><strong>提交读：不可重复读（READ COMMITTED）</strong></p><p>注：一个事务从开始到提交之前对数据所做的改变对其他事务是不可见的，这样就解决在READ-UNCOMMITTED级别下的脏读问题。</p><ol><li>事务2执行update语句但未提交前，事务1的前两个select操作返回结果是相同的</li><li>但事务2执行commit操作后，事务1的第三个select操作就读取到事务2对数据的改变</li><li>导致与前两次select操作返回不同的数据，因此出现了不可重复读的问题</li></ol></li></ol><h3 id="READ-COMMITTED（提交读）"><a href="#READ-COMMITTED（提交读）" class="headerlink" title="READ COMMITTED（提交读）"></a>READ COMMITTED（提交读）</h3><p> 一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，此现象称为不可重复读问题，Oracle 和 SQL Server 的默认隔离级别。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">A:将客户端A的事务隔离级别设置为read committed(已提交读)</span><br><span class="line"></span><br><span class="line">SET @@session.transaction_isolation = &apos;READ-COMMITTED&apos;;</span><br><span class="line">创建test表</span><br><span class="line">create database test;</span><br><span class="line">use test;</span><br><span class="line">create table test(id int primary key);</span><br><span class="line">insert into test(id) values(1);</span><br><span class="line"></span><br><span class="line">A：启动事务，此时数据为初始状态</span><br><span class="line">start transaction;</span><br><span class="line"></span><br><span class="line">B：启动事务，更新数据，但不提交</span><br><span class="line">start transaction;</span><br><span class="line">update test set id = 2 where id = 1;</span><br><span class="line"></span><br><span class="line">A：再次读数据，发现数据未被修改</span><br><span class="line">select * from test;</span><br><span class="line"></span><br><span class="line">B：提交事务</span><br><span class="line">commit;</span><br><span class="line"></span><br><span class="line">A：再次读取数据，发现数据已发生变化，说明B提交的修改被事务中的A读到了，这就是所谓的“不可重复读”</span><br><span class="line">select * from test;</span><br></pre></td></tr></table></figure><ol><li><strong>可重复读：幻读（REPEATABLE READ）：这是MySQL的默认事务隔离级别</strong><ol><li>事务每开启一个实例，都会分配一个版本号给它，如果读取的数据行正在被其他事务执行DELETE或UPDATE操作（既该行上有排他锁）</li><li>这时该事务的读取操作不会等待行上的锁释放，而是根据版本号去读取行的快照数据（记录在undo log中）</li><li>这样，事务中的查询操作返回的都是同一版本下的数据，解决了不可重复读问题。</li><li>虽然该隔离级别下解决了不可重复读问题，但理论上会导致另一个问题：幻读（Phantom Read）。</li><li>一个事务在执行过程中，另一个事务对已有数据行的更改，MVCC机制可保障该事务读取到的原有数据行的内容相同</li><li>但并不能阻止另一个事务插入新的数据行，这就会导致该事务中凭空多出数据行，像出现了幻读一样，这便是幻读问题</li></ol></li></ol><h3 id="REPEATABLE-READ（可重复读）"><a href="#REPEATABLE-READ（可重复读）" class="headerlink" title="REPEATABLE READ（可重复读）"></a>REPEATABLE READ（可重复读）</h3><p> 该隔离级别是 MySQL 默认的隔离级别，在同一个事务里，<code>select</code> 的结果是事务开始时时间点的状态，因此，同样的 <code>select</code> 操作读到的结果会是一致的，但是，会有<strong>幻读</strong>现象 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">将A的隔离级别设置为repeatable read(可重复读)</span><br><span class="line">SET @@session.transaction_isolation = &apos;REPEATABLE-READ&apos;;</span><br><span class="line">create database test;</span><br><span class="line">use test;</span><br><span class="line">create table test(id int primary key,name varchar(20));</span><br><span class="line"></span><br><span class="line">A：登录 mysql 终端 A，开启一个事务。</span><br><span class="line">start transaction;</span><br><span class="line">select * from test; -- 无记录</span><br><span class="line"></span><br><span class="line">B：登录 mysql 终端 B，开启一个事务。</span><br><span class="line">use test;</span><br><span class="line">start transaction;</span><br><span class="line">select * from test; -- 无记录</span><br><span class="line"></span><br><span class="line">A:切换到 mysql 终端 A，增加一条记录并提交。</span><br><span class="line">insert into test(id,name) values(1,&apos;a&apos;);</span><br><span class="line">commit;</span><br><span class="line">select * from test; --可以看到已经更改</span><br><span class="line"></span><br><span class="line">B:切换到 msyql 终端 B。</span><br><span class="line">select * from test; --此时查询还是无记录</span><br><span class="line"></span><br><span class="line">通过这一步可以证明，在该隔离级别下已经读取不到别的已提交的事务，如果想看到 mysql 终端 1 提交的事务，在 mysql 终端 2 将当前事务提交后再次查询就可以读取到 mysql 终端 1 提交的事务。</span><br><span class="line"> 可重复读隔离级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务部的更新该记录。 </span><br><span class="line"></span><br><span class="line">B：此时接着在 mysql 终端 B 插入一条数据。</span><br><span class="line">insert into test(id,name) values(1,&apos;b&apos;); -- 此时报主键冲突的错误</span><br><span class="line">这就是该隔离级别下可能产生的问题，MySQL 称之为幻读。</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure><ol><li><p><strong>可串行读（SERIALIZABLE）</strong></p><ol><li>这是事务的最高隔离级别，通过强制事务排序，使之不可能相互冲突，就像在每个读的数据行加上共享锁来实现</li><li>在该隔离级别下，可以解决前面出现的脏读、不可重复读和幻读问题，但也会导致大量的超时和锁竞争现象，一般不推荐使用</li></ol></li></ol><h3 id="SERIALIZABLE（可串行读）"><a href="#SERIALIZABLE（可串行读）" class="headerlink" title="SERIALIZABLE（可串行读）"></a>SERIALIZABLE（可串行读）</h3><p> 在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式加一把读共享锁，从而避免了脏读、不可重读复读和幻读问题。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">A:准备两个终端，在此命名为 mysql 终端 A 和 mysql 终端 B，分别登入 mysql，准备一张测试表 test 并调整隔离级别为 SERIALIZABLE，任意一个终端执行即可。</span><br><span class="line">set session transaction isolation level serializable;</span><br><span class="line">create database test;</span><br><span class="line">use test;</span><br><span class="line">create table test(id int primary key);</span><br><span class="line">insert into test(id) values(1);</span><br><span class="line"></span><br><span class="line">A:登录 mysql 终端 A，开启一个事务，并写入一条数据。</span><br><span class="line">start transaction;</span><br><span class="line">select * from test;</span><br><span class="line"></span><br><span class="line">B:登录 mysql 终端 B，开启一个事务。</span><br><span class="line">start transaction;</span><br><span class="line">select * from test; </span><br><span class="line"> delete from test;</span><br><span class="line"></span><br><span class="line">A:立马切换到 mysql 终端 A,提交事务。</span><br><span class="line">commit;</span><br><span class="line"></span><br><span class="line">一旦事务提交，msyql 终端 B 会立马返回 ID 为 1 的记录，否则会一直卡住，直到超时，其中超时参数是由 innodb_lock_wait_timeout 控制</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
