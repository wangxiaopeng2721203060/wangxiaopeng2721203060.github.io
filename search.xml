<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Docker存储]]></title>
    <url>%2F2096%2F09%2F26%2Fdocker%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[#Docker 存储Docek 镜像层的镜像分层结构 docker的镜像分层结构，如下所示： docker镜像中引入层layer概念，镜像的制作过程中的每一步都会生产一个新的镜像层 容器读写层的工作原理 我们刚刚在说镜像的分层特性的时候说到镜像是只读的。而事实上当我们使用镜像启动一个容器的时候，我们其实是可以在容器里随意读写的，从结果上看，似乎与镜像的只读特性相悖。 我们继续看上面的图，其实可以看到在镜像的最上层，还有一个读写层。而这个读写层，即在容器启动时为当前容器单独挂载。每一个容器在运行时，都会基于当前镜像在其最上层挂载一个读写层。而用户针对容器的所有操作都在读写层中完成。一旦容器销毁，这个读写层也随之销毁。 知识点： 容器=镜像+读写层 而我们针对这个读写层的操作，主要基于两种方式：写时复制和用时分配。 容器 容器由最上面一个可写的容器层和若干个只读的镜像层组成，容器的数据就存在这些层中。这种分层结构最大的特点是Copy-on-Write。 新数据会直接存放在最上面的容器层 修改现有数据会从镜像层复制文件到容器中，再在容器层修改并保存，镜像层的数据不会发生改变 若多个层中有命名相同的文件，用户只能看到最上面一层的文件 分层结构使镜像和容器的创建、共享以及分发变得非常高效，而这些都要归功于 Docerk stoage driver。正是 storage driver 实现了多层数据的堆叠并为用户提供一个单一的合并之后的统一视图。 Docker 为容器提供了两种存放数据的资源： 由storage driver（存储驱动） 管理的镜像层和容器层 用来放一些无状态的数据 对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。 Data Volume。（数据卷） 用来放一些有状态的数据，例如数据库 本质上是 Docker Host （主机）文件系统中的目录或文件，能够直接被 ** mount （挂载）到容器的文件系统中**。 关于docker镜像的三问 基于镜像A创建镜像B时是否会拷贝A镜像中的所有文件：是不会的 基于镜像创建容器时是否会拷贝镜像中的所有文件至文件层：不会的 容器与镜像在结构上有什么区别：没有区别容器会比镜像多了一个 merged文件 在讲原理前，先讲下写时复制和写时分配 写时复制（CoW） 所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论多少个容器共享同一个image，所作的写操作都是从image中复制到自己的文件系统中的复制本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离的，相互不影响。使用CoW可以有效的提高磁盘的利用率。 用时分配（allocate-on-demand） 而用时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。 Docker存储驱动的作用 将这些分层的镜像文件堆叠起来，并且提供统一的视图.使container的文件系统看上去和我们普通的文件系统没什么区别。当创建一个新的容器的时候,实际上是在镜像的分层上新添加了一层container layer（容器层）.之后所有对容器产生的修改,实际都只影响这一层。 注意 容器层：读写层(可写层)镜像层：只读层 Docker 支持多种 storage driver，有 AUFS 、Device Mapper 、Btrfs 、OverlayFS 、VFS 和ZFS。它们都能实现分层的架构，同时又有各自的特性。对于Docker 用户来说，具体选择使用哪个 storage driver 是一个难题，因为： ​ 没有哪个driver 能够适应所有的场景。 ​ driver 本身在快速发展和迭代。 优先使用 Linux 发行版默认的 storage driver。Docker 安装时会根据当前系统的配置选择默认的 driver。默认 driver 具有最好的稳定性，因为默认 driver 在发行版上经过了严格的测试。 运行docker info可以查看可查看当前系统使用的Storage driver。 123456789101112131415161718&gt; &gt; [root@izbp1dg6m4eebtcm77n0smz ~]# docker info&gt; &gt; Client:&gt; &gt; Debug Mode: false&gt; &gt; &gt; &gt; Server:&gt; &gt; Containers: 6&gt; &gt; Running: 4&gt; &gt; Paused: 0&gt; &gt; Stopped: 2&gt; &gt; Images: 4&gt; &gt; Server Version: 19.03.5&gt; &gt; Storage Driver: overlay2&gt; &gt; Backing Filesystem: extfs&gt; &gt; Supports d_type: true&gt; &gt; Native Overlay Diff: false&gt; &gt; Logging Driver: json-file&gt; &gt; Cgroup Driver: cgroupfs&gt; &gt; Ubuntu 用的 AUFS，底层文件系统是 extfs，各层数据存放在 /var/lib/docker/aufs。centos默认的driver用的是overlay2，底层的文件系统是xfs,各层数据存放在/var/lib/docker 而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。 比如启动一个容器，并不是为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。 docker提供了多种的存储驱动来实现不同的方式存储镜像 Docker五种存储驱动原理及应用场景和性能测试对比 Docker 最开始采用AUFS作为文件系统，也得益于AUFS分层的概念，实现了多个Container可以共享同一个image。但由于AUFS 为并入 Linux内核，且只支持 Ubuntu，考虑到兼容的问题，在 Docker 0.7 版本中引入了存储驱动，就如Docker官网上说的，没有单一的驱动适应所有的应用场景，要根据不同的场景选择合适的存储驱动，才能有效的提高Docker 的性能。如何选择适合的存储驱动，要先了解存储驱动原理才能更好的判断。 接下来我们说说这些分层的镜像是如何在磁盘中存储的。 docker 提供了多种存储驱动来实现不同的方式存储镜像 下列出了 Docker 中支持的存储驱动程序： 技术 存储驱动成名称 OverlayFS overlay 或 overlay2 AUFS aufs Btrfs btrfs Device Mapper devicemapper VFS vfs ZFS zfs AUFS AUFS（AnotherUnionFS）是一种 Union FS ，是文件级的存储驱动。AUFS 是一个能透明覆盖一个或多个县有文件系统的层状文件系统，把多层合并成文件系统的单层表示。简单来说就是支持将不同目录挂载到同一个虚拟文件系统下的文件系统。这种文件可以一层一层地叠加修改文件。无论低下有多少层都是只读的，只有最上层的文件系统是可写的。当需要修改文件时，AUFS创建该文件的一个副本，使用CoW将文件从只读层复制到可写层进行修改，结果保存在可写层。在Docker中，低下的只读层就是image，可写层就是Container。结构如下图所示： 历史：aufs驱动老早就在Docker中存在了！其实，他在使用graphdriver这个名字之前久存在了。如果你查看项目在那（即首次使用graphdriver名称）提交之前的历史，之前项目中当时只有一个aufs的实现。下边devicemapper部分会讲到更多关于graphdriver这个名称诞生的历史。 实现：Aufs最初代表的意思“另一个联合文件系统（another union filesystem）”，试图对当时已经存在的UnionFS实现进行重写。正如你期望的那样，它是一个传统意义的上层覆盖，通过利用aufs称作为“分支（branch）”的特性，让堆叠的目录合并成一个堆叠内容单一挂载点视图。此驱动会将父级信息组合一个有序列表，并把它作为挂载参数，然后把重活移交给aufs来把这些分层组装成一个联合视图。更多的细节信息可以在aufs的帮助文档上看到。 优点：这可能是历史最久且测试最完善的graphdriver后端了。它拥有不错的性能，也比较稳定，适用于广泛的场景。尽管它只在Ubuntu或者Debian的内核上才可以启用（下边有说明），但是这两个发行版和Docker一起使用的场景已经非常多，这让它在广阔的环境中得到了验证。同时，通过让不同的容器从同一个分层里面加载相同的库（因为他们在磁盘上是相同的inode）达到了共享内存页的效果。 缺点：Aufs从来没有被上游Linux内核社区接受。多年来Ubuntu和Debian都需要往内核集成一个历史久远的补丁包，且原作者已经放弃了让它被内核采纳的努力。可能与IPV4和IPv6的辩论有些类似，人们担心某一天内核更新后会出现难以整合aufs的补丁的情况，从而导致aufs没得玩。但是就如IPv6，替换aufs势在必行的决心讲了一年又一年。除此之外，它面临着很多其他比较棘手的问题。其中一个最麻烦的、也是比较有历史的问题（尽管某种程度上这是一个安全的特性），是关于在高层更改向上拷贝的文件的权限的，这个问题困扰了不少用户。最终在2015年早期的时候通过编号为#11799的PR使用aufs的dirperm1特性修复了。自然，这需要内核中有具有dirperm1能力aufs，然而这在今天任何较新版本的Ubuntu或者Debian上都已经不成问题了。 总结：如果你在使用Ubtuntu或者Debian，那默认的graphdriver就是aufs，它能满足你绝大多数需求。有人期望有一天它能被overlay的实现取代，但是考虑到overlay文件系统的诸多问题，以及在上游内核中的成熟程度等挑战，这尚未实现。最后，aufs中没有配额的支持。 Overlay Overlay 是Linux内核3.18后支持的，也是一种Union FS，和AUFS的多层不同的是Overlay只有两层：一个upper文件系统和一个lower文件系统，分别代表Docekr的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。在Docekr中，底下的只读层就是image，可写层就是Container。目前最新的OverlayFS为Overlay2。结构图如下所示： 历史：2014年8月，Red Hat的 Alex Larsson在编号为453552c8384929d8ae04dcf1c6954435c0111da0的代码提交中添加了针对OverlayFS（最初的上游内核的名称）的graphdriver。 实现：Overlay是一个联合文件系统，它的概念较之aufs的分支模型更为简单。Overlay通过三个概念来实现它的文件系统：一个“下层目录（lower-dir）”，一个“上层目录（upper-dir）”，和一个做为文件系统合并视图的“合并（merged）”目录。受限于只有一个“下层目录”，需要额外的工作来让“下层目录”递归嵌套（下层目录自己又是另外一个overlay的联合），或者按照Docker的实现，将所有位于下层的内容都硬链接到“下层目录”中。正是这种可能潜在的inode爆炸式增长（因为有大量的分层和硬连接）阻碍了很多人采用Overlay。Overlay2通过利用更高内核（4.0以及以上的版本）中提供了的更优雅处理多个位于下层分层的机制解决了这个问题。 优点：Overlay作为一个合并进主线Linux内核的一个有完整支持的联合文件系统有望成为人们的焦点。与aufs类似，通过使用磁盘上相同的共享库，它也能让分散的容器实现内存共享。Overlay同时有很多的上游Linux内核基于现代的应用场景，如Docker，被持续开发（参看overlay2）。 缺点：硬链接的实现方式已经引发了 inode耗尽的问题，这阻碍了它的大规模采用。inode耗尽并不是唯一的问题，还有其他一些与用户命名空间、SELinux支持有关的问题，且整体的成熟状况不足也阻碍着overlay直接取代aufs成为Docker默认的graphdriver。随着很多问题的解决，特别是在最新的内核发新版中，overlay的可用度越来越高了。如今出现的Overlay2修复了inode耗尽的问题，应该是从Docker 1.12版本之后的焦点，成为overlay驱动的后续开发对象。出于向后兼容的原因，overlay驱动将会继续留在Docker引擎中继续支持现有的用户。 总结：考虑到aufs没有足够多的发行版的支持，能有一个上游集成的联合文件系统且拥有Linux内核文件系统社区的支持，overlay驱动的加入是一个重大进步。Overlay在过去的18-24个月已经成熟了很多，并且随着overlay2的出现，它之前一些麻烦的问题已经解决了。希望overlay（或者更具可能性的overlay2）会成为未来默认的graphdriver。为了overlay最好的体验，上游内核社区在4.4.x的内核系列里面修复了很多overlay实现中存在的问题；选择该系列中更新的版本可以获得overlay更好的性能和稳定性。 Overlay2 历史：Derek McGowan在编号为#22126的PR中添加了overlay2的graphdriver，在2016年6月被合并进Docker 1.12版本，正如该PR的标题注明的，要取代之前overlay的主要原因是它能“支持多个下层目录”，能解决原先驱动中inode耗尽的问题。 实现：在上面的overlay部分已经讲述了Linux内核中的Overlay的框架。上面链接的PR中改进了原有的设计，基于Linux内核4.0和以后版本中overlay的特性，可以允许有多个下层的目录。 优点：overlay2解决了一些因为最初驱动的设计而引发的inode耗尽和一些其他问题。Overlay2继续保留overlay已有的优点，包括在同一个引擎的多个容器间从同一个分层中加载内库从而达到内存共享。 缺点：现在可能唯一能挑出overlay2的问题是代码库还比较年轻。很多早期的问题已经在早期测试过程中发现并被及时解决了。但是Docker 1.12是第一个提供overlay2的发行版本，随着使用量的增长，相信可能还会发现其他问题。 总结：将Linux内核中的一个现代的、广受支持的联合文件系统，和一个和Docker中一个性能优秀的graphdriver结合起来，这应该是Docker引擎未来打造默认的graphdriver最好的道路，只有这样才能获得各种Linux发行版广泛的支持。 Device mapper Device mapper 是Linux 内核 2.6.9 后支持的，提供的一种从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略。前面讲的 AUFS 和 OverlayFS 都是文件级存储，而 Device mapper 是块级存储，所有的操作都是直接对块进行操作，而不是文件。Device mapper 驱动会先在块设备上创建一个资源池，然后在资源池上创建一个带有文件系统的基本设备，所有镜像都是这个基本设备的快照，而容器则是镜像的快照。所以在容器里看到文件系统是资源池上基本设备的文件系统的快照，并不有为容器分配空间。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个用时分配。当要修改已有文件时，再使用 CoW 为容器快照分配块空间，将要修改的数据复制在容器快照中新的块里在进行修改。Device mapper 驱动默认会创建一个 100 G 的文件包含镜像和容器。每个容器被限制在 10G 大小的卷内，可以自己设置调整。结构如下图所示： 历史：Devicemapper很早就以Ｃ代码的包装器面貌存在了，用来和libdevmapper进行交互； 是2013的９月Alex Larsson在编号为 739af0a17f6a5a9956bbc9fd1e81e4d40bff8167的代码提交中添加的。几个月后的重构了才诞生了我们现在所知道的“graphdriver”这个词；Solomon Hykes在2013年10月份早期代码合并的注释中说：将devmapper和aufs整合进通用的“graphdriver”框架。 实现：devicemapper这个graphdriver利用了Linux中devicemapper代码中众多特性之一，“轻配置（thin provisioning）”，或者简称为“thinp”。（译注：根据Wikipedia，“thin provisioning是利用虚拟化技术，让人觉得有比实际可用更多的物理资源。如果系统的资源足够，能同时满足所有的虚拟化的资源，那就不能叫做thin-provisioned。”） 这与之前提到的联合文件系统不同，因为devicemapper是基于块设备的。这些“轻配置（thin-provisioned）”的块设备带来的是如联合文件系统所提供的一样轻量的行为，但是最重要的一点是，他们不是基于文件的（而是基于块设备的）。正如你能推测的，这让计算分层之间的差别变得不再容易，也丧失了通过在容器间使用同样的库片段而共享内存的能力。 优点：Devicemapper在过去的年间也被一些人感到不屑，但是它提供的一个非常重要的能力让红帽系（Fedora,RHEL，Project Atomic）也有了一个graphdriver。因为它是基于块设备而不是基于文件的，它有一些内置的能力如配额支持，而这在其他的实现中是不容易达到的。 缺点：使用devicemapper没有办法达到开箱立即唾手可得很好的性能。你必须遵循安装和配置指示才能得到性能还可以的配置。并且最重要的是，在任何需要用Docke引擎来做点正事的地方，都不要使用“虚拟设备（loopback）”模式（对于运行有devicemapper且负载高的系统，如延迟删除（ deferred removal）这样的特性绝对有必要的，这能减少引擎看起来好似夯住了一样的悲剧。）。它的一些特性依赖libdevmaper特定的版本，并且需要比较高级的技能来验证系统上所有的设置。同时，如果Docker Engine的二进制是静态编译的话，devicemapper会完全无法工作，因为它需要udev sync的支持，而这不能被静态编译进引擎中。 总结：对于红帽类发行版本来说，devicemapper已经成为“可以直接用”的选择，并且在过去几年间里得到了红帽团队的大力支持和改进。它质量上有优点也有缺点，如果安装/配置过程中没有特别格外注意的话，可能导致和其他选项比较起来性能低下、质量不高。鉴于overlay和overlay2受到了Fedora和RHEL最新的内核的支持，并且拥有SELinux的支持，除非在Red Hat场景中有某种必须使用devicemapper的需求，我想随着用户的成熟他们会转向overlay的怀抱。 Btrfs Btrfs 被称为下一代写时复制文件系统，并入Linux内核，也是文件级存储，但可以向 Device mapper 一直操作底层设备。 Btrfs 把文件系统的一部分配置为一个完整的子文件系统，称为 subvolume。那么采用 subvolume ，一个大的文件系统可以被划分为很多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间使用时便从底层设备中分配，类似应用程序调用 malloc（）分配内存一样。为了灵活利用设备空间， Btrfs 将磁盘空间划分为多个 chunk。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata ，某些chunk 只存放数据。这种模型有很多优点，比如 Btrfs 支持动态添加设备。用户在系统中添加新的磁盘之后，可以使用 Btrfs 的命令将该设备添加到文件系统中。Btrfs 把一个大的文件系统当成一个资源池，配置成多个完整的子文件系统，还可以往资源池里加新的子文件系统，而基础镜像则是子文件系统的快照，每个子镜像和容器都有自己的快照，这些快照都是 subvolume 的快照。 当写入一个新文件时，为在容器的快照里为其分配一个新的数据块，文件写在这个空间里，这个叫做分配。而当要修改已有文件时，使用 CoW 复制分配一个新的原始数据和快照，在这个新分配的空间变更数据，变结束再跟新相关的数据结构指向新子文件系统和快照，原来的原始数据和快照没有指针指向，被覆盖。 历史：2013年12月较晚的时候，Red Hat公司的Alex Larsson在编号为e51af36a85126aca6bf6da5291eaf960fd82aa56的提交中，让使用btrfs作为管理/var/lib/docker的文件系统成为可能。 实现：Btrfs的原生特性中，有两个是“子卷（subvolumes）”和“快照（snapshots）”。（译注：根据Wikipedia，“子卷在btrfs中不是一个块设备，也不应该被当做是一个块设备。相反，子卷可以被想象成POSIX文件的命名空间。这个命名空间可以通过顶层的子卷来访问到，也可以独立地被挂载。快照在Btrfs中实际上是一个子卷，通过使用Btrfs的写时复制来和其他的子卷共享数据，对快照的更改不会影响原先的子卷。” ） graphdriver实现中主要结合了这两个能力，从而提供了堆叠和类似写时复制的特性。当然，graphdriver的根（默认情况下是：/var/lib/docker）需要是一个被btrfs文件系统格式化的磁盘。 优点：Btrfs几年前发布的时候（2007-2009时代），它被视作一个未来的Linux文件系统并受到了大量的关注。如今在上游Linux内核中，该文件系统已经比较健壮，并受到良好的支持，是众多可选的文件系统之一。 缺点：但是Btrfs并没有成为Linux发行版的主流选择，所以你不大可能已经有一个btrfs格式化的磁盘。因为这种在Linux发行版中采用不足的原因，它并没有受到类似其他graphdriver一样的关注和采用。 总结：如果你正在使用btrfs，那很显然的这个graphdriver应该迎合了你的需求。在过去几年有过很多Bug，并且有一段时间缺乏对SELinux的支持，但是这已经被修复了。同时，对btrfs配额的支持也直接加进了docker守护进程中，这是Zhu Guihua在编号为#19651的PR中添加的，这个特性包含在了Docker 1.12版本中。 ZFS ZFS 文件系统是一个革命性的全新的文件系统，它从根本上改变了文件系统的管理方式， ZFS 完全抛弃了 “ 卷管理 ” ，不再创建虚拟的卷，而是把所有设备集中到一个存储池中进行管理，用 “ 存储池 ” 的概念来管理物理存储空间。过去，文件系统都是构建在物理设备之上的，为了管理这些物理设备，并为数据提供冗余，“ 卷管理 ” 的概念提供了一个单设备的映射。而 ZFS 创建在虚拟的，被称为 “ zpools ” 的存储池之上。每个存储池由若干虚拟设备（ virtual devices ，vdevs ）组成。这些虚拟设备可以是原始磁盘，也节能是一个RAID1 镜像设备，或是非标准 RAID 等级的多磁盘组。 于是 zpool 上的文件系统可以使用这些虚拟设备的总存储容量。 下面看一下Docker 里ZFS的使用。首先从 zpool里分配一个ZFS 文件系统给镜像的基础层，而其他镜像层则是这个 ZFS 文件系统快照的克隆，快照是只读的，而克隆是可写的，当容器启动时则在镜像的顶层生成一个可写层。如下图所示： d当要写一个新文件时，使用按需分配，一个新的数据块从 zpool 里生成新的数据写入这个块，而这个新空间存于容器（ ZFS 的克隆 ）里。 当要修改一个已存在的文件时，使用写时复制，分配一个新空间并把原始数据复制到新空间完成修改。 历史：ZFS的graphdriver是由Arthur Gautier和Jörg Thalheim一起在#9411的PR中实现的，在2014年的5月被合并进了Docker引擎里面，并且从Docker 1.7版本开始用户可以使用。该实现依赖Go的一个三方包go-zfs进行相关zfs命令的交互。 实现：与btrfs和devicemapper类似，要使用zfs驱动必需要有一个ZFS格式化的块设备挂载到graphdriver路径（默认是/var/lib/docker）。同时也需要安装好zfs工具（在绝大多数的发行版上是一个名为zfs-utils的包）供zfs Go库调用来执行相关操作。ZFS有能力创建快照（与btrfs类似），然后以快照的克隆作为分享层的途径（在ZFS的实现中成了一个快照）。因为ZFS不是一个基于文件的实现，aufs和overlay中所拥有的内存共享能力在ZFS是没有的。 优点：ZFS正在受到越来越多的欢迎，在Ubuntu 16.04中，在Ubuntu的LXC/LXD中已经被使用。最初由Sun创建，ZFS已经存在很长的时间了，并且在Solaris和很多BSD的衍生版中使用，并且它的Linux移植版实现看起来也比较稳定，对于容器文件系统的场景也有足够合理性能。ZFSgraphdriver也很及时的在Dockr 1.12中通过PR #21946添加了配额的支持，这让它在配额支持方面和btrfs、devicemapper站在了同一起跑线上。 缺点：除了没有基于文件（inode）的共享达到内库共享之外，很难说ZFS和其它同样基于块设备的实现相比有什么缺点。通过比较，ZFS看起来欢迎程度越来越高。对于那些完全支持或者正在使用ZFS的Linux发行版或者UNIX衍生版而言，zfs graphdriver可以是一个非常好的选择。 总结：ZFS的支持为Docker引擎中稳定的graphdriver加了分。对于那些ZFS的使用者，或者那些ZFS扮演了更要角色的发行版来说，Docker能直接支持该文件系统，对这些社区来说是一个好消息。对于那些默认文件系统是ext4和xfs的发行版，默认采用overlay驱动的用户来说，时间会告诉我们他们是否会对zfs驱动产生更多的兴趣。 存储驱动的对比及适应场景 存储驱动 特点 优点 缺点 适用场景 AUFS 联合文件系统、未并入内核主线、文件级存储 作为docker的第一个存储驱动，已经有很长的历史，比较稳定，且在大量的生产中实践过，有较强的社区支持 有多层，在做写时复制操作时，如果文件比较大且存在比较低的层，可能会慢一些 大并发但少IO的场景 overlayFS 联合文件系统、并入内核主线、文件级存储 只有两层 不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件消耗更多的时间 大并发但少IO的场景 Devicemapper 并入内核主线、块级存储 块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件 不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本，在很多容器启停的情况下可能会导致磁盘溢出 适合io密集的场景 Btrfs 并入linux内核、文件级存储 可以像devicemapper一样直接操作底层设备，支持动态添加设备 不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本 不适合在高密度容器的paas平台上使用 ZFS 把所有设备集中到一个存储池中来进行管理 支持多个容器共享一个缓存块，适合内存大的环境 COW使用碎片化问题更加严重，文件在硬盘上的物理地址会变的不再连续，顺序读会变的性能比较差 适合paas和高密度的场景 AUFS VS Overlay AUFS和Overlay都是联合文件系统，但AUFS有多层，而Overlay只有两层，所以在做写时复制操作时，如果文件比较大且存在比较低的层，则AUSF可能会慢一些。而且Overlay并入了linux kernel mainline，AUFS没有，所以可能会比AUFS快。但Overlay还太年轻，要谨慎在生产使用。而AUFS做为docker的第一个存储驱动，已经有很长的历史，比较的稳定，且在大量的生产中实践过，有较强的社区支持。目前开源的DC/OS指定使用Overlay。 Overlay VS Device mapper Overlay是文件级存储，Device mapper是块级存储，当文件特别大而修改的内容很小，Overlay不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件要消耗更多的时间，而块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件，在这种场景下，显然device mapper要快一些。因为块级的是直接访问逻辑盘，适合IO密集的场景。而对于程序内部复杂，大并发但少IO的场景，Overlay的性能相对要强一些。 Device mapper VS Btrfs Driver VS ZFS Device mapper和Btrfs都是直接对块操作，都不支持共享存储，表示当有多个容器读同一个文件时，需要生活多个复本，所以这种存储驱动不适合在高密度容器的PaaS平台上使用。而且在很多容器启停的情况下可能会导致磁盘溢出，造成主机不能工作。Device mapper不建议在生产使用。Btrfs在docker build可以很高效。ZFS最初是为拥有大量内存的Salaris服务器设计的，所在在使用时对内存会有影响，适合内存大的环境。ZFS的COW使碎片化问题更加严重，对于顺序写生成的大文件，如果以后随机的对其中的一部分进行了更改，那么这个文件在硬盘上的物理地址就变得不再连续，未来的顺序读会变得性能比较差。ZFS支持多个容器共享一个缓存块，适合PaaS和高密度的用户场景。 IO性能对比 测试工具：IOzone（是一个文件系统的benchmark工具，可以测试不同的操作系统中文件系统的读写性能）测试场景：从4K到1G文件的顺序和随机IO性能测试方法：基于不同的存储驱动启动容器，在容器内安装IOzone，执行命令： 1./iozone -a -n 4k -g 1g -i 0 -i 1 -i 2 -f /root/test.rar -Rb ./iozone.xls 测试项的定义和解释 Write：测试向一个新文件写入的性能。Re-write：测试向一个已存在的文件写入的性能。Read：测试读一个已存在的文件的性能。Re-Read：测试读一个最近读过的文件的性能。Random Read：测试读一个文件中的随机偏移量的性能。Random Write：测试写一个文件中的随机偏移量的性能。 测试数据对比 Write： Re-write: Read： Re-Read： Random Read： Random Write： 通过以上的性能数据可以看到： AUFS在读的方面性能相比Overlay要差一些，但在写的方面性能比Overlay要好。 device mapper在512M以上文件的读写性能都非常的差，但在512M以下的文件读写性能都比较好。 btrfs在512M以上的文件读写性能都非常好，但在512M以下的文件读写性能相比其他的存储驱动都比较差。 ZFS整体的读写性能相比其他的存储驱动都要差一些。 简单的测试了一些数据，对测试出来的数据原理还需要进一步的解析。 Docker 提供了可插拔的存储驱动程序架构。它使我们能够灵活地 插入 Docker中的存储驱动程序。他完全基于Linux文件系统 。 要实现这一功能，我们必须 在docker 守护进程的开始时就设置驱动程序。 Docker 守护程序只能运行一个存储驱动程序，并且该守护程序实例创建的所有容器使用相同的存储驱动程序。 当前存储驱动 查看守护程序使用哪个存储驱动程序，可以使用一下命令。 1$ docker info 可以看到上面的命令显示了守护进程使用的存储驱动程序。备份文件系统 extfs 。 extfs 表示覆盖存储驱动程序在文件系统的顶部运行。 后备文件系统实质用于在 /var/lib/docker 录下创建 Docker 主机的本地存储区域的文件系统。 下表包含必须与主机备份文件系统相匹配的存储驱动程序。 存储驱动 常用 已禁用 overlay ext4xfs btrfs aufs overlayzfs eCryptfs overlay2 ext4xfs btrfs aufs overlayzfs eCryptfs aufs ext4xfs btrfs aufs eCryptfs aufs btrfsonly N/A devicemapper Direct-lvm N/A vfs debugging only N/A N/A 注意 ：- “已禁用/Disabled on” 表示某些存储驱动程序无法在某些后台文件系统上运行 设置存储驱动程序 可以通过 dockersd命令按指定名称来设置存储驱动程序。以下命令启动守护程序并设置新的驱动程序。 1$ dockerd --storage-driver=devicemapper 稍后，可以通过 docker info 命令检查 docker 服务驱动程序 对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。 1234# 如一些工具箱，启动是为了执行命令，不需要保存数据供以后使用，使用完直接退出，容器删除时存在容器层的工作数据也一起删除，这没问题，下次启动新容器即可。# 但对于另一类应用这种方式就不合适了，它们有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的，例如数据库。这就要用到docker 的另一个存储机制：data volume Data Volume（数据卷） 对于有些容器，我们可能会持久化数据的需求，也就是容器启动时需要加载已有的数据，容器销毁时希望保留产生的数据，也就是说这类容器是有状态的。 这就需要用到 Docker 的 Data Volume 存储机制。Data Volume本质上是 Docker host文件系统中的目录或文件，能够直接被 mount 到容器的文件系统。 在具体的使用上，Docekr 提供了两种类型的Volume：bind mount 和docker managed volume。 附：bind mount 与 docker managed volume 的区别 这两种 data volume 实际上都是使用 host 文件系统的中的某个路径作为 mount 源。它们不同之处在于： 不同点 bind mount docker managed volume volume 位置 可任意指定 /var/lib/docker/volumes/… 对已有mount point 影响 隐藏并替换为 volume 原有数据复制到 volume 是否支持单个文件 支持 不支持，只能是目录 权限控制 可设置为只读，默认为读写权限 无控制，均为读写权限 移植性 移植性弱，与 host path 绑定 移植性强，无需指定 host 目录 什么是数据卷 Data Volume 数据卷 ：是可以存放在一个或多个容器内的 特定的目录，提供独立于容器之外的持久化存储；是经过特殊设计的目录，可以绕过联合文件系统（UFS），为一个或多个容器提供访问； 12345678910Docker Contrainer面向对象中的对象对象一旦被销毁，数据就不存在了容器一旦被销毁，则容器内的数据将一并被删除服务器中的图案也会一并销毁容器中的数据不是持久化状态的 不使用 volume的时候，对容器进行的改动是不会被保存的，使用 volume可以实现持久化存储；比如运行一个数据的操作，数据库的一个容器，数据库的数据应该被持久化存储的，volume就可以实现这个，并且 volume可以提供容器与容器之间的共享数据； Docker 的理念之一： 就是将其应用于其运行的环境打包，因此，通过Docker 容器的生存周期，都是与容器中运行的程序相一致的，而我们对数据的要求通常是持久化的；另一方面，docker容器之间也需要有一个 共享数据的渠道 ，而这些需求就催生出了docker数据卷的产生； 数据卷的设计的目的： 在于 数据的永久化 ，它完全独立于容器的生存周期，因此，Docekr不会在容器删除时删除其挂载的数据卷，也不会存在类似垃圾收集机制，对容器引用的数据卷进行处理了； 数据卷特点： Docker数据卷是独立于Docker的存在，它存在于Docker host（宿主机）中，因此，它与容器的生存周期是分离的； Docker数据卷本质上是存在于Docker宿主机的本地文件系统中； Docker 数据卷可以是目录也可以是文件；（不是块设备） Docker 容器可以利用数据卷的技术与容器宿主机进行数据共享； 同一个目录或者文件，可以支持多个容器进行访问，这样其实实现了容器的数据共享和交换； 数据卷是在容器启动是进行初始化的，那么如果容器使用的镜像包含了的数据也会在容器启动时拷贝到容器的数据卷中； 数据卷可以在容器之间共享和重用； 数据卷的修改会立马生效；容器可以对数据卷里的内容直接修改；容器对数据卷进行的修改是及时的，所有的修改都会直接体现在数据卷中； 数据卷的更新不会影响镜像；因为文件不会写到镜像中去，数据卷是独立于联合文件系统的，而镜像本身基于联合文件系统，so镜像与数据卷之间不会有相互影响的情况； 数据卷会一直存在，即使挂载数据卷的容器已经删除因为数据均本质上是宿主机上的一个目录，同时为了提供数据的永久化，它的生存周期与容器是完全隔离的； Docker 容器中的数据操作经过了UFS 的，UFS 会在宿主机中写一次文件，这个文件在宿主机上是临时的，这时候就出现了重复写的情况，会影响系统的性能；此外，删除容器的时候，就没有人能够通过UFS 在访问到宿主机中的文件了； 容器卷可以绕过 UFS 直接操作主机上的文件，当容器删除的时候，宿主机上的文件还在，就在指定的目录下，在重新创建容器的时候们可以指定容器继续读取宿主机上的文件； 创建一个数据卷 包含数据卷挂载的容器在容器关闭时，如果修改了宿主机下的数据卷会，容器里面会产生改变吗？ bind mount 数据卷 使用docker run –name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx 创建一个bind mount 数据卷 是宿主机的存储位置必须是绝对路径。目录不存在则会生成 12345678# 以下两种情况创建的数据卷如果浏览器访问宿主机的ip:8080 会出现报错，因为这是创建的时候清空了容器数据卷下index.html# 创建的宿主机和容器的数据卷都有读写的权限$ docker run --name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx# 这样执行后的文件宿主机的~/myvolume 文件如果不存在直接创建，容器的文件路径不存在也会直接创建，如果/usr/share/nginx/html文件存在里面内容会清空# 给容器里面的数据卷加权限$ docker run --name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html:ro nginx# 如果执行这个 :/usr/share/nginx/html:ro这个地方加的是 :ro 是设置的只有读取权限 123456789101112131415# 运行dockers inspect 容器名称或容器（ID） 是将容器的配置文件已json字符串的形式返回&quot;Binds&quot;: [ &quot;/root/myvolume:/usr/share/nginx/html&quot; # 宿主机数据卷位置: 容器的目录位置 ],&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/root/myvolume&quot;, # 是宿主机数据卷的存储位置 &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, # 权限 true是可以读写 fales 是只读 &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 123# 在宿主机的数据卷下执行:vim index.html # 在文件里写入hello ， 你在访问的时候就可以在页面上看到你写入得数据了 执行 docker exec -it 容器名称（容器ID） bahs进入到容器里面，每个容器都会包含一个迷你版的linux系统 执行 cd /usr/share/nginx/html 执行 ls 你会看到容器目录里会有我们刚才创建好的文件 index.html 执行 cat index.html 可以看到里面我们加入的数据 如果是挂载数据卷的时候加 :ro 容器内修改文件，发现会提示该文件是只读的 docker managed volume 数据卷 创建出来的两个都是有读写权限的 使用docker run –name nginx-test2 -p 8080:80 -d -v /usr/share/nginx/html nginx 创建一个docker managed volume 数据卷 这种命令创建是不用指定宿主机数据卷存储位置的默认在 /var/lib/docker/volumes/ 下的文件名是经过sha256 摘要过的 查看宿主机创建出来的数据卷 123456$ cd /var/lib/docker/volumes/$ ls 8d668720aaeccee44b5fb554571912a6a257eb3a28cecf334203805a0c9b6fd3 #这是自己创建出来的数据卷# 执行 cd _data 进入这这个文件夹里面$ ls50x.html index.html # 这两个文件是把容器里文件给拷贝了出来 可以在宿主机或者容器里面都可以对文件进行读写操作 挂载多个目录实现数据卷的 就是执行多个 -v 就可以 容器间的数据共享 数据卷容器挂载了一个本地文件系统的目录，其它容器通过挂载这个数据卷容器来实现容器间的数据的共享； 容器间挂载 创建数据卷，只要在docker run命令后面跟上-v参数即可创建一个数据卷，当然也可以跟多个-v参数来创建多个数据卷，当创建好带有数据卷的容器后，就可以在其他容器中通过--volumes-from参数来挂载该数据卷了，而不管该容器是否运行。 1docker run -tid --rm --volumes-from nginx-test --name nginx-test3 nginx -i : 以交互模式运行容器，通常与 -t 同时使用； -t : 为容器重新分配一个伪输入终端，通常与 -i 同时使用； -d : 后台运行容器，并返回容器ID； 再创建一个nginx-test4，挂载nginx-test3中从nginx-test挂载的数据卷，当然也可以直接挂载初识的nginx-test容器的数据卷 12* 即使删除了初始的数据卷容器 nginx-test，或者是删除了其他容器，但只要是有容器在使用该数据卷，那么它里面的数据就不会丢失* 命令中的rm表示当容器退出即停止的时候，会自动删除该容器 备份数据卷 创建一个容器container1，包含两个数据卷/usr/share/nginx/html1和/usr/share/nginx/html2（这两个目录是在容器里的数据卷路径） 12345678910$ docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container1 -p 8080:80 nginx# 创建容器container1$ docker exec -it container1 bash #进入创建好的容器里面$ cd html1/ # 进入到html1数据卷中$ echo html1 &gt;&gt; 1.text # 向 1.text 文件中追加数据，文件不存在则会创建文件$ cd html2/ # 进入到html2数据卷中$ echo html2 &gt;&gt; 2.text # 向 2.text 文件中追加数据，文件不存在则会创建文件 接下来进行数据卷的备份操作 使用 - -volumes-from 来创建一个加载 container1 容器卷的容器，并从宿主机挂载当前所在目录到容器的 /backup 目录，容器内会 tar 压缩 /var/colume1 目录下的文件到 /backup/backup1.tar，因为宿主机当前目录已经映射到 /backup 目录了，因此会在宿主机当前目录也存在该压缩包。备份完毕后 -rm 自动删除该创建的容器。 备份container1容器中的/usr/share/nginx/html1数据卷数据 123456789101112# 备份container1容器中的/usr/share/nginx/html1数据卷数据# -tid 这个参数加不加都可以# --rm 加上，备份后就会自动删除这个容器，如果不加这个 --rm 参数，name备份后的容器就会保留，docker ps -a就会查看到）# $(pwd) [root@iz2zefaujekcdpmfw1qs4az ~]# pwd/root[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup1.tar /usr/share/nginx/html1b3663a3bdd302a38036d6a156471cd448c8e5b9333a20f9480b3c61cbd9270df[root@iz2zefaujekcdpmfw1qs4az ~]# lsbackup1.tar –volumes-from [containerName]：这个命令来指定需要备份的容器的名字；（数据卷容器的名字） -v $(pwd):/backup:权限：使用-v命令来指定希望备份文件存放的位置；本地存放目录：容器存放目录：读写权限；（默认权限是读写） tar cvf /backup/backup.tar [container data volume]：tar表示执行备份的操作是：压缩文件的命令； /backup/backup.tar是文件存放的地址， [container data volume]指定需要备份的目录； tar cvf 压缩；tar xvf解压缩； 备份container1容器中的/usr/share/nginx/html2数据卷数据 12345678910111213# 备份container1容器中的/usr/share/nginx/html2数据卷数据[root@iz2zefaujekcdpmfw1qs4az ~]# pwd/root[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup2.tar /usr/share/nginx/html2001129bc393d5d0ed4665d053d4ca7972584cf2bd56980064be182ec758138cd[root@iz2zefaujekcdpmfw1qs4az ~]# lltotal 22464-rw-r--r-- 1 root root 10240 Dec 16 18:52 backup1.tar # 文件1-rw-r--r-- 1 root root 10240 Dec 16 19:05 backup2.tar # 文件2drwxr-xr-x 2 root root 4096 Dec 16 16:45 myvolume-rw-r--r-- 1 root root 22973527 Mar 26 2019 Python-3.7.3.tgz 备份container1 容器中的 /usr/share/nginx/html1 和 /usr/share/nginx/html2 数据卷数据 1234567891011121314# 备份container1 容器中的 /usr/share/nginx/html2 和 /usr/share/nginx/html2 数据卷数据[root@iz2zefaujekcdpmfw1qs4az ~]# pwd/root[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup.tar /usr/share/nginx/html1 /usr/share/nginx/html2441df929e123cbe51564ca3d6bf3f06a5ea415298a34bb9871f1ed2b68a60102[root@iz2zefaujekcdpmfw1qs4az ~]# lltotal 22476-rw-r--r-- 1 root root 10240 Dec 16 18:52 backup1.tar-rw-r--r-- 1 root root 10240 Dec 16 19:05 backup2.tar-rw-r--r-- 1 root root 10240 Dec 16 19:09 backup.tardrwxr-xr-x 2 root root 4096 Dec 16 16:45 myvolume-rw-r--r-- 1 root root 22973527 Mar 26 2019 Python-3.7.3.tgz 恢复数据给同一个容器 之前的数据卷是从 container1 中备份的，现在模拟 container1 数据卷丢失，然后直接用之前备份的 backup.tar 进行恢复 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 为了测试恢复，先删除容器里原先的数据（注意：数据卷目录不能删除，只能删除其中的数据）[root@iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container1 bash #进入到创建的容器里root@6869560e6ff5:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@6869560e6ff5:/# cd /usr/share/nginx #进入到容器里面的数据卷所在的目录root@6869560e6ff5:/usr/share/nginx# lshtml html1 html2 root@6869560e6ff5:/usr/share/nginx# cd html1# 进入到 html1 数据卷目录root@6869560e6ff5:/usr/share/nginx/html1# ls1.textroot@6869560e6ff5:/usr/share/nginx/html1# rm -rf 1.text # 删除 1.text 文件root@6869560e6ff5:/usr/share/nginx/html1# lsroot@6869560e6ff5:/usr/share/nginx# cd html2# 进入到 html2 的数据卷目录root@6869560e6ff5:/usr/share/nginx/html2# ls2.textroot@6869560e6ff5:/usr/share/nginx/html2# rm -rf 2.text # 删除 2.text 文件root@6869560e6ff5:/usr/share/nginx/html2# ls# 进行数据卷恢复，恢复数据卷中的所有数据注意-C后面的路径，表示将数据恢复到容器里的路径直接使用压缩包中文件的各个路径。比如压缩包中的结果如下：tar -xvf backup.tar #解压压缩文件# 数据1usr/share/nginx/html1/1.text--usr --share --nginx --html1 --1.text# 数据2 usr/share/nginx/html2/2.text--usr --share --nginx --html2 --2.text# 直接将文件解压到 /usr/share/nginx/html1 和 /usr/share/nginx/html2 目录[root@iz2zefaujekcdpmfw1qs4az ~]# docker run --rm --volumes-from container1 -v $(pwd):/backup nginx tar xvf /backup/backup.tar -C /usr/share/nginx/html1/usr/share/nginx/html1/1.textusr/share/nginx/html2/usr/share/nginx/html2/2.text# 直接进入容器查看[root@iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container1 bashroot@6869560e6ff5:/# cd /usr/share/nginx/ root@6869560e6ff5:/usr/share/nginx# lshtml html1 html2# 查看数据是否存在root@6869560e6ff5:/usr/share/nginx# ls html11.textroot@6869560e6ff5:/usr/share/nginx# ls html22.textroot@6869560e6ff5:/usr/share/nginx# cat html1/1.text html1root@6869560e6ff5:/usr/share/nginx# cat html2/2.text html2 恢复数据给新的容器1234567891011121314151617181920212223242526272829303132333435363738# 新建一个容器container2[root@iz2zefaujekcdpmfw1qs4az ~]# docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container2 nginx89abb55858fb1e3dddc07c2066d05614349aaf78ba446a1ea12f1241b98e4896[root@iz2zefaujekcdpmfw1qs4az ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES89abb55858fb nginx &quot;/bin/bash&quot; 9 seconds ago Up 8 seconds 80/tcp container26869560e6ff5 nginx &quot;/bin/bash&quot; 2 hours ago Up 2 hours 80/tcp container1# 开始恢复数据[root@iz2zefaujekcdpmfw1qs4az ~]# pwd/root[root@iz2zefaujekcdpmfw1qs4az ~]# lltotal 22476-rw-r--r-- 1 root root 10240 Dec 16 18:52 backup1.tar-rw-r--r-- 1 root root 10240 Dec 16 19:05 backup2.tar-rw-r--r-- 1 root root 10240 Dec 16 19:09 backup.tardrwxr-xr-x 2 root root 4096 Dec 16 16:45 myvolume-rw-r--r-- 1 root root 22973527 Mar 26 2019 Python-3.7.3.tgz# 恢复数据[root@iz2zefaujekcdpmfw1qs4az ~]# docker run --rm --volumes-from container2 -v $(pwd):/backup nginx tar xvf /backup/backup.tar -C /usr/share/nginx/html1/usr/share/nginx/html1/1.textusr/share/nginx/html2/usr/share/nginx/html2/2.text# 查看确实已经恢复了[root@iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container2 bashroot@89abb55858fb:/# ls /usr/share/nginx/html html1 html2root@89abb55858fb:/# ls /usr/share/nginx/html11.textroot@89abb55858fb:/# ls /usr/share/nginx/html22.textroot@89abb55858fb:/# cat /usr/share/nginx/html1/1.text html1root@89abb55858fb:/# cat /usr/share/nginx/html2/2.text html2 注意： –volumes-from [containerName]：这个命令来指定需要备份的容器的名字；（数据卷容器的名字） -v $(pwd):/backup:权限：使用-v命令来指定希望备份文件存放的位置；本地存放目录：容器存放目录：读写权限；（默认权限是读写） tar cvf /backup/backup.tar [container data volume]：tar表示执行备份的操作是：压缩文件的命令； /backup/backup.tar是文件存放的地址， [container data volume]指定需要备份的目录； tar cvf 压缩；tar xvf解压缩； 新容器创建时挂载的数据卷路径最好和之前备份的数据卷路径一致 新容器创建时，如果挂载的数据卷只是备份卷的一部分，那么恢复的时候也只是恢复一部分数据。 比如新建容器挂载数据卷为 -v /usr/share/nginx/html1 ,那么使用 backup.tar 恢复时，只会恢复 /usr/share/nginx/html1 的数据， /usr/share/nginx/html2 的数据是不会恢复的 比如新容器创建时挂载的数据卷目录和备份的数据卷目录不一致，那么数据恢复不了，除非修改 - C 后面的路径，比如新建容器时指定数据卷目录为 /usr/share/nginx/html ，恢复时也是用 -C /usr/share/nginx/html，则是可以成功恢复的 删除数据卷123docker volume ls 列出所有的数据卷docker volume ls --filter dangling=true 过滤不在使用的数据卷docker volume rm [volume name] 删除一个数据卷，容器正在使用的数据卷不能删除，绑定挂载的数据卷无法删除 1docker volume rm my-volio 删除数据卷 my-volio 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令 1$ docker volume prune]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手动定义一个全局中间件]]></title>
    <url>%2F2060%2F07%2F18%2F%E6%89%8B%E5%8A%A8%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%85%A8%E5%B1%80%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[手动定义一个全局中间件 创建一个 middlerware.py（名字可以自己定义一个） 的文件 12345678910111213141516171819202122232425262728293031323334353637383940# 导入 MiddlewareMixin# 没有这个模块就下载一个from django.utils.deprecation import MiddlewareMixin# 导入from django.shortcuts import reversefrom django.http import JsonResponseimport timefrom .views import decrypt_oralceimport jsonLOGIN_REQUIRE_LIST = [reverse(var) for var in []] # 定义一个全局监控的路由列表，表里添加路由名# LoginRequired 函数名需要到 settings.py 里面进行配置,如下# 列表里面放的是需要登录判断的路由LOGIN_REQUIRE_LIST = [reverse(var) for var in []]class LoginRequired(MiddlewareMixin): def process_request(self,request): # 重定义请求来临需要做的事情 # 判断请求是否需要登录 # request.path() # 返回当前用户访问的路径 # print(request.META[&apos;HTTP_AUTHORIZATION&apos;]) if request.path in LOGIN_REQUIRE_LIST: token = request.META.get(&apos;HTTP_AUTHORIZATION&apos;) if not token or token == &apos;null&apos;: return JsonResponse(&#123; &apos;code&apos;:6207, &apos;message&apos;:&apos;未认证登录&apos; &#125;) else: # 逆向解析 token_data = json.loads(decrypt_oralce(token)) user_id = token_data.get(&apos;id&apos;) if token_data[&apos;expire&apos;] &lt; time.time(): # token 过期 return JsonResponse(&#123; &apos;code&apos;:7001, &apos;message&apos;:&apos;登陆时间已过期&apos; &#125;) data = request.POST.copy() data[&apos;id&apos;] = user_id request.POST = data 123456789101112# settings.py配置MIDDLEWARE = [ &apos;django.middleware.security.SecurityMiddleware&apos;, &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;, &apos;corsheaders.middleware.CorsMiddleware&apos;, &apos;django.middleware.common.CommonMiddleware&apos;, # &apos;django.middleware.csrf.CsrfViewMiddleware&apos;, &apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;, &apos;django.contrib.messages.middleware.MessageMiddleware&apos;, &apos;django.middleware.clickjacking.XFrameOptionsMiddleware&apos;, &apos;peng.middlerware.LoginRequired&apos;, # LoginRequired -&gt; 这个名字就是你在 middlerware.py里面的函数名 加一行这个注册一下] views.py 里面 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# 密码加密import hashlibfrom django.contrib.auth.hashers import make_password,check_password# 全局中间件import itsdangerousfrom shiyanpro.settings import SECRET_KEY# AES 加密算法容器from Crypto.Cipher import AESimport base64import jsonimport time# Create your views here.# 定义memcache连接对象 mem = memcache.Client([&apos;47.96.189.157&apos;])BLOCK_SIZEE = 16AES_KEY = &apos;wxpeng&apos; # key 值一定是16、32等EXPIRE = 3000def add_16(value): while len(value) % 16 != 0: value += &apos;\0&apos; return str.encode(value) def add_32(value): while len(value) % 32 != 0: value += &apos;\0&apos; return str.encode(value)# ECB 加密def encrypt_oracle(text): &apos;&apos;&apos; text的格式： text:&#123;&apos;name&apos;:&apos;zhangsan,&apos;id&apos;:3&#125; &apos;&apos;&apos; aes = AES.new(add_32(AES_KEY),AES.MODE_ECB) encrypt_value = aes.encrypt(add_16(text)) # text --&gt; 需要加密的东西 # ECB 模式加密，内容必须是‘进制流’ encrypt_text = str(base64.encodebytes(encrypt_value),encoding=&apos;utf-8&apos;) print(encrypt_text) return encrypt_text# ECB 解密def decrypt_oralce(text): &apos;&apos;&apos; text的格式： text:&#123;&apos;name&apos;:&apos;zhangsan,&apos;id&apos;:3&#125; &apos;&apos;&apos; aes = AES.new(add_32(AES_KEY),AES.MODE_ECB) base64_decrypted = base64.decodebytes(text.encode(encoding=&apos;utf-8&apos;)) decrypted_text = str(aes.decrypt(base64_decrypted),encoding=&apos;utf-8&apos;).replace(&apos;\0&apos;,&apos;&apos;) return decrypted_text# 生成token函数def jwt_itsdangerous_token(user): jwt_ = itsdangerous.TimedJSONWebSignatureSerializer(SECRET_KEY,300) data = &#123; &apos;id&apos;:user.id, &#125; token = jwt_.dumps(data).decode() return token# 定义密码加密函数def get_pass(str_): s = hashlib.sha1() s.update(str_.encode()) return s.hexdigest()# 在登录接口中，账号密码验证成功的情况下，写入如下代码，data = &#123; &apos;id&apos;:user.id, &apos;expire&apos;:time.time() + EXPIRE # token 过期时间 &#125; token = encrypt_oracle(json.dumps(data)) return JsonResponse(&#123; &apos;code&apos;:1, &apos;message&apos;:&apos;登录成功&apos;, &apos;token&apos;:token &#125;) 前端判断返回的 code 是否是 6027 或 7001 就OK]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（2）]]></title>
    <url>%2F2056%2F02%2F12%2FDocker%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[什么是DockerDocker 是一个开源的应用容器引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在本地编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。 简单的理解，Docker类似于集装箱，各式各样的货物，经过集装箱的标准化进行托管，而集装箱和集装箱之间没有影响。也就是说，Docker平台就是一个软件集装箱化平台，这就意味着我们自己可以构建应用程序，将其依赖关系一起打包到一个容器中，然后这容器就很容易运送到其他的机 器上进行运行，而且非常易于装载、复制、移除，非常适合软件弹性架构。 因此，就像船只、火车或卡车运输集装箱而不论其内部的货物一样，软件容器充当软件部署的标准单元，其中可以包含不同的代码和依赖项。 按照这种方式容器化软件，开发人员和 IT 专业人员只需进行极少修改或不修改，即可将其部署到不同的环境。 总而 言之，Docker 是一个开放平台，使开发人员和管理员可以在称为容器的松散隔离的环境中构建镜像、交付和运行分布式应用程序。以便在开发、QA 和生产环境之间进行高效的应用程序生命周期管理。 Docker能解决什么问题高效有序利用资源 机器资源有限； 单台机器得部署多个应用； 应用之间互相隔离； 应用之间不能发生资源抢占，每个应用只能使用事先注册申请的资源。 一次编译，到处运行 类似于java代码，应用及依赖的环境构建一次，可以到处运行 Docker架构Docker使用C/S架构，Client 通过接口与Server进程通信实现容器的构建，运行和发布。client和server可以运行在同一台集群，也可以通过跨主机实现远程通信。 Docker核心原理Namespaces命名空间（namespaces）是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。 在这种情况下，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这也是我们不想看到的，而 Docker 其实就通过 Linux 的 Namespaces 对不同的容器实现了隔离。 Linux 的命名空间机制提供了以下七种不同的命名空间，包括 CLONE_NEWCGROUP、CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER 和 CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。 Docker镜像原理 镜像是什么镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件, 它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 1.1 UnionFS(联合文件系统)UnionFS(联合文件系统): Union文件系统(UnionFS)是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承, 基于基础镜像(没有父镜像)， 可以制作各种具体的应用镜像。特性: 一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 1.2 Docker镜像加载原理docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。 bootfs(boot file system)主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的, 包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。 rootfs(root file system), 在bootfs之上。包含的就是典型Linux系统中的/dev, /proc, /bin, /etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。 平时我们安装虚拟机的CentOS都是好几个G，为什么docker这里才200M？linux mini 200G 2G 对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就行了。由此可见对于不同的linux发行版，bootfs基本是一致的，rootfs会有差别，因此不同的发行版可以共用bootfs。 1.3 分层的镜像以我们的pull为例，在下载的过程中我们可以看到docker的镜像好像是在一层一层的在下载 1.4 为什么docker镜像要采用这种分层结构呢最大的一个好吃就是共享资源比如：有多个镜像都从相同的base镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像,同时内存中也只需加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 镜像的特点Docker镜像都是只读的当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作为”容器层”，“容器层”之下的都叫”镜像层”。 Docker容器原理Docker 容器通过 Docker 镜像来创建，容器与镜像的关系类似于面向对象编程中的对象与类。 如图所示基本架构： Docker 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板。 Docker 容器(Container) 容器是独立运行的一个或一组应用。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建有一个新的 Django 项目]]></title>
    <url>%2F2050%2F10%2F10%2F%E5%88%9B%E5%BB%BAdjango%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[创建一个新的 Django 项目 - Django-admin startproject 项目名称 - Cd 到 创建的 django 项目中 - 创建子项目： - Python manage.py startapp 子项目名 - Python manage.py createsuperuser 创建超级用户管理员 - Python manage.py runserver 启动项目]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-Views-视图层]]></title>
    <url>%2F2032%2F12%2F09%2FDjango-Views-%E8%A7%86%E5%9B%BE%E5%B1%82%2F</url>
    <content type="text"><![CDATA[视图层 视图函数一般用来接收一个Web请求HttpRequest，之后返回一个Web响应HttpResponse HttpRequest 一个视图函数用来响应用户的Request请求，每个视图函数默认的第一个位置参数request用来接收用户发起请求的HttpRequest信息。 视图函数的返回值，为一个HttpResponse值，包括我们要返回给用户的HTML页面或者字符串等等，以及对应的头部字段信息 123from django.http import HttpResponsedef index(request): return HttpResponse('Hello world') 常见请求方式 POST和GET是HTTP协议定义的与服务器交互的方法。 GET一般用于获取/查询资源信息，而POST一般用于更新资源信息。另外，还有PUT和DELETE方法 get 常用来从指定地址请求数据； 如果需要在请求时提交某些数据，则以路由形式传递参数，查询Query字符串如下格式所示： 1https://www.baidu.com/?key=abc&amp;pos=hebei get请求可被浏览器缓存，保存在历史记录中 get不应在使用敏感数据时使用，明文包路在请求地址中 get有长度限制 post 向指定的资源提交要被处理的数据 使用POST，提交的数据保存在HTTP协议中的消息主体部分 post请求不会被浏览器缓存 post提交数据长度无限制 post比get更加安全 request 如果说urls.py是Django中前端页面和后台程序桥梁，那么request就是桥上负责运输的小汽车，可以说后端接收到的来至前端的信息几乎全部来自于requests中 request.method 获取当前用户请求方式， 请求方式字符串为纯大写：&#39;GET&#39;、&#39;POST&#39; 如用户以get方式发起请求，对应代码中获取到的结果以及在判断时像是这样 123def index(request): if request.method == 'GET': … request.GET 当用户通过get方式请求站点，并在路由中提供了查询参数，可以通过该属性获取到对应提交的值 123456789def index(request): print(request.GET) # &lt;QueryDict: &#123;'name': ['jack'], 'id': ['1']&#125;&gt; print(type(request.GET)) # &lt;class 'django.http.request.QueryDict'&gt; name_ = request.GET.get('name') id_ = request.GET.get('id') content = '%s:%s' % (name_,id_) return HttpResponse(content) request.GET是一个类似字典的数据类型：QueryDict 其中也支持类似对字典的get或直接dict.[key]键值访问方式，当然使用get方式进行对应key获取会更好，因为get在访问不到时不会报错 如果定义了如上所示的视图函数，那么在访问连接时，我们可以通过路由传参： 1http://127.0.0.1:8000/?name=jack&amp;id=1 这里对应页面会显示的结果： 1jack:1 注意：使用GET方法在连接中进行参数提交，后台接收到的数据类型均是字符串 request.POST 获取用户以post形式提交的数据并保存在后台，为类字典数据，这里和request.GET是一个东西； 在网页中，一般我们通过html的表单进行数据的提交，POST方式可以提交空数据 因为涉及到了表单页面，所以我们先来弄一个HTML页面 12345678910&lt;body&gt; &lt;div&gt;这是一个关于POST的测试&lt;/div&gt; &lt;form action="/" method="POST"&gt; &#123;% csrf_token %&#125; 账号:&lt;input type="text" name="account"&gt; &lt;br&gt; 密码:&lt;input type="password" name="passwd"&gt; &lt;input type="submit" value="提交"&gt; &lt;/form&gt; &lt;/body&gt; 在模板页面中，一旦涉及到了表单提交，那么一定要注意在表单区域添加csrf_token标签进行防跨站伪造令牌的加载，否则表单数据的将被认为是无效的。 在接下来的视图函数中会使用到input标签中的name属性； name值属性维护了post的数据传入到后台时的标示，会与表单的数据组合成类字典格式 如name属性为account的输入框中输入了test，那么后台数据接收到的值类似：{&#39;account&#39;:&#39;test&#39;} 写一个视图函数用来捕获当前表单使用POST形式提交的数据： 123456789def index(request): if request.method="POST": print(request.POST) print(type(request.POST)) account = request.POST.get("account") passwd = request.POST.get("passwd") content = "%s:%s" % (account,passwd) return HttpResponse(content) return render(request,"index.html") #在使用get形式请求时，返回表单页面 如果在表单页面中账号填写为test，密码为123456；在视图函数中捕捉到的结果为： 1&lt;QueryDict: &#123;&apos;csrfmiddlewaretoken&apos;: [&apos;EmyGwsVcrXI2LDkYLS9qflkUH4N7bM1nfTQxr3fsOsZlI4vJFwci7TargtYRAGl2&apos;], &apos;account&apos;: [&apos;test&apos;], &apos;passwd&apos;: [&apos;123456&apos;]&#125;&gt; 表单夺表提交 在request.POST中需要注意，某些情况下，使用POST提交数据的表单数据可能是多个值，类似复选框CheckBox，直接使用request.POST.get()进行获取是有一些问题的，比如修改模板页`面如下所示 1234567&lt;form action="/" method="POST"&gt; &#123;% csrf_token %&#125; &lt;input type="checkbox" name="taste" value="eat"&gt;吃 &lt;input type="checkbox" name="taste" value="sleep"&gt;睡 &lt;input type="checkbox" name="taste" value="play"&gt;耍 &lt;input type="submit" value="提交"&gt;&lt;/form&gt; 这是一个name值为taste的兴趣爱好采集的多选框，value值将会作为选中时，提交到后台的值，比如现在我们全选这些表单数据，那么后台接收到的值是这样的 1&lt;QueryDict: &#123;&apos;csrfmiddlewaretoken&apos;: [&apos;nuaLzxc2E0artYKUZiefMPv5iHTX5gLFY1sCu8wi1vrKqpVFTWh7EnlCR64Hua5k&apos;], &apos;taste&apos;: [&apos;eat&apos;, &apos;sleep&apos;, &apos;play&apos;]&#125;&gt; 但是问题接踵而至，我们发现使用get函数获取不到对应全选的整个结果，而是只拿到了选中的最后一项 request.POST.get(key, default=None) 返回对应key值的数据中的最后一个数据单独返回；key值不存在，取default 要想真正拿出所有的结果，应该使用getlist函数 request.POST.getlist(key, default=None) 将对应key值的所有数据以一个列表形式返回；key值不存在，取default request.META request.MATE获取的是一个标准的python字典。它包含了所有的HTTP请求信息 比如用户IP地址和用户Agent（通常是浏览器的名称和版本号）。 注意，Header信息的完整列表取决于用户所发送的Header信息和服务器端设置的Header信息 CONTENT_LENGTH：请求的正文的长度，字符串类型 CONTENT_TYPE：请求的正文的MIME 类型 HTTP_ACCEPT：响应可接收的Content-Type HTTP_ACCEPT_ENCODING：响应可接收的编码 HTTP_ACCEPT_LANGUAGE：响应可接收的语言 HTTP_HOST：客服端发送的HTTP Host头部 HTTP_REFERER：请求前的连接地址 HTTP_USER_AGENT：客户端的user-agent字符串 QUERY_STRING：单个字符串形式的查询字符串（未解析过的形式） REMOTE_ADDR：客户端的IP 地址 REMOTE_HOST：客户端的主机名 REMOTE_USER：服务器认证后的用户 REQUEST_METHOD：一个字符串，例如GET 或POST SERVER_NAME：服务器的主机名 SE0RVER_PORT：服务器的端口，字符串类型 request.FILES 接收用户上传文件及相关信息。同样类似于request.POST，提取到的数据为一个类字典的数据类型，包含所有文件上传的信息 f = request.FILES.get(&#39;upload_file&#39;) file_data = f.read()：读取整个上传文件的内容，适合小文件上传 yiled = f.chunks()：返回一个类似生成器（&lt;class &#39;generator&#39;&gt;）的数据，每一次读取按块返回文件，可以通过for迭代访问其中数据；适合上传大文件到服务器。 f.multiple_chunks()：返回文件大小，当文件大小大于2.5M时，返回True，反之返回False，可以通过该函数来选择是否使用chunks方法或read直接存储。 如果想要修改这个文件判定的默认值，可以通过：FILE_UPLOAD_MAX_MEMORY_SIZE在settings文件下进行设置 f.content_type：上传文件时头部中的Content-Type字段值，参考MIME类型 f.name：上传文件名字 f.charset：上传文件编码 f.size： 上传文件大小，字节为单位：byte 创建好静态资源目录，并在下面创建一个img文件夹，保存我们即将上传的图片； 完成上传文件的HTML表单页面 1234567&lt;form action="/" method="POST" enctype="multipart/form-data"&gt; &#123;% csrf_token %&#125; &lt;input type="file" name="upload_file" /&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; &lt;img src="&#123;% static 'img/1.jpg' %&#125;" alt="这是一张图片"&gt;&lt;!-- 这里使用的是即将要上传的文件名字，只做文件是否上传成功的简单测试 --&gt; 注意：上传文件的页面表单，一定要记得设置属性enctype=&quot;multipart/form-data&quot; 视图函数如下编写，接收上传图片，并保存在静态目录下刚才创建好的img目录中 12345678910111213def index(request): if request.method == "POST": f = request.FILES.get("upload_files") path = os.path.join(settings.STATICFILES_DIRS[0],'img/'+f.name) # 上传文件本地保存路径 with open(path,'wb') as fp: if f.multiple_chunks: #判断到上传文件为大于2.5MB的大文件 for buf in f.chunks(): #迭代写入文件 fp.write(buf) else: fp.write(f.read()) return HttpResponse("Success!") return render(request, 'index.html') 测试上传一个名为1.jpg的图片，如果成功上传，那么后台static目录下会出现该图片，并且模板页面也可以展示对应图片效果 HTTPResponse 一个视图的返回值经常是为了向用户返回一个HttpResponse响应， 有如下常用的可以返回HttpResponse的函数 response HttpResponse(content=b&#39;&#39;) 返回一个字符串内容 from django.http import HttpResponse render(request,template_name,context=None,content_type=None,status=None) 返回一个可渲染HTML页面，状态码为200 from django.shortcuts import render 12&gt; request`：固定参数，响应的`request`请求，来自于参数部分接收的`HttpRequest&gt; template_name：返回的模板页面路径 context：模板页面渲染所需的数据，默认为字典格式 content_type：生成之后的结果使用的MIME类型 status：响应的状态码，默认为200 redirect(to, permanent=False) 一个重定向，浏览器通过该状态码自动跳转到一个新的路由地址，默认返回响应状态码302 from django.shortcuts import redirect to：可以是一个django项目中视图函数的路由映射，也可以是一个reverse的反向路由解析 permanent：如果设置为True，将返回301状态码，代表永久重定向 12302：临时重定向，旧地址资源临时不能用了，搜索引擎只会暂时抓取新地址的内容而保存旧的地址。301：永久重定向，旧地址资源已经不复存在，搜索引擎不光会抓取新地址的内容，还会替换旧地址为新地址 视图错误处理 为了方便我们开发，django提供了一个异常叫做Http404异常，我们可以在视图函数的代码中按照需求进行抛出，抛出之后django项目会自动捕获该异常，并会展示默认的404页面 1234from django.http import Http404def index(request): if request.GET.get("id") == "1": raise Http404 在settings中的debug配置项为false时，访问http://127.0.0.1:8000/?id=1，可以看到django为我们提供的错误页面； 除了django默认提供的，我们还可以可以在模板目录下定义全局404.html进行错误页面的定制 123&lt;h1&gt; 抱歉，找不到你要的东西&lt;/h1&gt; 自定义错误处理视图 除去404错误的自定义，django还提供了覆盖默认错误行为处理的办法； 有些时候，django自动的错误处理可能不能满足我们的需求，那么我们可以重新定义一些新的视图函数， 来覆盖掉django所提供的错误处理视图函数，最后在urls.py路由配置文件下通过定义全局变量来重新设置默认的错误处理视图函数 1234handler404：覆盖page_not_found()视图。handler500：覆盖server_error()视图。handler403：覆盖permission_denied()视图。 handler400：覆盖bad_request()视图。 12345678910from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path('admin/', admin.site.urls), path('', include("viewapp.urls")),]handler404 = "viewapp.views.error_404"# APP.模块.视图函数handler500 = "viewapp.views.error_500" 相关定义好的错误处理视图函数 12345678def error_404(request): return HttpResponse("这是404错误")def error_403(request): return HttpResponse("这是403错误")def error_500(request): return HttpResponse("这是500错误")]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile]]></title>
    <url>%2F2031%2F06%2F30%2FDockerFile%2F</url>
    <content type="text"><![CDATA[DockerFile1、DockerFile简介 DockerFile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本 构建步骤（1）编写DockerFile文件（2）执行docker build（3）docker run 2、DockerFile构建过程解析 编写规范 每条保留字指令都必须为大写字母且必须跟参数：例如 FROM nginx 指令从上到下，顺序执行 #表示注释 每条指令都会创建一个新的镜像层，并对镜像进行提交 编写步骤 docker从基础镜像运行一个容器 执行一条指令并对容器做出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行dockerfile中的下一条指令直到所有指令都指向完成 dockerfile、镜像、容器之间的关系可以类比为生产环境中的，原材料，交付品，运行的产品 3、常用关键字（语法） 关键字 释意 FROM 基础镜像，当前新镜像的父镜像 MAINTAINER 镜像维护者的姓名和邮箱 RUN 容器构建需要运行的命令，用&amp;&amp;连接脚本可以减少镜像的层数 EXPOSE 当前容器对外暴露出的端口 WORKDIR 指定在创建容器后，终端默认登录进来的目录 ENV 构建过程中的环境变量 ADD 将宿主机文件拷贝进镜像内并解压缩 COPY 拷贝文件到镜像中 VOLUME 容器数据卷，数据保存和持久化 CMD 指定容器需要运行的命令，多个命令出现时只执行最后一个CMD命令 ENTRYPOINT 指定容器需要运行的命令 ONBUILD 当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像内触发 4、案例解析 以官方centos7镜像为例 12345678910FROM scratchADD centos-7-x86_64-docker.tar.xz /LABEL org.label-schema.schema-version="1.0" \ org.label-schema.name="CentOS Base Image" \ org.label-schema.vendor="CentOS" \ org.label-schema.license="GPLv2" \ org.label-schema.build-date="20191001"CMD ["/bin/bash"] 官方仓库里的centos为精简压缩版，我们可centos添加额外功能，例如：netstat查看所有端口。 尝试编写Dockerfile来实现这一功能 任意目录下新建DockerFile空文件 12touch DockerFilevi DockerFile 写入可执行文本 123456FROM centosENV mypath /homeWORKDIR $mypathRUN yum -y install net-tools &amp;&amp; touch 1.txtEXPOSE 80CMD /bin/bash docker build执行DockerFile 1docker build -t centos:1.1 -f DockerFile . -t 指定镜像的名字。[name:版本 =&gt; centos:1.1] -f 显示指定构建镜像的 Dockerfile 文件（Dockerfile 可不在当前路径下）。如果不使用 -f，则默认将上下文路径下的名为 Dockerfile 的文件认为是构建镜像的 “Dockerfile” . 这个表示打包的上下文（其实就是Dockerfile所在目录）是在当前目录。指定构建镜像的上下文的路径，构建镜像的过程中，可以且只可以引用上下文中的任何文件 docker build 官方语法 “docker build [OPTIONS] PATH | URL | -”。 更多详情请参考：https://docs.docker.com/engine/reference/commandline/build/ 查看是否安装了netstat 12docker run -t -i -d centos /bin/bashdocker exec -it 容器id bash]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-Urls-路由层]]></title>
    <url>%2F2031%2F06%2F11%2FDjango-Urls-%E8%B7%AF%E7%94%B1%E5%B1%82%2F</url>
    <content type="text"><![CDATA[路由层 路由是Web服务的入口，就好像办事大厅有各个服务窗口一样 Django奉行DRY主义，提倡使用简洁、优雅的URL： 可以不用.html、.php或.cgi之类后缀 尽量不要单独使用无序随机数字这样无意义的东西 让你随心所欲设计你的URL，不受框架束缚 路由urlpatterns urlpatterns是路由文件中的一个全局变量，用来存放路由及视图函数的映射关系 用户发起的请求URL都会首先进入主控制目录下的这个urls.py文件中进行查找匹配 首先找到urls.py下的urlpatterns全局变量，这是一个路由规则实例的列表数据。 按照先后定义顺序，进行路由匹配。 找到第一个匹配项时停止匹配，执行匹配到的视图函数。 遍历完全，未发现匹配，django进行异常处理 其中urlpatterns中的每一个路由映射规则可以由path或re_path进行构造 注意：Django的路由不考虑HTTP请求方式，仅根据URL进行路由；即，只要URL相同，无论POST、GET等哪种请求方式都指向同一个操作函数 path path(regex, view, kwargs=None, name=None) regex：一个匹配对应url地址的规则字符串。 view：路由对应的视图函数，并且会自动封装HttpRequest作为第一个参数给这个视图函 kwargs：视图函数的关键字参数。 name：该路由的全局命名，可以让我们方便的在django项目中任意部分显示的使用，相当于为url取变量名，接下来全局使用该命名值即可；当对应url路由改变之后，结合路由反向解析使用的地方不需要更改路由 此外，django还提供了一个兼容老版本url路由配置函数的re_path函数；re_path：第一个参数部分为一个正则匹配规则，其他与path同 静态路由 静态路由用来映射对应视图函数，以下是一个简单的例子 1234from django.http import HttpResponsedef index(request): return HttpResponse('Hello Worlds!') 123456from django.urls import path,re_pathfrom urlapp import viewsurlpatterns = [ path('',views.index), re_path(r"^",views.index),] 路由传参 有的时候，我们的路由设置不能一直维持一个一成不变的状态； 比如遇到一些内容翻页的场景，那么我们的连接可能是：xx.com/airticle_list/1/、xx.com/airticle_list/2/ 那么这样的路由其实对应的都应该是一个视图函数，用以展示页面内容，那么如何设计这样的路由，就要涉及到动态路由及路由传参 123def index(request,x,y): content = "x:%s\ny:%s" % (x,y) return HttpResponse(content) 定义如上函数，将会接收连接中的后两部份path值作为参数，分别依次给到x和y 1234567891011from django.urls import path,re_pathfrom urlapp import viewsurlpatterns = [ path('&lt;int:x&gt;/&lt;str:y&gt;/',views.index), #指明类型 path("&lt;x&gt;/&lt;y&gt;/",views.index) #不指明类型 re_path(r"^(?P&lt;x&gt;\d+)/(?P&lt;y&gt;[a-zA-Z]+)/$"), # (?P&lt;name&gt;pattern) 正则分组 re_path(r"^(\d+)/([a-zA-Z]+)/$"),] 路由通过尖括号进行分组匹配，使用int以及str内置转换器将连接对应部分的值进行转换；并将匹配到的结果传递到视图函数对应的参数位置上； 访问：http://127.0.0.1:8000/1/abc/ 其中1将作为x的参数值，abc将作为y的参数 但如果访问连接是：http://127.0.0.1:8000/abc/abc/，这会匹配到第二个路由，第二个路由没有对传递参数的类型进行限定 内置Path转换器： 12345str：匹配除了路径分隔符（`/`）之外的非空字符串，这是默认的形式int：匹配正整数，包含0slug：匹配字母、数字以及横杠、下划线组成的字符串uuid：匹配格式化的uuid，如 075194d3-6885-417e-a8a8-6c931e272f00path：匹配任何非空字符串，包含了路径分隔符 自定义转换器 除了以上django所提供的path转换器，如果还觉得无法实现我们想要的功能，我们可以通过编写一个类进行自定义path转换器 定义转换器类，类名随意 定义类中必须属性 regex：一个字符串形式的正则表达式，也是对应的路由规则 to_python(self, value)：用于将匹配到的路由字符串转换为Python中的数据类型，并传递给视图函数，如果转换失败，必须抛出ValueError，路由映射视图函数时使用 to_url(self, value)：将Python数据类型转换为一段url的方法，to_python方法的反向操作，反向解析时使用 通过django.urls模块中的register_converter函数进行注册 12函数第一个参数为转换器类函数第二个参数为转换器别名 以下定义一个路由参数只能是三位字符的路由规则 123456789101112131415#先将转换器类定义class ThreeChar: regex = "[a-zA-Z]&#123;3&#125;" def to_python(self,value): print("to_python") return str(value) def to_url(self,value): # 当通过反向路由解析时，将会调用该函数 print('to_url') return str(value)[:3] #此处切片操作是为了当反向路由解析传参字符串长于3时，可以将其截断，符合转换器正则规则#注册转换器from django.urls import register_converterregister_converter(ThreeChar,'tc') 1234urlpatterns = [ path('&lt;tc:x&gt;/&lt;tc:y&gt;/',views.index)]#127.0.0.1:8000/aaa/bbb/ 接下里，通过路由进行访问该视图映射时，一定是三个字符所组成的路由才可以，否则是访问不到的 1234567#urls.pyapp_name = "app"path('&lt;tc:x&gt;/&lt;tc:y&gt;/',views.index, name="threechr")#views.pyreturn redirect(reverse("app:threechr",args=('aaaa','bbbb')))#此时会调用three路由规则中的tc转换器中的to_url反向合成路由，并切片只取参数前三位 路由分发 我们的路由编写都是在项目主要目录下的urls.py文件中，但是如果app有很多的话，这么多路由都写到一起，明显是一件很不方便管理的事情 其实在之前的练习中，我们使用的方式均是路由分发，每个子app都拥有自己独立的urls.py路由映射文件，而主控路由文件里只需要使用include函数导入子app下路由文件即可，这就是路由分发 1234567from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path('admin/', admin.site.urls), path('',include("urlapp.urls")) # 使用include 实现路由分发，找到子app下的路由文件] 路由分发为我们带来的好处有很多，可以让我们在多个app的项目中更加方便有效的管理每一个路由 并且也可以让我们的用户在访问时看到浏览器中的URL地址更加赏心悦目 路由反向解析 到了这里，思考一下，之前我们已经设置过了很多路由； 但是现在会出现一个问题，比如我们把其中某个路由规则进行了修改，把aaa换成了aba，那么现在我们需要回到每一个使用到这个路由的地方进行同步修改，这显然非常麻烦的，如果修改的路由更多，这甚至是一个灾难 django也为我们提供了一个解决办法，通过为路由映射使用name参数，来为每一个路由映射设置一个独立唯一的变量名 12345path('left/&lt;str:x&gt;/',views.left, name="left"),path('right/&lt;int:x&gt;/',views.right, name="right"),# 通过正则命名分组方式re_path(r'^left/([a-zA-Z]+)/$',views.left,name="left"),re_path(r'^right/(?P&lt;x&gt;\d+)/$',views.right, name="right") 两个视图函数对应如下： 12345678910111213def left(request,x): # x: str content = &#123; 'message':x, &#125; return render(request, "left.html", content)def right(request,x): # x: int content = &#123; 'message':x, &#125; return render(request, "right.html",content) 两个HTML页面 1234567&lt;p&gt;我是左页面&lt;/p&gt;&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;a href="&#123;% url 'right' 123 %&#125;"&gt;右页面&lt;/a&gt;&lt;!-- ------另一个页面------ --&gt;&lt;p&gt;我是右页面&lt;/p&gt;&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;a href="&#123;% url 'left' 'abc' %&#125;"&gt;右页面&lt;/a&gt; 在模板页面中，对于已命名路由可以通过 &#123;% url “name” “arg” %&#125;模板标签进行反向解析 参数以空格隔开，在标签后传入 视图函数反向解析 12def index(request): return redirect(reverse("left",args=('aaa',) )) 在视图函数中需要使用到路由命名时，进行反向解析需要我们通过django.shortcuts模块下的reverse函数 reverse(viewname,args=None,kwargs=None) 1234参数介绍viewname：视图函数、命名路由映射、或视图函数路径的字符串args：元组形式路由传参。kwargs：字典形式路由传参 命名空间 如果想在多个app下使用相同的name路由命名，那么我们可以通过路由分发过程中的include函数来指定不同app所属的命名空间 123456789from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path('admin/', admin.site.urls), path('app1/',include(("app1.urls",'app1'))), #直接传递一个元祖，元祖第一个值为分发路由地址，第二个值为命名空间 path('app2/',include(("app2.urls",'app2')))] 当为每个app的路由分发映射设置了命名空间，接下来在模板页面以及视图函数对路由的反向解析将是如下所示的样子，路由解析前加冒号指明命名空间 12def index(request): return redirect(reverse("app1:left")) 1&lt;a href="&#123;% url 'app2:left' %&#125;"&gt;app2:left&lt;/a&gt; 应用命名空间：app_name 使用app_name指明命名空间，在子app的urls.py文件下配置全局变量app_name，这个值是唯一的 在这个路由文件中定义的其他映射关系，将具有命名空间app1 1234app_name = "app1" # 这个值应该是唯一的urlpatterns = [ ...] 实例命名空间：namespace 当有多个子app同时引入同一个子路由映射文件，比如这样 12345678from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path('admin/', admin.site.urls), path('app1/',include("app1.urls")), path('app2/',include("app1.urls"))] 这就会出现一个问题，不同的路由访问在做路由反向解析时，会造成混淆， 此时需要给每一个路由分发的规则设置namespace属性，为实例进行命名空间 12345678from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path('admin/', admin.site.urls), path('app1/',include("app1.urls",namespace="app1")), path('app2/',include("app1.urls",namespace="app2"))] 这样做的好处，可以在不同路由导向同一app下时，为他们的不同命名空间； 虽然看起来到最后执行的视图函数功能是一样的，但可以分清楚究竟是哪个路由引起视图函数在工作 接下来视图及模板页面中使用namespace的值 12345678910111213&lt;p&gt;我是左页面&lt;/p&gt;&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;a href="&#123;% url 'app1:right' 123 %&#125;"&gt;app1的右页面&lt;/a&gt;&lt;p&gt;我是右页面&lt;/p&gt;&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;a href="&#123;% url 'app1:left' 'abc' %&#125;"&gt;app1的左页面&lt;/a&gt;&lt;!-- ----------------------------------------- --&gt;&lt;p&gt;我是左页面&lt;/p&gt;&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;a href="&#123;% url 'app2:right' 123 %&#125;"&gt;app2的右页面&lt;/a&gt;&lt;p&gt;我是右页面&lt;/p&gt;&lt;p&gt;路由参数: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;a href="&#123;% url 'app2:left' 'abc' %&#125;"&gt;app2的左页面&lt;/a&gt;]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化、云计算概念]]></title>
    <url>%2F2030%2F12%2F30%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E3%80%81%E4%BA%91%E8%AE%A1%E7%AE%97%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[虚拟化、云计算概念：美国环境保护署（EPA）报告的一组有趣的统计数据。 EPA研究服务器和数据中心的能源效率时发现，实际上服务器只有5%的时间在工作。在其他时间，服务器都处于 “休眠” 状态。就是说只有5%的消耗属于服务性能的消耗，其他都属于自己的无用消耗。 ####什么是虚拟化： 虚拟化是指通过虚拟化技术奖一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间运行而互不影响，从而显著提高计算机的工作效率。 虚拟化使用软件的方法重新定义划分IT资源，可以实现IT资源的鼎泰分配、灵活调度、跨域共享，提高IT资源利用率，使IT资源能够真正成为社会基础设施，服务于各行各业中灵活多变的应用需求。 虚拟化技术的应用价值：虚拟化前 资源浪费 系统资源的利用率不高， 有的服务器长期空闲， 有的服务器超负荷为运转 管理难度大（设备多） 服务器、路由、防火墙等设备数量众多，管理难度大。 重复劳动 经常性的重装、重做系统，调试网络设备等 参数配置繁琐 调整单台服务器CPU内存、硬盘大小等流程繁琐 安全性差 每台主机一个独立的操作系统，当安装一个完整的LAMP环境时，apache和mysql的资源是共享的，会造成安全性的问题。当Apache爆发漏洞时，可能会导致mysql的数据泄露。 虚拟化后： 高利用率 将分散、独立的服务器资源整合成虚拟资源池后，资源利用率大大提高 自由配置 在资源池范围内，可以自行添加虚拟机，更改虚拟机内存、存储空间等参数 统一管理 通过虚拟化平台能够清晰的查看服务器运行情况、硬件健康状况等信息 更稳定 虚拟化本身就是一个安全技术，通过虚拟化技术手段，提高系统稳定性，保证数据安全 虚拟化过程：给每个服务器上装一个(VMware)虚拟卡，通过虚拟化软件把孤立的、分散的服务器资源连接在一起，形成一个虚拟化资源池，将资源集中起来，然后相对的虚拟出多台服务器，通过虚拟化软件将虚拟化任务自动的分配在多台服务器上 虚拟化技术的分类： 全虚拟化技术 完全虚拟化技术又叫硬件辅助虚拟化技术，最初所使用的的虚拟化技术就是全虚拟化技术，它在虚拟机（VM）和硬件之间加了一个软件层——Hyperyisor，或者叫做虚拟机监控器（VMM） hypervisor（虚拟机软件层/虚拟机监控机） 半虚拟化技术/准虚拟化技术（使用比较少） 半虚拟化技术，也叫准虚拟化技术。它就是在全虚拟化的基础上，把客户操作系统进行了修改，增加了一个专门的API，这个API可以将客户操作系统发出的指令进行最优化，即不需要Hypervisor耗费一定的资源进行翻译操作，因此Hypervisor的工作负担变得非常的小，因此整体的性能也有很大的提高。 openstack云计算概念：云计算就是通过网络访问服务的一种模式。 “云计算”可以理解为：通过互联网可以使用足够强大的计算机为用户提供的服务，这种服务的使用像可以统一的单位来描述。 虚拟化和云计算比较虚拟化： 是一种技术存在，从1个物理硬件系统创建多个模拟环境 云计算： 是一种服务模式存在，汇聚并自动化分配虚拟资源以供按需使用]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识]]></title>
    <url>%2F2030%2F11%2F11%2FDjango%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[开始玩耍Django Django是一个开放源代码的Web应用框架，由Python写成。采用了MVT的框架模式；最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的，即是CMS（内容管理系统）软件 框架是以比利时的吉普赛爵士吉他手Django Reinhardt来命名的 django安装 pip install django==2.0.4(版本号) pip install django默认安装最新版本 创建项目 django-admin startproject myproject 开启开发服务器 cd myproject：进入项目目录 python manage.py runserver：开启服务 python manage.py runserver 7000：改变服务监听端口 python manage.py runserver 0:8000：改变服务监听IP:端口 项目文件夹123456manage.py：用来管理当前项目的一个命令行工具myproject/： 项目主文件夹myproject/__init__.py：空文件，用来指明当前的myproject为一个可导入的模块包myproject/settings.py：项目主要配置文件myproject/urls.py：项目主要路由配置文件myproject/wsgi.py：项目部署WSGI并发服务器时所需要的配置文件 Settings.py 该文件是整个项目的主控文件，其中相关配置选项如下 https://docs.djangoproject.com/zh-hans/2.1/ref/settings/ 123456789101112131415161718192021222324- BASE_DIR: 当前项目工作目录，用来在每一次开启项目时动态找到相关资源路径- SECRET_KEY: 加密的hash值以及保护某些签名数据的关键密钥- DEBUG: 调试模式- ALLOWED_HOSTS: 有哪些主机或域名可以访问当前django站点，如设置为*代表全部可访问。- INSTALL_APPS: django项目中所有使用的应用名称，自创建子应用也要加到这里，不然ORM数据库无法被识别到！- MIDDLEWARE: django中间件，用来在request或reponse过程中添加功能，比如确保安全性，传输保存Session等 - SecurityMiddleware: xss脚本过滤，一些安全设置 - SessionMiddleware: session支持中间件，在每次用户访问django项目时，添加session对每一个浏览器 - CommonMiddleware: 通用组件，比如为路由添加末尾斜杠 - CsrfViewMiddleware: 防跨站请求伪造令牌，为客户端添加csrf_token密钥，在表单提交时需提交该值 - AuthenticationMiddleware: admin用户组件，每个request对象都会被添加admin下的user属性 - MessageMiddleware: 消息中间件 展示一些后台消息给前端 - XFrameOptionsMiddleware: 防止欺骗点击攻击出现；自身页面被嵌入到他人页面中，点击欺骗- ROOT_URLCONF: 主路由配置文件，字符串填写url.py文件路径- TEMPLATES: 模板文件配置项- WSGI_APPLICATION: WSGI服务器配置项，找到当前django下的wsgi引入APP文件- DATABASES: 数据库配置项，默认使用SQLite3，一个本地文件数据库- AUTH_PASSWORD_VALIDATORS: 检查用户密码强度的验证程序列表，不过是针对admin界面下的用户，而非自定义- LANGUAGE_CODE: django所使用语言文件- TIME_ZONE: django所使用时区- USE_I18N: 国际化支持 18表示Internationalization这个单词首字母I和结尾字母N之间的字母有18个- USE_L10N: 是localization的缩写形式，意即在l和n之间有10个字母- USE_TZ:开启了Time Zone功能，则所有的存储和内部处理，包括print显示的时间将是是UTC时间格式- STATIC_URL: URL访问静态资源时的路径 来搞个Hello Worlddjango创建子应用 项目和应用有啥区别？ 应用是一个专门做某件事的网络应用程序：比如博客系统，或者公共记录的数据库，或者简单的投票程序 项目则是一个网站使用的配置和应用的集合。项目可以包含很多个app应用，应用可以被很多个项目使用 python manage.py startapp myapp 创建子应用 app目录1234- admin.py: app在admin注册展示时需要的文件- views.py: app的功能视图函数文件- models.py: app需要使用数据库时的文件- urls.py: 当使用include路由分发时，每个app应该有他自己的子路由文件，这个是默认没有创建好的 视图函数 打开app下的views.py文件 Web访问起始就是通过一个URL连接地址访问到服务器上的一个函数 在views.py中我们通过编写函数的形式，接收用户请求的request并返回一个response 12345# 每一个视图函数都需要有一个必须参数 request,用来接收用户访问时的请求内容from django.http import HttpResponsedef index(request): return HttpResponse("&lt;h1&gt;Hello world&lt;/h1&gt;") HttpResponse函数用来向用户返回一个字符串 路由配置 创建好了一个可以在请求时返回H1标签的视图函数，但是现在通过浏览器还是访问不到 需要我们为这个app下的函数进行路由配置 第一种简单的路由配置，直接在主控路由文件下，找到这个视图函数 12345678910#myproject/urls.pyfrom django.contrib import adminfrom django.urls import pathfrom myapp import viewsurlpatterns = [ path('admin/', admin.site.urls), #admin控制界面路由 path('',views.index) #path函数第一个参数为访问地址，空字符串代表：当用户直接访问首页时 #第二个参数代表访问该地址时对应的视图函数，我们引入了app下的views中的index视图函数] 接下来访问127.0.0.1:8000，那么你会看到一个非常大的Hello world 以上将视图函数的查找直接写到主控路由并不是最好的办法 我们的项目通常会有非常多的路由配置项，如果都堆到这个文件中肯定是非常乱的，难以维护 我们可以在对应app下创建一个子路由控制文件，并在其中设置视图的路由配置 123456#myapp/urls.pyfrom django.urls import pathfrom . import viewsurlpatterns = [ path("",views.index)] 现在虽然配置了app下的路由文件，但是访问时，是看不到对应视图的结果 这是因为默认的url查找动作将会从主控路由文件开始，我们还需要在主控路由文件下进行路由分发设置 让主控路由可以找到子app下的路由映射文件 12345678910#myproject/urls.pyfrom django.contrib import adminfrom django.urls import path,includefrom myapp import viewsurlpatterns = [ path('admin/', admin.site.urls), #path('',views.index) path('',include("myapp.urls")), # 函数 include() 允许引用其它 URLconfs] 接下来再次尝试，在浏览器中访问主机域名；如果可以看到的话，恭喜你，效果已经很棒了！ 路由查找流程 查找主控路由文件下的urlpatterns全局变量，这是一个序列数据类型，其中每一个元素都是对应的一个路由匹配规则 如果在规则中查找到符合匹配规则的，则执行其中的对应执行函数 如果对应的不是一个执行函数，而是一个include路由包含，那么截断与此项匹配的URL的部分，并将剩余的路由字符串发送到include所包含的子路由文件中以供进一步处理 如果没有匹配到的任何结果，django默认抛出Page not found (404) 注意：Django的路由不考虑HTTP请求方式，仅根据URL进行路由，即，只要URL相同，无论POST、GET等哪种请求方式都指向同一个操作函数 path path函数用来处理一个路由对应的视图映射 path(route, view, name) route： 匹配规则，是一个字符串 view：对应的视图函数 name：未来我们会用到他，用来为匹配规则命名，这样方便日后修改路由而不影响全局下的路由使用 re_path re_path是path函数的加强版 可以在re_path函数的第一个位置的字符串参数，是一个标准Python正则表达式，其余参数与path相同 注意：匹配模式的最开头不需要添加/，因为默认情况下，每个url都带一个最前面的/，既然大家都有的部分，就不用浪费时间特别写一个了，所以一定要注意在写路由映射关系时，记得加末尾的/ 模板页面 返回一个字符串这肯定是不行的，太low了，也不好看，现在来返回一个正式的HTML页面 并在HTML页面中加入模板变量，由视图函数动态传递值； 配置django中模板页面的保存路径，在项目目录下的settings.py文件中 12345678910111213141516#myproject/settings.pyTEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR,'template')], # 就是这一行 设置静态模板路径 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,] 创建template目录并在其中创建index.html文件 12345678910&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;hi&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;&#123;&#123; message &#125;&#125;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 在HTML页面中，我们并没有明确指出H1标签的内容；通过一个``来等待接收视图函数传来的数据，在HTML页面中这样的变量也叫做模板变量，双大括号为使用语法 接下来修改之前的视图函数，由视图函数传递变量给到HTML页面 12345678#myapp/views.pyfrom django.shortcuts import renderdef index(request): #return HttpResponse("&lt;h1&gt;Hello world&lt;/h1&gt;") content = &#123; "message":"你好，世界" #此处的key值message对应页面中我们写的&#123;&#123; message &#125;&#125; &#125; return render(request,'index.html',content) render render函数用来返回一个模板页面，并将一个字典组合成的模板变量传递到模板页面上，完成页面的渲染 render(request, template_name, context=None) 返回一个HTTP响应 request： 固定接收request请求 template_name： 为一个可以找到的模板页面 context： 模板页面所需模板变量 模板变量 在django中的HTML页面，不光可以编写原本的标签等内容，还可以像Vue一样在页面中使用双大括号，来提前定义一些模板变量，之后动态的渲染到HTML模板页面中 模板变量可以由后台视图函数构建一个字典数据类型传递， 字典的key是模板变量名，value值该模板变量对应的数据 当然，模板变量的内容远不止此，还会再后面继续为大家叙述 静态文件 虽然有了模板页面，可以来展示一些标签的效果，但是整个HTML还是感觉很丑陋 我们还要继续引入一些类似css、img这样的静态资源，来装饰我们的页面 在django中模板页面的静态资源使用，不能像之前写HTML代码直接引入 需要我们首先在项目中创建目录保存对应的静态资源，该目录名常为static 在settings中配置静态文件保存目录，添加如下内容 1234STATICFILES_DIRS = ( os.path.join(BASE_DIR, 'static'),)# STATICFILES_DIRS 该配置项用来告诉django在查找静态资源时，应该访问哪个目录 在项目中创建static目录，static目录下创建专门保存图片的img目录，在里面存一张图片1.jpg 12345678#此时的目录结构myproject/ myproject/ myapp/ template/ static/ img/ 1.jpg 有了图片，接下来在模板页面中去引入并使用它，打开index.html进行修 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &#123;% load staticfiles %&#125;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;hi&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;&#123;&#123; message &#125;&#125;&lt;/h1&gt; &lt;img src='&#123;% static "img/1.jpg" %&#125;' alt="图片"&gt;&lt;/body&gt;&lt;/html&gt; 这里用到了一个特殊语法：&#123;% tag %&#125;这个叫静态标签，静态标签不同于模板变量，静态标签经常用来加载数据，或创建逻辑，比如之后我们要学到的&#123;% if %&#125;，使用静态标签可以方便我们在模板页面上实现某些只有在后台代码中才可以实现的逻辑功能 在页面中要引入静态资源：图片，CSS，JS文件在引入时都需要通过&#123;% static “path” %&#125;来进行引入 最后，需要使用静态标签static前使用&#123;% load staticfiles %&#125;标签进行静态资源路径的加载 模型数据库 有了以上内容的修饰，现在感觉还是缺少一些什么，我们在视图函数中为前端页面返回的是一个提前定义好的变量，这显然在真正开发中是很少出现的，我们的数据大都来自于数据库中，那么现在需要我们在项目中加入数据库，并且在视图函数中通过对数据库的访问来拿到数据 创建数据库，这里使用项目自带的SQLite3数据库，默认已经是配置好的，接下来需要我们进入到app下的models.py文件中，编写一个类，这个类就对应数据库中的一张表 1234567891011#myapp/models.pyfrom django.db import models# Create your models here.class Weather(models.Model): weather = models.CharField(max_length=100,verbose_name="天气") class Meta: verbose_name_plural = "天气" # 设置当前表名的一个可读的性更好的名字 def __str__(self): return self.weather 在这里我们使用到了django的orm映射关系用来创建数据库表，继承自django的models.Model类， 一个类用来表示一张表，类中的一个属性代表一个字段， 这里我们定义了一个类型为CharField，长度为100的字段，用来存储天气 models.CharField(max_length=100,verbose_name=&quot;天气&quot;) 下面的class Meta是模型类的元类，用来设置当前表的一些属性； 这里我们使用verbose_name_plural属性设置当前表在admin后台查看时的名字 在这里我们还定义了一个属于实例的函数__str__，用来描述当前数据在返回时的默认展示结果，为weather字段的值 django在创建模型类对应的数据表时，默认使用 应用名加下划线加模型类名作为表的名字；比如当前Weather表名为：myapp_Weather orm映射关系，是django与数据库之间的一个桥梁，可以使开发者不再关注如何去编写SQL语句，直接通过一套ORM所提供的API接口即可方便对各种数据库进行交互 当某个子应用APP涉及到了数据库的使用时，要记得在settings文件中进行配置 12345678910#myproject/settings.pyINSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'myapp',] 接下来通过manage.py命令行管理工具提供的两条，创建我们所需要的数据 注意：默认django本身就已经需要一些数据的创建，所以我们在初次执行以下两条命令时可能会看到很多数据表和字段的创建，不要惊讶，这是正常的 python manage.py migrate：根据数据库迁移文件生成对应SQL语句并执行 初次执行是为了先把默认django需要的数据库创建出来 python manage.py makemigrations：创建数据库迁移文件 这次执行是为了创建APP中Weather模型类的迁移文件 12&gt; python manage.py migrate&gt; 将新添加的模型类迁移文件生成对应SQL，实际创建出对应的Weather表 如果提示结果正常，那么代表相应的数据表已经创建好了，接下来就需要我们去到django为我们提供的admin（数据库管理界面）来进行相关表的操作了！ admin控制台 admin控制台是django为我们提供的一个非常便捷的用来管理数据库的界面 在主控路由文件下，其实你已经看到了它对应的路由设置：path(&#39;admin/&#39;, admin.site.urls), 进入admin界面，初次访问连接：127.0.0.1/admin，会提示我们输入账号密码，这是因为django的admin界面是需要一个超级管理员来登陆访问的，所以还需要我们创建对应的admin界面下的超级用户 创建admin超级用户，使用manage.py命令行工具执行如下命令 1python manage.py createsuperuser 1234567891011121314Username (leave blank to use 'lienze'): rootEmail address:Password:Password (again):This password is too short. It must contain at least 8 characters.This password is too common.This password is entirely numeric.Password:Password (again):This password is too common.This password is entirely numeric.Password:Password (again):Superuser created successfully. 以上是我们创建超级用户的过程，非常坎坷； 可以看到，在输入太短（不满足8位），或是只包含数字的简单密码，超级用户的创建都是被拒绝的 所以我们把用户账号创建为root，而密码创建为a1234567， 接下来开启测试服务器，并通过创建好的超级用户登陆访问，如果幸运的话，你已经可以看到后台的admin界面啦 admin界面已经展示出了默认django所使用的两张表，用户表和组表，用来保存当前管理后台的用户以及对应权限分组，可以点入用户表查看其中我们刚创建的root。 admin注册表 问题还是有的，虽然admin界面已经可以登入，但是为什么看不到刚才创建的Weather表呢 这是因为默认的表创建之后，还需要通过对应app下的admin.py文件进行admin后台注册，只有注册在这个文件中的模型类对应的表才可以在admin界面所看到 在app下的admin.py文件中进行模型类的注册 123456#myapp/admin.pyfrom django.contrib import adminfrom myapp import modelsadmin.site.register(models.Weather)#使用register函数接收模型类作为参数即可完成注册 注册成功之后，在服务器，通过浏览器访问admin界面，就可以看到创建好的Weather表了 鼠标点击进去之后，就可以看到对应的表数据界面；右上角提供了可以添加功能的选项，试试给这个表来一些数据吧，这里我们添加了三条数据 1阴天，晴天，打雷了 视图操作模型 最终我们希望可以在视图函数中通过orm接口来访问到表中的数据，那么来打开视图文件吧：views.py 12345678910#myapp/views.pyfrom django.shortcuts import renderfrom myapp import modelsdef index(request): weathers = models.Weather.objects.all() content = &#123; "weathers":weathers, &#125; return render(request, 'index.html', content) 光返回是不行的，虽然我们绑定到了模板版变量的字典中，但是还得修改一下对应的要渲染的HTML页面哦： 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &#123;% load staticfiles %&#125;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;hi&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;% for weather in weathers %&#125; &lt;p&gt;&#123;&#123; weather &#125;&#125;&lt;/p&gt; &#123;% empty %&#125; &lt;p&gt;没有任何天气&lt;/p&gt; &#123;% endfor %&#125;&lt;/body&gt;&lt;/html&gt; 模板标签&#123;% for xxx in xxxs %&#125;可以用来在模板页面出迭代访问取出每一个数据 具体对于不同序列数据的访问我们会在后面详细为大家介绍 &#123;% empty %&#125;标签用来判断当循环访问数据为空时要做的事情，最后循环标签要有&#123;% endfor %&#125;标签进行结束；因为HTML中并没有像Python缩进这样的方式来控制代码块。 总结 至此，我们的HELLO WORLD项目已经涵盖了django框架中的大部分常用的组件； 路由、视图、模板、静态、模型，admin 那么其中每一部分都还有很多内容等着我们去了解！]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制转十进制，十进制转二进制]]></title>
    <url>%2F2030%2F11%2F05%2F%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6%EF%BC%8C%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6%2F</url>
    <content type="text"><![CDATA[二进制介绍 二进制是计算技术中广泛采用的一种数制。二进制数据是用0和1两个数码来表示的数。它的基数为，进位规则是“逢二进一”，借位规则是“借一当二”，由18世纪德国数理哲学大师莱布尼兹发现。当前的计算机系统使用的基本上是二进制系统，数据在计算机中主要是以补码的形式存储的。计算机中的二进制则是一个非常微小的开关，用“开”来表示1，“关”来表示0。20世纪被称作第三次科技革命的重要标志之一的计算机的发明与应用，因为数字计算机只能识别和处理由‘0’.‘1’符号串组成的代码。其运算模式正是二进制。19世纪爱尔兰逻辑学家乔治布尔对逻辑命题的思考过程转化为对符号”0’’.’’1’’的某种代数演算，二进制是逢2进位的进位制。0、1是基本算符。因为它只使用0、1两个数字符号，非常简单方便，易于用电子方式实现。 十进制介绍 十进制：600，3/5，-7.99……看着这些耳熟能详的数字，你有没有想太多呢？其实这都是全世界通用的十进制，即1.满十进一，满二十进二，以此类推……2.按权展开，第一位权为10^0，第二位10^1……以此类推，第N位10^（N-1），该数的数值等于每位位的数值*该位对应的权值之和。 十进制转二进制 十进制转二进制：十进制数转换为二进制数时，由于整数和小数的转换方法不同，所以先将十进制数的整数部分和小数部分分别转换后，再加以合并。下面就是方法，挺简单的 12345用15除以2，商为7，余数为1，再用7除以2，商为3，余数为1，再用3除以2，商为1，余数为1，再用1除以2，商为0，余数为1，最后吧余数倒过来排列就为二进制的1111（即商为0时的1，商为1时的1，商为3时的1，商为7时的1） 二进制转十进制 以二进制的1111转十进制为例： 12把二进制的1111看成是十进制的1111即1*10^3 + 1*10^2 + 1*10^1 + 1然后把10变成2，即1*2^3 + 1*2^2 + 1*2^1 + 1=15]]></content>
      <tags>
        <tag>进制转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 监控系统]]></title>
    <url>%2F2030%2F10%2F30%2FZabbix%20%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Zabbix 监控系统什么是监控系统？例如：开车时的行车记录仪、班级里面的监控摄像头、医院使用的血压监测仪等等 在IT领域中，监控系统就是监控系统资源以及性能的硬件或者软件 监控软件 单一监控程序 windows系统的任务管理 linux系统中的top、vmstat、iostat 分布式监控程序 为什么需要监控系统？为用户提供稳定、高效、安全的服务 但是像zabbix和open-falcon只能监控某些方面。而为了业务高效运行还需要和APM也就是应用性能监控、全局链路调用追踪等一起实现。而安全性需要安全团队和相关系统紧密结合才行 监控系统都有哪些功能？ 数据收集. 数据展示 告警策略 告警发送 事件管理 报表管理. 认证权限. 开源监控系统现状 Nagios. 1999年发布的初始版本。它可以监控网络、主机等设备。支持丰富的监控插件。用户可以根据自己的实际环境定义监控 Cacti. 2001年发布的。是一套基于SNMP和RRDTool的网络流量监控分析的系统 RRDTool: 用来处理时间序列数据的套件 SNMP: 简单网络管理协议 Ganglia Zabbix Prometheus Falcon Grafana Grafana是可以美观的展示和分析监控数据的工具，收集数据并支持告警等功能 Zenoss Graphite Open-falcon … 小米公司开源的，高可用、可扩扎的开源监控解决方案 监控系统可以干什么？ KPI聚类 瓶颈分析 KPI异常检测、定位 故障预测 容量预估 Zabbix 简介 市场上还有一款叫做open-falcon和zabbix类似，而且市场上也是在广泛使用，都是属于分布式监控程序 zabbix 是一个基于web界面的提供分布式系统监控的企业级的开源解决方案。 zabbix 能监视各种网络参数， 保证服务器系统的安全稳定的运行，并提供灵活的通知机制以让SA快速定位并解决存在的各种问题。 了解zabbix我们通过zabbix能够监控到哪些硬件资源呢？理论上说，只要是与我饿们的业务相关的硬件资源，又应该被监控。比如主机、交换机、路由器、UPS等等。但是，监控她们的额前提是能与他们进行通讯，那么问题来了，由于硬件不同，导致我们无法使用统一的方法去监控他们，这个时候就需要监控程序有一定的通用性，或者说，监控程序需要能够与多种硬件设备通讯，才能满足我们的监控需求。所以zabbix如果想要能够全面的监控这些对象，则需要能够通过各种方法与他们通讯。 Zabbix 的优点 支持自动发现服务器和网络设置 支持底层自动发现 分布式的监控体系和集中式的web管理 支持主动监控和被动监控模式 服务器支持多种操作系统： linux solaris HP-UX AIX FreeBSD OpenBSD MAC … Agent客户端支持多种操作系统： linux Solaris HP-UX AIX FreeBSD Windows … 基于SNMP、IPMI接口方式也可以 监控Agent 安全的用户认证及权限配置 基于WEB的管理方法，支持自由的自定义事件和邮件发送 高水平的业务视图监控资源，支持日志审计、资产管理等功能 支持高水平API二次开发、脚本监控、自Key定义、自动化运维整合调用 Zabbix 监控组件及流程zabbix 主要有三大组件组成，分别是 Zabbix server端 Zabbix WEB GUI Zabbix Datebase Zabbix Server Zabbix Proxy端 Zabbix Agent端 zabbix的好处：占用资源少、可以获取CPU、内存、网卡、磁盘、日志等信息。 对于无法安装客户端的设备，zabbix支持通过SNMP获取监控数据 zabbix支持通过IPMI(智能平台管理接口)获取硬件的温度、风扇、硬盘、电源等 #####zabbix监控系统的意义 通过这些监控系统我们可以了解设备的繁忙程度、是否有异常的进程占用资源 比较常见的是：通过传感器获取设备的监控信息 Zabbix 能监控哪些硬件资源呢？ 如果理论上说，只要与我们业务相关的硬件资源，都可以被监控。例如：主机、交换机、路由器等等。但是监控的前提是能与他们进行通讯 Zabbix 支持哪些通讯方式呢？ Agent：通过专用的代理程序进行监控，与常见的master/agent模型类似。如果被监控对象支持对应的agent，推荐首选这种方式 ssh/tenet：通过远程控制协议进行通讯，比如ssh或telnet SNMP:通过SNMP协议与被监控对象进行通讯，SNMP协议全称 Simple Network Mnaagement Protocol,被译为“简单网络管理协议”，通常来说，我们无法在路由器、交换机这种硬件上安装agent，但是这些硬件往往都支持SNMP协议、SNMP是一种比较久远的、通行的协议，大部分网络设备都支持这种协议，其实SNMP协议的工作方式也可以理解为master/agent的工作方式，只不过实在这些设备中内置了SNMP的agent而已，所以大部分网络设备都支持这种协议 IPMI：通过IPMI接口进行监控，我们可以通过标准的IPMI硬件接口，监控被监控对象的物理特征，比如电压、温度、风扇状态、电源状态等等 JMX：通过JMX进行监控，JMX全称 Java Management Extensions ，也就是Java管理扩展，监控JVM虚拟机时，使用这种方法也是非常不错的选择 Zabbix 监控流程zabbix 核心组件 zabbix agent：部署在被监控主机上，负责被监控主机的数据，并将数据发送给zabbix server zabbix server：负责接收agent发送的报告信息，并且负责组织配置信息，统计信息，操作数据等 zabbix database：用于储存所有zabbix的配置信息、监控数据的数据库 zabbix web：zabbix的web界面，管理员通过web界面管理zabbix配置以及查看zabbix相关监控信息 zabbix proxy：可选组件，用于分布式监控环境中，zabbix proxy代表server端，完成局部区域内的信息收集，最终统一发往server端 我们将zabbix agent 部署到被监控主机上，由agent采集数据，报告给负责控制中心主机，中心主机也就是master/agent模型中的master，负责监控的中心主机被称为zabbix serevr，zabbix server将从agent端接收到信息储存于zabbix的数据库中，我们把zabbix的数据库端称为zabbix database，如果管理员需要查看各种监控信息，则需要zabbix的GUI，zabbix的GUI是一种Web GUI，我们称之为zabbix web，zabbix web是使用PHP编写的，所以，如果想要使用zabbix web展示相关监控信息，需要依赖LAMP环境，不管 是zabbix server，或是zabbix web，他们都需要连接到zabbix database获取相关数据 当监控规模变得庞大时，我们可能有成千上万台设备需要监控，这时我们是否需要部署多套zabbix系统进行监控呢？如果部署多套zabbix监控系统。那么监控压力就会被分摊，但是，把这些监控的对象将会被尽量平均的分配到不同的监控系统中，这个时候，我们就无法通过统一的监控入口，去监控这些对象了。虽然分摊了监控压力，但是也增加了监控工作的复杂度？其实，zabbix天生就有处理这种问题的能力，因为zabbix支持这种分布式监控，我们可以把成千上万台的监控对象分成不同的区域，每个区域中设置一台代理主机，区域内的每个监控对象的信息被agent采集，提交给代理 主机，在这个区域内，代理主机的作用就好比zabbix server，我们称为这些代理主机为zabbix proxy，zabbix proxy再将收集到的信息统一提交给真正的zabbix server处理。这样，zabbix proxy不仅分摊了zabbix server的压力，同时，我们还能够通过统一的监控入口，监控所有的对象 zabbix 工作模式 我们都知道，agent端采集完数据主动发送给server端，这种模式我饿称之为主动模式，也就说对于agent端来说是主动的。 其实，agent端也可以不主动发送数据，而是等待server过来拉取数据，这种模式我们叫被动模式 其实不管是主动模式还是被动模式，都是对于agent端来说的。而且，主动模式与被动模式可以同时存在，并不冲突。 管理员可以在agent端使用一个名为zabbix_sender的工具，测试是否能够从server端发送数据。 管理员也可以在server端使用一个名为zabbix_get的工具，测试是否能从agent端拉取数据 Zabbix 服务器搭建部署安装描述简单地概念刚刚已经描述过，zabbix的几个常用的重要组件，在安装zabbix时，其实是在安装这些组件。 由于我们的监控规模也不大，所以此处将不会安装zabbix proxy ，我们需要安装如下组件： Zabbix server Zabbix database Zabbix web Zabbix agent 好了，接下来一个一个聊 安装的zabbix server版本为3.0 因为zabbix3.X依赖的php版本 不能低于php5.4，而在centos6.8中，php默认版本为5.3 如果你想要使用centos6.X的操作系统。同时想要更加方便的升级php，可以使用Remi源升级PHP， 但是为了更加方便的使用yum源安装相关软件包，此处使用centos7安装zabbix3.0.7 安装 zabbix server为了方便安装，配置zabbix的官方yum源 1http://repo.zabbix.com/ 我们配置一下zabbix3.0的yum源 首先进入/ect/yum.repo.d/文件夹 查看一下 是否有zabbix.repo，如果没有创建一个并编写，如下图格式 12345[zabbix]name=zabbixbaseurl=http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/gpgcheck=0enabled=1 同时，我们配置了base源与epel源，因为安装过程中会用到这些yum源。 没有配置好的话，会报出如下图的错： 所以在下载之前，先配置好base源和epel源 这里选择的是redhat7下x86_64的zabbix3.0版本的包。但是安装zabbix-server-mysql时报错，原因是缺少libiksemel.so.3()(64bit)和fping包。这是因为yum安装zabbix不仅需要配置zabbix包源，还需要配置好epel源和base源，base源我们有自带就不用说了。 这时我们需要配置epel源 1yum -y install epel-release 1ls /etc/yum.repo.d/ 这里看到多了epel.repo这个文件，表明epel配置成功。 然后我们继续安装zabbix-server-mysql 1234yum -y install zabbix-server-mysql错误：软件包：zabbix-server-mysql-3.0.25-1.el7.x86_64 (zabbix)需要：libiksemel.so.3()(64bit) 我们发现这里还有缺少依赖包libiksemel.so.3()(64bit)的问题。 我们通过下载zabbix源来解决这个问题 1yum -y install http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm 最后安装zabbix-server-mysql成功 1234yum -y install zabbix-server-mysql zabbix-get --skip-broken已安装:zabbix-server-mysql.x86_64 0:3.0.25-1.el7 准备工作完毕，剩下的就是安装各个组件了，我们一个一个安装 先安装zabbix server 由于我们使用mysql作为数据库，所以，在安装zabbix3.X的版本的server端时，需要安装zabbix-server-mysql包，在3.X的zabbix版本中，并没有单独的zabbix server端程序包，安装zabbix-server-mysql包即为了安装了server端包，同时，我们可以在服务器安装zabbix_get包，以便想agent端发起测试采集数据请求，所以，我们在server端安装如下; 1yum install zabbix-server-mysql zabbix-get 在安装的时候，我遇到了一个问题， 密密麻麻的英文很头疼，而且好多都不认识咋办？其实也不用全都理解，全都认识，认识关键字就行。例如：You could try using –skip-broken to work around the problem ，大概意思就是 ‘你可以使用 “–skip-broken” 来解决这个问题‘，所以只需要在代码后面加上就可以了 1yum install zabbix-server-mysql zabbix-get --skip-broken 还有一种解决办法，就是更新一下你的yum，因为你的yum版本低了。 1yum -y update 安装完成后，输入 1rpm -ql zabbix-server-mysql 如果出现下图这样的情况，那就是你安装失败了。需要重新安装 重新安装还有可能碰到一种问题， 连上你同桌的WiFi就好了，因为你的网络丝毫不给你一分薄面！ 之后重新下载一下就好了，出现Comlete就是现在好了，如下图 后面出现类似的问题，同样的方法解决就好了 之后继续配置，输入 1rpm -ql zabbix-server-mysql 输入这行命令，看见create.sql.gz那就进入到这个文件夹 1cd /usr/share/doc/zabbix-server-mysql-3.0.28 之后解压create.sql.gz这个压缩文件，即可获得初始化sql脚本 1gunzip create.sql.gz 之后输入 1ll create.sql 是这样的效果，就是正确的！ 但是需要注意的是，此sql脚本中sql只会在对应的数据库中初始化zabbix所需要的数据库表，但是不会创建zabbix数据库，所以，创建zabbix数据库这一步骤，还是需要我们手动进行的。所以，此处我们先动手创建zabbix的数据库，过程如下： 进入数据库 12345create database zabbix charset 'utf8';grant all on zabbix.* to zabbix@'localhost' identified by '123456';flush privileges; zabbix数据库初始化完成后，执行对应的sql初始化脚本，输入命令： 12mysql -uroot -p -Dzabbix &lt; /usr/share/doc/zabbix-server-mysql-3.0.28/create.sql# /usr/share/doc/zabbix-server-mysql-3.0.28/create.sql 对应的是你create.sql所在的地点 进入数据库，zabbix库，查看表，出现这些表，就是导入成功 配置zabbix server端并启动server端已经安装完毕，并且数据库也已经初始化，现在我们开始配置server端，编辑zabbix server端的配置文件 1vim /etc/zabbix/zabbix_server.conf 此处列出我们可能会经常修改的参数，如下： LIstenPort=10051 服务器默认端口 SourceIP= 通过SourceIP参数可以指定服务器的源IP，当server端㕛多个IP地址时，我们可以指定服务器端使用固定的IP于agent端进行通讯，为了安全起见，agent端会基于IP进行一定的访问控制，也就是说agent端只允许指定IP以server端的身份菜鸡被监控主机的数据，如果IP不对应，租不允许采集被监控主机的数据，所以，当server端 有多个IP时，我们可以通过SourceIP参数，指定server端 通过哪个IP采集被监控主机的数据 LogType=file=file 通过LogType参数，可以指定通过哪种方式记录日志，此参数可以设置为三种值，system、file、console，system表示将日志发往syslog，file表示使用指定的文件 作为日志 文件，console表示将日志发往控制台，默认为file LogFile=/var/log/zabbix/zabbix_server.log 当LogType设置为file时，通过LogFile参数设置日志文件位置 LogFileSize=0 指明日志文件达到 多大是自动滚动，单位为MB，如果设置LogFileSize为50时，表示日志大小达到 50MB滚动一次，设置为0表示日志文件不寄回滚动，所有入职保存在一个文件中 Debuglevel=3 通过DebugLevel参数可以定义日志的详细程度，即为日志级别 DBHost=localhost 通过DBHost参数设置zabbix数据库 所在的服务器IP，由于此处zabbix于mysql安装在同一个服务器上，所以此处设置为localhost DBUser=zabbix 通过DBUser指定zabbix数据库用户名 DBPassword= 通过DBPassword指定zabbix数据库用户的密码 DBPort=3306 通过DBPort指定zabbix所在数据库服务监听的端口号 DBSocket=/var/lib/mysql/mysql.sock 如果数据库服务于server端在同一台服务器上，可以通过DBSocket指定数据库本地套接字文件位置，但是需要注意，即使设置了mysql套接字文件的位置，还是需要配合DBHost参数，否则在登录zabbix控制台时，可能会出现警告，在zabbix server的log中，也可能会出现无法连接数据库的提示 根绝上述的配置参数的解释，根据具体需求进行实际配置即可。 配置完成后，启动zabbix服务端即可，输入 1234systemctl start zabbix-server.service# 输入ss -tnl# 查看10051端口是否被监听 启动后,10051端口已经被监听，如下图 安装zabbix web端zabbix web 可以安装在单独的主机上，只要能连接到zabbix database所在的数据库即可。但是此处为了方便，我们将zabbix web与mysql以及 zabbix server 安装在同一台服务器上。 因为 zabbix web 需要lamp环境，所以，此处我们将会依赖到的环境先安装好。 代码如下： 1yum install httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml 完成上述步骤后，安装zabbix web所需要的两个包，对应版本为3.0.7. 1yum install zabbix-web zabbix-web-mysql --skip-broken 查看刚才安装完成的zabbix-web程序包，可以看到，zabbix-web的web应用存放在/usr/share/zabbix中。 1rpm -ql zabbix-web zabbix还是比较贴心的，针对httpd，zabbix-web包中已经包含了对应zabbix文档路径的配置文件。 输入： 1vim /etc/httpd/conf.d/zabbix.conf 以看到，针对zabbix web的文档路径，此文件中已经为我们准备了默认设置，如果不使用httpd的虚拟主机，只要把时区稍加改动即可直接使用 而此处，我们使用httpd的虚拟主机访问zabbix web ，所以，将配置文件爱你中的内容改为如下配置，同时将时区修改为亚洲上海 12345678910111213141516171819202122232425262728293031323334353637383940&lt;VirtualHost 39.106.84.122&gt;servername zabbix.zhanglei.netdocumentroot /usr/share/zabbix Alias /zabbix /usr/share/zabbix &lt;Directory "/usr/share/zabbix"&gt; Options FollowSymLinks AllowOverride None Require all granted &lt;IfModule mod_php5.c&gt; php_value max_execution_time 300 php_value memory_limit 128M php_value post_max_size 16M php_value upload_max_filesize 2M php_value max_input_time 300 php_value max_input_vars 10000 php_value always_populate_raw_post_data -1 php_value date.timezone Asia/Shanghai &lt;/IfModule&gt; &lt;/Directory&gt; &lt;Directory "/usr/share/zabbix/conf"&gt; Require all denied &lt;/Directory&gt; &lt;Directory "/usr/share/zabbix/app"&gt; Require all denied &lt;/Directory&gt; &lt;Directory "/usr/share/zabbix/include"&gt; Require all denied &lt;/Directory&gt; &lt;Directory "/usr/share/zabbix/local"&gt; Require all denied &lt;/Directory&gt;&lt;/VirtualHost&gt; 配置为完成后，启动httpd服务。 好了，zabbix web安装配置完成 访问 服务器IP/zabbix，就可以看到如下图的zabbix安装页面 配置好之后，别忘记把把/usr/share/zabbix复制到/var/www/html里面 之后，IP/zabbix/setup.php访问即可，就可出现如下图的样子。 初始化zabbix 配置完成上述安装步骤后就可以看到zabbix安装页面。点击下一步 不出意外的话，你们也会这样。哈哈哈 按照错误的这四个参数。修改/etc/php.ini文件中的配置就行 1vim /etc/php.ini post_max_size=16M max_execution_time=300 max_input_time=300 date.timezone =Asia/Shanghai 找到这四个，直接把配置改了就好，和我的一样就行。 如果嫌找的麻烦，直接搜索，输入‘/’ 1/你想搜索的关键字，或者全拼 改好之后重新启动下服务 1systemctl restart httpd.service 之后再重新加载下页面，就会像如下图： 可以看到，zabbix检查的环境已经全部满足，所以点击下一步！ 此处zabbix需要配置数据库连接，此处配置数据库的类型，IP，端口，数据库名，用户密码等信息，端口填写0表示使用默认端口(3306端口) 请确定概要信息无误，点击下一步 之后，就会进入登录页面，默认账号admin，密码zabbix 登录完成后，可以看到zabbix的仪表盘 全是英文，作为一个爱国的知识青年，肯定看不爽，所以 ，我们可以把它调成中文版 语言选择中文，点击 更新即可，蛋黄思思你可能无法在语言中看到中文的选项，如果无法找到中文选项，则代表你的配置文件中的中文选项显示属性为false 当然了，如果你没有这项选择，那么你可以修改下如下文件 1vim /usr/share/zabbix/include/locales.ini.php 找到中文对应的值，将显示属性设置为true即可，如上图所示 但是，你可能还会遇到中文乱码情况，如果遇到中文乱码，可以从Windows中挑选一个顺眼的中文字体，将对应字体放置到inux中 zabbix web的字体目录中，因为我们使用的是rpm包安装的zabbix web，所以zabbix web默认字体目录为 /usr/share/zabbix/fonts/，Windows中的字体文件后缀名如果为TTF，当我们把对应字体文件拷贝到zabbix字体目录是，需要修改其后缀名为小写的ttf（如果本来就是小写的则不用任何修改了），字体文件上传完毕后，修改/usr/share/zabbix/include/defines.inc.php配置文件，将下图中显示字体部分修改为刚才上传的字体文件对应的名称即可。 好了，上述操作完成后，zabbix控制台即显示中文了。 但是你可能会在访问zabbix控制台时，可能会发现如下提示： 如果出现图中的提示，可能是由如下几个原因引起的： 1、zabbix-server未正常启动 2、已经开启selinux，但是没有正常设置对应权限 3、zabbix-server未能正常连接数据库 4、zabbix.conf.php文件中$ZBX_SERVER参数对应的主机名不能正常解析 5、其他原因，需要查看zabbix server 日志 如果在访问zabbix控制台时并没有出现上述提示，忽略上述描述即可。 为了更加安全，我们不应该使用管理员的默认密码，所以，我们最好先修改管理员密码 好了。基本配置已经配置完成了，我们以后的监控工作就要围绕着这个web界面展开了！ Zaabix agent 安装现在万事具备，就差agent端了，agent端安装也非常方便，直接被监控主机上安装如下两个包即可。 当然了，在安装之前，指定要把上面的准备工作全都做好，否则会出错的哦！ 此处被管理主机 centos7，已经配置好了对应的zabbix源，agent版本可以跟server端版本 不一致，没有关系，安装即可 1yum install -y zabbix-agent zabbix-sender 我们查看一下zabbix-agent都安装了什么文件，当然，最重要的就是zabbix_agentd.conf这个配置文件了 还记得我们在刚开始介绍zabbix时说过“主动模式”与“被动模式”吗？这两种模式的相关配置，都需要在zabbix_agentd.conf中定义，打开这个文件，我们来配置一下常用的agent端配置。首先，可以看到配置文件中有很多注释，打开配置文件，首先看到的就是”通用参数配置段”，我们可以在此配置段配置zabbix_agent进程的进程编号文件路径，存储日志方式，日志文件位置，日志滚动阈值等常用设定，细心如你一定已经发现，zabbix_agent配置文件的”通用配置段”中的参数大多数与zabbix_server配置文件中的常用参数意义相同，所以，此处不再过多赘述，如果没有特殊需要，保持默认即可。 此处先说说我们马上会用到的两个配置，如下图红框中的注释所描述的，“被动模式配置段”与“主动模式配置段” 我们已经在最开始的概念介绍中，描述过，“主动模式”和“被动模式”都是对于agent端来说的，而且它们可以同时存在，，并不冲突。 我们先来看看“被动模式”的相关配置参数。 被动模式相关参数如下： Sserver：用于指定允许哪台服务器拉去当前服务器的数据，当agent端工作于被动模式，则代表server端会主动拉取agent端数据，那么server端的IP必须与此参数的IP对应，此参数用于实现基于IP的访问控制，如果有多个IP，可以使用逗号隔开。 ListenPort：用于指定当agent端工作于被动模式所监听的端口号，默认端口号10050，也就是说，server端默认访问10050端口，从而拉取数据。 ListenIP：用于指定agent端工作于被动模式时所监听的IP地址，默认值为0.0.0.0，表示监听本机的所有IP地址。 StartAgents：用于指定预生成的agent进程数量。 主动模式 主动模式的常用参数如下： ServerActive：此参数用于指定当agent端工作于主动模式时，将信息主动推送到哪台server上，当时有多个IP时，可以用逗号隔开。 Hostname：此参数用于指定当前主机的主机名，server端通过此参数对应的主机名识别当前主机。 RefreshActiveChescks：此参数用于指明agent端没多少秒主动将采集到的数据发往server端。 此处，我们同时设置“被动模式”与“主动模式”的如下参数，其他保持默认即可，修改完成后保存退出。 Server=47.96.230.50 ServerActive=47.96.230.50 Hostname=testzbx1.zsythink.net 配置文件修改完成后，启动agent端进程 好了，agent端也已经安装好了！ 在 Zabbix 中添加主机在添加主机之前，我们先把工作场景描述清楚。然后再根据描述的工作场景进行演示 假设，我们想要使用zabbix监控一台linux服务器，那么，我们肯定要将这个服务器纳入zabbix的管理范围，而“添加主机”这个操作，就是将被监控的主机纳入zabbix管理范围的一个必须操作，如果我们有10台主机都需要呗zabbix监控呢？没错，这10台主机必须被添加到zabbix的监控列表中，在zabbix中，我们将被监控的对象称为“主机”，“主机”不一定是服务器，也可以是路由器，交换机等网络设备，而且，根据主机的属性、角色、特征的不同，我们还能够将主机分组。 比如，我们有10台服务器，10台服务器中，有3台window服务器，有7台linux服务器，那么，我们还可以按照操作系统的不同，将他们分成两组，Windows服务器组于linux服务器组，或者我们不按照操作系统对主机进行分组，而是根据服务器的角色对主机分组。 比如，一共10台服务器，3台是是提供ldap服务的，2台是提供web服务的，5台是提供数据库服务的，我们也可以把他们按照角色分成3组，ladp主机组、web主机组、db主机组，当然，我们也只是举个例子。 实际应用中，具体怎样分组，是根据实际需求视情况而定的，那么，为什么要将主机分组呢？这是为了方便管理，因为同一类主机需要被监控的指标很有可能 都是相同的，所以将他们分为一组方便管理，当然了，这就是后话，我们后面再聊！ 上面一段话中，我们提到了两个zabbix的常用术语，“主机”与“主机组”，我们再来总结一遍： 1231、host（主机）：需要zabbix监控的对象，被称为主机，主机必须属于某个主机组。2、hostgroup（主机组）：“主机组”也被称为“主机群组”，是由具有相同属性、特征、角色的多个主机组成的逻辑单元。 理解 上述两个术语，并且能够在zabbix中使用他们，就是我们所要达到的目的。 那么我们来看看怎样在zabbix添加一台主机，在动手添加主机之前。先说明下我们的环境。 我们已经将zabbix-server、zabbix-database、zabbix-web安装在了39.106.84.122上。 同时，我们将zabbix-agent安装在了47.97.172.176上。 所以此处，47.97.172.176就是被监控的对象 ，我们需要将176添加为zabbix主机。 首先呢，打开我们的zabbix web 控制台，看看都有那些“主机组”。 点击“配置“—-”主机群组“，可以看到，系统默认已经为我们准备了一些主机组，如果这些主机组不满足我们的需要，我们也可以创建新的主机组 点击下图中的“创建主机群组”按钮，即可创建主机组，但是，我们还不用深入研究主机组，此处只是让大家了解一下，对主机有一个初步的认识。 同样，点击配置—–主机，即可查看已经被加入zabbix主机列表的主机，可以看到，zabbix默认将zabbix server添加为了一台主机，以便 可以自己监控自己，但是此处，我们需要添加一台我们自己的主机，就是47.97.172.176， 点击创建主机，点击创建主机之前，可以选择左侧的群组下来菜单，以确定将要创建的主机所在的主机组，当然，我们也可以先不选主机组，直接点击创建主机按钮。 点击创建主机按钮之后，即可看见类似如下界面，为了更好的描述每个步骤，具体解释参靠下图后面的注释列表。 1、我们可以在主机名的文本框中填写被监控主机的主机名称。 2、可见名称一般使用剪短的、易读的、见名知义的名称表示主机即可。 3、我们可以选择将要创建的主机属于哪个主机组，当然，如果没有合适的主机组，我们也可以直接在创建主机时，直接创建新的主机组，我上面说过，每个主机必须存在于某个主机组中，所以，主机组是必须的 4、如果在三的3的位置上没有对应的、可用的、合适的主机组，我们可以直接在新的群组中创建当前主机需要的主机组。 5、选择通过哪种接口监控当前主机，可选的方式有IPMI接口、JMX接口、SNMP接口、agent接口，我们说过，”主机”在zabbix中，可以是服务器，路由器，交换机等等硬件设备，有的硬件设备只支持某种接口，所以，当我们添加主机时，会让我们选择通过哪种合适的接口监控它，具体各接口的适用场景我们已经在第一篇介绍zabbix概念的文章中描述过，此处不再赘述，当然，如果一台主机能被多种接口所监控，也可以同时配置多个接口监控这台主机，但是当前，我们需要监控的主机是一台Linux服务器，而且已经安装了对应的agent端，所以，此处，我们只使用agent接口对当前主机进行监控，而使用agent接口时，可以通过IP连接到对应agent，也可以使用主机名连接到对应agent，而此处，我们选择使用IP地址连接到对应的agent，IP地址就是我们将要添加的主机的IP，47.97.172.176 ，对应端口为默认的10050，如果你想要使用主机名连接到对应的agent，那么需要保证主机名能够被正常解析到47.97.172.176上，此处不再赘述，如果有多个IP可以连接到对应agent，可以点击”添加”，添加一条新的IP。 6、对将要添加的主机进行描述，添加响应的描述信息即可。 7、表示是否使用zabbix proxy监控当前主机，虽然上图中。此处翻译为“由agent代理程序检测”，但是实际是用于指定zabbix proxy的，与zabbix agent并没有关系，但是因为我们没有配置zabbix_proxy，所以此处保持默认即可 好了，按照上述界面中的配置进行设置以后，点击”添加”按钮，即可简单的添加一台主机，可以看到，47.97.172.176已经被添加到了主机列表中。 而且，如果此时我们再次查看主机组，已经发现，TestHosts主机组已经被添加了，而且其中的成员已经包含了testzbx1主机。 回到主机列表，可以看到我们刚才添加的testzbx1主机，但是testzbx1主机的”可用性”对应的4中接口都是灰色的。 第二个图我们可以看见，何金存的主机已经成功的卑微监控了， 上图中，而ZBX就代表agent接口，虽然我们在添加主机时，配置了通过agent监控对应主机，但是，由于我们并没有配置监控主机的任何指标，所以，ZBX仍然是灰色的，也就是说，我们现在只是将192.168.1.107加入了zabbix的监控范围，但是并没有对它进行任何实际的监控，因为我们还没有配置任何”监控项”，至于怎样配置监控项，且听下回分解。 在Zabbix中添加监控项上面呢已经描述了zabbix添加主机，但是，我们还并没有对主机进行任何指标的实际监控那么现在，我们就来说说，具体怎样监控我们想要监控的指标。 首先，打开我们zabbix控制台，点击配置—主机，可以看到我们上次创建的主机，虽然我们为对应的被监控主机安装了agent，但是主机对应的ZBX仍然显示灰色，代表我们还没有任何监控项被检测到，那么现在，我们来为“何金存”主机添加一个监控项。 点击“何金存”主机上的监控项，如下图所示位置。 进入监控项配置界面后，可以根据一些条件，筛选出已经存在的一些控制项，但是我们并没有任何监控项，所以此处 ，我们直接点击创建监控项按钮。以便新建监控项。 假如，现在我们想要监控“何金存”这台主机的CPU的上下文切换此处，那么我们可以在此界面进行如下配置 首先，在名称文本框中设置监控项的名称，我们此处监控的指标cpu上下文切换次数，所以，命名次监控项为“cpu context swiyches” 因为我们在“何金存”这台主机上安装了zabbix agent，所以，此处类型保持默认，选择zabbix客户端。 在键值一栏中，我们可以选择对应的key，也就是说，我们通过哪个key，这些key都是zabbix自带的key，这些key一般都是系统级别的通用的监控项所能够用到的key，如果这些“键”不能满足我们的需求，我们则需要自定义key，这是后话，后面再聊，此处，我们选择system/cpu.switches 选择完可以看见，key的值已经自动填充到了“键值”的文本框中 说到这，我们可以通过命令行，来看下对应的“键”返回信息到底是什么样子的？ 之前的我介绍过zabbix概念是已经说过：管理员可以在server端使用另一个名为zabbix_get的工具，测试是否能够从agent端拉取数据。 我们就是通过agent接口监控数据的，agent监听在10050端口上，此处保持默认即可。 而我们刚才也看到了，通过zabbix_get获取到的system.cpu.switches的数据，都是一些十进制的整数，所以，信息类型选择数字，数据类型选择十进制。 数据更新间隔表示每个多长时间获取一次监控项对应的数据，为了演示方便，能尽快获取到数据，我们设定位每隔30秒获取一次监控信息，此处表示每隔30秒获取一次47.97.172.176主机的cpu上下文切换次数 ，但是需要注意，在生产环境中，如果不是特别重要的、敏感的、迅速变化的数据，不要获取的这么频繁，因为如果我们的监控项变得特别多时，获取信息的时间间隔过于频繁会带来巨大的监控压力，同时对数据库的写入也是一种考验。 当然，我们也可以灵活的定义时间间隔，比如，周一到周五我们的业务量比较少，可以10分钟获取一次数据，而周六周日的业务量会剧增，为了实时监控，可以设置5分钟获取一次数据，这里只是举个例子，如果有类似的需求，可以通过“自定义事件间隔”配置段，添加不同时间段的不同检测频率。 因为我们每隔30秒就获取一次数据，那么这些数据都会变成历史，存入数据库中，通过上图中的开始数据文本框，可以设置历史数据的保存时长。 上图中，我们设置历史数据保存8天，趋势数据是什么意思呢？趋势数据就是每个小时收集到历史数。 从上图中，还可以看到有一个趋势数据保存天数，趋势数据是什么意思呢？趋势数据就是每个小时收集到的历史数据中的最大值、最小值，平均值以及每个小时收集的到的历史数据的数据量，所以，趋势数据每小时收集一次，数据量不会特别大，一般情况下，历史数据的保留时间都比趋势数据保留时间短很多，因为历史数据比较多，如果我们监控的主机非常多，而且监控的频率 特别频繁，那么数据库的压力则会变得非常大。 继续往下看，可以看到储存值于查看两个下拉框。 我们点开储存值下拉框，可以看到三个选项，不变、差量（每秒频率）、差量（简单变化） 那么这些值都是什么意思呢？ 不变：表示获取到的值是什么样子的，就在数据库中存储为什么样子。 差量（简单变化）：表示本次收集的信息值 减去 上一次收集到的信息值 得出的差值 差量（每秒速率）：表示本次收集到的值 减去 上次收集到的值以后，再除于两次收集信息的间隔时间。 而此处，我们监控的指标为cpu上下文切换次数，这是一个不断增长的整数值，所以，我们选择差量（每秒速率）最合适 这样发=我们就能 够监控到不同时间段内cpu上下文切换的频率了。 那么查看值 是什么意思呢？查看值可以改变监控数据的展示方式，以便监控人员更容易理解，此处我们保持默认即可，在实际用到是我们在做解释。 新的应用集 与 应用集 是什么意思呢？ 我们可以把“应用集”理解为同一类型的监控项的集合，“应用集”英文原词为application，application为一组item（监控项）的集合，比如，我们有3个监控项，他们分别监控“磁盘使用率”，“磁盘写入速率”，“磁盘读取速率”，虽然他们监控指标不同，但是他们都是监控“磁盘”的监控项 ，所以，我们可以把他们归类为“磁盘”应用集，同理，如果有2个监控项，一个是监控nginx连接数量的，一个是监控nginx请求数量的，虽然他们监控的指标不同，但是他们都是监控nginx相关指标的，所以，我们可以把他们归为nginx应用集。 但是，由于我们没有创建过任何应用集，所以上图中，应用集选择框中没有任何可选择应用集，如果没有可选的合适的应用集，我们可以直接在“新的应用”文本框中填入要创建的应用集名称，那么对应应用集会自动被创建当前监控项 也会自动归类为这个应用集。 继续聊，”填入主机资产纪录栏位”我们后面再聊。 描述信息栏填写关于这个监控项的相关描述。 “已启用”默认被勾选，表示此监控项被创建后，立即生效，即创建此监控项后立即开始监控。 好了，监控项的配置我们已经解释的七七八八了，示例配置如下，点击添加按钮, 注：为了更快的获取演示效果，此处将数据更新间隔设置为5秒，但是生产环境中请仔细考虑具体设置为多少秒比较适合生产环境的需求。 点击添加按钮以后，可以看到，何金存主机的第一个监控项已经被添加，而且处于已用状态。 点击监控项旁边的“应用集” 可以看到，应用集中已经存在了cpu应用集，而且这个应用集中已经存在一个监控项，就是我们刚才创建的”cpu context switches”监控项。 从对应的主机组中找到对应的主机， 点击过滤按钮之后，应该可以看到我们刚才创建的监控项，已经存在了部分数据，如果你刚刚创建完监控项，不要着急立马查看“监控项”数据，因为他可能需要一段时间收集数据。 但是，如果超出正常收集数据的时间后，很长时间以内仍然无法收集到数据，那么有可能 是因为agent端与server端时间不同步引起的，请确定你的agent端与server端的时间是同步的。 过程中出现了一个问题 这个问题，检查两处，如果其他问题也是首先想这两处。 1、防火墙是否关闭 2、进入/etc/zabbix/zabbix_agentd.conf配置文件，找到Server，把“127.0.0.1”改成监控服务器IP 好，接着往下看啊 可以看到，“cpu context switches”这个监控项已经存在数据，我们点击对应的“图形”连接 点击上图中的图形连接，可以看到如下界面，zabbix已经监控到了对应的cpu上下文切换频率，并且绘制出了对应的“图形” 如果没有图形就按照下图来操作即可。操作完之后还是没有图形，那就是没数据。 我们已经为主机添加了第一个监控项，并且已经成功监控到了对应的数据，好了，我们已经入门了。 本文参考网站 – http://www.zsythink.net/archives/447]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上传码云]]></title>
    <url>%2F2030%2F10%2F26%2F%E4%B8%8A%E4%BC%A0%E7%A0%81%E4%BA%91%2F</url>
    <content type="text"><![CDATA[【上传码云】命令 第一步，从自己的码云分支上拉下分支 12git clone https://git.oschina.net/shixunone-project/shixunone-nextcloud.git# https://git.oschina.net/shixunone-project/shixunone-nextcloud.git -&gt; 是你从码云项目上复制下来的 第二步，进入到下载下来的分支项目上 1cd shixunone-nextcloud 第三步，没有想上传的 django 项目的，就创建一个。有 你想传的 django 项目的话，就直接拉到这个文件夹即可 1django-admin startproject textpro1 （自己定义一个django项目名） 第四步，将 django 项目添加到码云 1git add 自己定义的django项目名 第五步，将项目提交到码云 1git commit -m &quot;这里的文字随便编写&quot; 第六步，直接将项目推送到码云 1git push]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下如何关闭某个被占用的端口]]></title>
    <url>%2F2030%2F10%2F25%2FLinux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%85%B3%E9%97%AD%E6%9F%90%E4%B8%AA%E8%A2%AB%E5%8D%A0%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[【 Linux 】如何关闭某个被占用的端口 1）查找被占用的端口 12abloume@ubuntu:~$ netstat -tln | grep 8000tcp 0 0 192.168.2.106:8000 0.0.0.0:* LISTEN 2）查看被占用端口的PID 123abloume@ubuntu:~$ lsof -i :8000COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEpython3 6072 root 4u IPv4 612939 0t0 TCP *:irdmi (LISTEN) 3）kill 掉该进程 1abloume@ubuntu:~$ kill 6072 # 6027 -&gt; 进程号PID]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VUE中父子组件传参]]></title>
    <url>%2F2030%2F10%2F15%2FVUE%E4%B8%AD%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E4%BC%A0%E5%80%BC%2F</url>
    <content type="text"><![CDATA[父子组件传值通过 props 实现，这种方式只能由父向子传递，子组件不能更新父组件内的datapro子组件传值通过 emit 实现 父组件给子组件传参：通过 props 方法传值,先定义一个子组件，在父组件中，引入子组件。这一步很简单，想必大家都会吧，这一步就不说了，直接上代码父组件写法： 1234567891011121314151617181920 &lt;template&gt; &lt;div&gt; &lt;div&gt;父组件&lt;/div&gt; &lt;child :message=&quot;parentMsg&quot;&gt;&lt;/child&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import child from &apos;./child&apos; //引入child组件export default &#123;components: &#123; child &#125;， data() &#123; return &#123; parentMsg: &apos;father&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 子组件写法： 1234567891011&lt;template&gt; &lt;div&gt; &lt;div&gt;&#123;&#123;message&#125;&#125;&lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; props: [&quot;message&quot;]&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 子组件给父组件传参：通过 emit 方法传值 vue文档中是这么解释的：如果子组件想要改变数据呢？这在vue中是不允许的，因为vue只允许单向数据传递，这时候我们可以通过触发事件来通知父组件改变数据，从而达到改变子组件数据的目的.子组件写法 123 &lt;template&gt; &lt;div @click=&quot;up&quot;&gt;&lt;/div&gt;&lt;/template&gt; 12345methods: &#123; up() &#123; this.$emit(&apos;upup&apos;,&apos;hehe&apos;); //主动(dispatch)触发upup方法，&apos;hehe&apos;为向父组件传递的数据 &#125;&#125; 父组件写法： 123&lt;div&gt; &lt;child @upup=&quot;change&quot; :msg=&quot;msg&quot;&gt;&lt;/child&gt; //监听子组件触发的upup事件,然后调用change方法&lt;/div&gt; 12345methods: &#123; change(msg) &#123; this.msg = msg; &#125;&#125;]]></content>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue中Axios配置]]></title>
    <url>%2F2030%2F10%2F11%2FVue%E4%B8%ADAxios%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Vue中Axios配置 导入：在vue文件main.js中写入（需要安装cnpm install --save axios） import axios from &apos;axios&apos; Vue.prototype.axios = axios 在 build 文件夹中的 webpack.base.conf 用 const createLintingRule = () =&gt; ({ // test: /\.(js|vue)$/, // loader: &apos;eslint-loader&apos;, // enforce: &apos;pre&apos;, // include: [resolve(&apos;src&apos;), resolve(&apos;test&apos;)], // options: { // formatter: require(&apos;eslint-friendly-formatter&apos;), // emitWarning: !config.dev.showEslintErrorsInOverlay // } }) 替换 第一种方法: proxyTable: { &apos;/api&apos;: { //使用&quot;/api&quot;来代替&quot;http://f.apiplus.c&quot; target: &apos;http://127.0.0.1:8000/&apos;, //源地址 changeOrigin: true, //改变源 pathRewrite: { &apos;^/api&apos;: &apos;&apos; //路径重写 } } } 第二种方法： 用Django的第三方包 django-cors-headers 来解决跨域问题 操作步骤： 1.pip install django-cors-headers 2.在settings.py中添加&apos;corsheaders.middleware.CorsMiddleware&apos;,在SessionMiddleware 和CommonMiddleware的中间 #允许谁请求 3.在settings.py中添加CORS_ORIGIN_ALLOW_ALL = True]]></content>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Md语法入门1]]></title>
    <url>%2F2030%2F10%2F10%2FMD%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[MD语法入门md即markdown文件的基本常用编写语法,是一种快速标记、快速排版语言，现在很多前段项目中的说明文件readme等都是用.md文件编写的，而且很多企业也在在鼓励使用这种编辑方式，特别作为一个前端从业者更要学会使用这种语言。下面就简单和大家分享一些.md基本语法 一、基本符号：* - + . &gt;基本上所有的markdown标记都是基于这四个符号或组合，需要注意的是，如果以基本符号开头的标记，注意基本符号后有一个用于分割标记符和内容的空格。 二、标题 前面带#号，后面带文字，分别表示h1-h6,只到h6，而且h1下面会有一条横线 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 相当于标签闭合 123456# 一级标题 ### 二级标题 ##### 三级标题 ####### 四级标题 ######### 五级标题 ########### 六级标题 ##### 效果如下： 一级标题二级标题三级标题四级标题五级标题六级标题三、列表 无序列表123456789101112//形式一+ a+ b+ c//形式二- d- e- f//形式三* g* h* i 以上三种形式，效果是这样的： a b c d e f g h i 注意，数字后面的点只能是英文的点 今天有点累，接下来的语法在我的个人博客里面，喜欢可以收藏一下。方便随时观看 老渔夫爱吃锅包肉]]></content>
      <tags>
        <tag>MD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建一个新的 Vue 项目]]></title>
    <url>%2F2030%2F10%2F09%2F%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84vue%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[创建一个新的 Vue 项目 - Vue init webpack 项目名 - 一路 yes 加 空格 - Npm run dev 启动项目 - vue中路由去“#”：mode: &apos;history&apos;,]]></content>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django与vue上传照片，通过 sqllite3 手动上传照片配置：]]></title>
    <url>%2F2030%2F10%2F08%2FMy-New-Post%2F</url>
    <content type="text"><![CDATA[django与vue上传照片，通过 sqllite3 手动上传照片配置： 第一步： 在项目文件夹中创建一个保存照片的文件夹，推荐用 ‘media’，因为后面会用到，现在记住了，后面也方便写。之后在 media 文件夹中再创建一个 ‘img’ 文件夹，负责保存照片 第二步： 在 settings 中配置：代码如下：123import osMEDIA_ROOT = os.path.join(BASE_DIR,&apos;media&apos;)# 通过 ImageField 上传文件，会自动到‘medtia’文件夹中 第三步： 创建表时，创建问价字段选择 ImageField 。 ImageField 其中有个必写的字段，那就是 ‘upload_to’，这个字段后面填的是数据库存储照片时的地址。代码如下：12img = models.ImageField(upload_to=&apos;img&apos;) # 这就是上面我们在 media 文件夹中创建 img 文件夹的原因 第四步： 配置路由，方便我们在vue中渲染数据 代码如下：1234from django.urls import path,re_path # 这个是我们创建django项目时自带的，只有后面的re_path是我们后加的from . import settingsfrom django.views.static import servere_path(&apos;^medtia/(?P&lt;path&gt;.*)/$&apos;,serve,&#123;&apos;document_root&apos;:settings.MEDTIA_ROOT&#125;) 在 vue 中我们该如何操作呢？ 看下面的代码吧： 12&lt;input type=&apos;file&apos; id=&apos;img&apos;&gt;&apos;&apos;&apos;在文件框中，用 id 属性绑定&apos;&apos;&apos; 下面的方法中，提取获取到的文件地址 1let img = document.getElementById(&apos;img&apos;).files[0] OK！完成，收工]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uwsgi + nginx + django部署]]></title>
    <url>%2F2030%2F08%2F20%2Fuwsgi%20%2B%20nginx%20%2B%20django%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[uwsgi + nginx + djangonginx配置123456789101112131415161718192021222324252627user root;worker_processes 1;error_log /usr/local/nginx/logs/error.log warn;pid /run/nginx.pid;events &#123; worker_connections 1024; # multi_accept on;&#125;http &#123; server &#123; listen 80; # 监听端口 server_name 47.96.189.157; # 访问路径名称 charset utf-8; # 编码 include /usr/local/nginx/conf/mime.types; access_log /home/qwe/rening/rening/nginx.log; location / &#123; include /usr/local/nginx/conf/uwsgi_params; uwsgi_connect_timeout 30; uwsgi_pass 0.0.0.0:8000; # 反向代理的UWSGI端口 &#125; location /static/ &#123; alias /home/qwe/rening/static/; # 项目的静态资源路径,固定写法 &#125; &#125;&#125; uwsgi配置123456789101112131415[uwsgi]#使用nginx连接时使用，Django程序所在服务器地址socket= 0.0.0.0:8000#项目目录chdir=/home/qwe/reningmodule=rening.wsgi:application#项目中wsgi.py文件的目录，相对于项目目录wsgi-file=rening/wsgi.py# 进程数processes=1# 线程数threads=2# uwsgi服务器的角色master=truepy-autoreload=1 django文件配置 子应用文件夹中添加uwsgi.ini文件，里面参考uwsgi配置 启动nginx命令 进入到nginx文件夹, 输入 1./nginx 启动uwsgi命令 进入项目文件夹, 输入 1uwsgi -d --ini uwsgi.ini]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB存储引擎]]></title>
    <url>%2F2030%2F07%2F15%2FInnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E(1)%2F</url>
    <content type="text"><![CDATA[InnoDB存储引擎InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有：1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键5、InnoDB被用在众多需要高性能的大型数据库站点上InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 MyISAM存储引擎MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有：1、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是164、最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上5、BLOB和TEXT列可以被索引6、NULL被允许在索引的列中，这个值占每个键的0~1个字节7、所有数字键值以高字节优先被存储以允许一个更高的索引压缩8、每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快9、可以把数据文件和索引文件放在不同目录10、每个字符列可以有不同的字符集11、有VARCHAR的表可以固定或动态记录长度12、VARCHAR和CHAR列可以多达64KB使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex） MEMORY存储引擎MEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有：1、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度2、MEMORY存储引擎执行HASH和BTREE缩影3、可以在一个MEMORY表中有非唯一键值4、MEMORY表使用一个固定的记录长度格式5、MEMORY不支持BLOB或TEXT列6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表）8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） Archive引擎Archive存储引擎只支持Insert和Select操作，在MySQL5.1之前也不支持索引。Archive引擎会缓存所有的写操作并利用zlib对插入的行进行压缩，所以比MyISAM表的磁盘I/O少。但是每次select查询都需要执行全表扫描。所以Archive表适合日志和数据采集类应用，这类应用做数据分析时往往需要权标骚婊。或者在一些需要更快速的insert操作的场合下也可以使用。 Archive引擎支持行级锁和专用的缓冲区，所以可以实现高并发的插入。在一个查询开始直到返回表中存在的所有行数之前，Archive引擎会组织其他的select执行，以实现一致性读。另外，也实现了批量插入在完成之前对读操作是不可见的。这种机制模仿了事物和MVCC的一些特性，但Archive引擎不是一个事物型的引擎，而是一个针对高速插入和压缩做了优化的简单引擎。 2 面向列的存储引擎MySQL默认是面向行的，每一行的数据时一起存储的，服务器的传也是以行为单位处理的。而在大数据量处理时，可能面向列的方式效率更高。如果不需要整行的数据，面向列的方式可以传输更少的数据。如果每一列都单独村吃醋，那么压缩的效率也会更高。I Infobright是最有名的面向列的存储引擎。在非常大的数据量时（数十TB），该引擎工作良好。Infobright是为数据分析和数据仓库应用设计的。数据高度压缩，按照块进行排序，每个块都对应有一组员数据。在处理查询时，访问元数据可以决定跳过该块进行排序，每个块都对应有一组元数据。在处理查询时，访问元数据可决定跳过该块，甚至可能只需要元数据就可以满足查询的需求。但该引擎不支持索引，不过在这么大的数据量级，即使有索引页很难发挥作用，而且块结构也会一种准索引（quasi-index）。Infobright需要对MySQL服务器做定制，因为一些地方需要修改以适应面向列的存储需要。如果查询无法在存储层使用面向列的模式执行，则需要在服务器层转换成按行处理，这个过程会很慢。Infobright有社区版和商业版两种。 另外一个面向列的存储引擎是Calpont公司的InfiniDB，也有社区版和商业版。InfiniDB可以在一组机器集群间做分布式查询，但目前还没有哦生产环境的应用案例。 3 社区存储引擎如果要列举所有社区提供的引擎可能会有三位数。但是很大部分影响力有限，只有极少数人在使用。在这里举例一些，但都没有在生产环境中应用过，慎用。 ① Aria：之前的名字是Maria，是MySQL创建者计划用来替代MyISAM的一款引擎。MariaDB包含了该引擎，之前计划开发的很多特性因为在MariaDB服务层实现，所以引擎层就取消了。在2013~2014年Aria就是解决了MyISAM的崩溃安全回复问题，当然还有一些特性是MyISAM不具备的，例如 数据的缓存（MyISAM只能缓存索引）。 ② Groonga：这是一款全文索引引擎，号称可以提供准确而高效的全文索引。 ③ OQGraph：该引擎由uOpen Query研发，支持图操作（例如查找两点之间最短的路径），用SQL很难实现该类操作。 ④ Q4M：该引擎在MySQL内部实现了队列操作，这也是SQL很难实现的操作。 ⑤ SphinxSE：该引擎为Sphinx全文索引搜索服务提供了SQL接口。 ⑥ Spider：该引擎可以将数据切分成不同的分区，比较高效透明的实现了分片（shard），并且可以针对分片执行并行查询（可以是分布式的分片）。 ⑦ VPForMySQL：改引擎支持垂直分区，通过一系列的代理存储引擎是新。垂直分区指的是可以将表分成不同列的这，并且单独存储。但对于查询来说，看到的还是一张表。改引擎和Spider的作者是同一人。 转换表的引擎下面接受三种Mysql 数据库将表的存储引擎转换成另外一种引擎。每种方法都有优缺点。 ALTER TABLE将表的一个引擎修改为另个引擎最简单的办法就是是用alter table 语句，需要执行很长时间。Mysql会按行讲源数据复制到另一新表当中，在复制期间可能会消耗系统所有的I/O能力，同时原表会加上锁。所以在繁忙的表上执行此操作要下心。如果转换表的存储引擎将会丢失和原引擎相关的所有特性。如，将一张InnoDB表转换为MyISAM，然后转换InnoDB，原InnoDB上的所有外键将会丢失。 导入和导出为了更好的控制转换过程，可是使用mysqldump 工具将数据导入文件中，然后修改文件中的create table 语句中的存储引擎选项，mysqldump 工具默认会在create table 中加上drop 语句。 创建和查询第三种装换技术综合了第一种的高效和第二种方法的中的安全，不需要导出真个表的数据。而是先创建一个新的存储引擎的表。然后利用 Insert 。。。。select 语句来导出， Mysql常见索引有：主键索引、唯一索引、普通索引、全文索引、组合索引 PRIMARY KEY（主键索引） ALTER TABLE table_name ADD PRIMARY KEY ( col ) UNIQUE(唯一索引) ALTER TABLE table_name ADD UNIQUE (col) INDEX(普通索引) ALTER TABLE table_name ADD INDEX index_name (col) FULLTEXT(全文索引) ALTER TABLE table_name ADD FULLTEXT ( col )组合索引 ALTER TABLE table_name ADD INDEX index_name (col1, col2, col3 ) Mysql各种索引区别：普通索引：最基本的索引，没有任何限制唯一索引：与”普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。主键索引：它 是一种特殊的唯一索引，不允许有空值。全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。组合索引：为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。创建复合索引时应该将最常用（频率）作限制条件的列放在最左边，依次递减。 where 字段从左往右顺序，数据量最少的字段放在最左边，因为这样查询次数会最少]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed]]></title>
    <url>%2F2030%2F07%2F15%2Fsed(1)%2F</url>
    <content type="text"><![CDATA[处理流程 sed（流处理编辑器），处理文本的过程如下： 1、从文本或者管道中读入一行内容到模式空间（临时缓冲区） 2、使用sed命令处理，重复第1步，直到文件处理完毕 3、输出到屏幕 注意两点： 1、sed一次处理一行的内容 2、sed默认的不改变文件内容 测试数据 1`[root@localhost ``test``]``# cat -n data.txt`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` 使用sed的格式 命令行格式：将包含sed的命令写在命令行中执行 1`$ ``sed` `[options] ``'command'` `files` 脚本格式：将sed的命令写在一个脚本中，然后执行的时候，指定sed脚本的路径即可 1`$ ``sed` `-f scriptfile files` 上面这两个命令中，files都是要进行处理的文件。 命令行格式1`$``sed` `[options] ``&apos;command&apos;` `files` options可以使用下面这几个值： -e：可以指定多个command -n：与p（print）命令合用时，表示只显示被选中的行，而不是显示所有的行，然后被选中的行会显示两次。 -i：将sed的操作结果更新到文件中，因为默认的是不会操作文件本身的。 command：行定位（正则）+ sed命令，首先会通过正则行定位，选中要进行操作的行，然后执行sed命令 行定位 选择1行，可以使用两种方式： 1、n； 选中1行，n表示行号 2、/root/ 使用正则表达式，注意要包含在/…./之间 1`[root@localhost ``test``]``# #打印第5行``[root@localhost ``test``]``# sed -n "5 p" data.txt``Maecheal 男 30 Washington America` `[root@localhost ``test``]``# #打印匹配"China"的记录``[root@localhost ``test``]``# sed -n "/china/ p" data.txt``[root@localhost ``test``]``# sed -n "/China/ p" data.txt``小红 女 20 BeiJing China``小明 男 22 ChongQing China``花花 女 30 HeBei China` 选择多行，同样有两种方式： 1、x,y； 选中行号在x~y之间的行 2、/小红/, /山本/ 选择匹配两个正则表达式之间的行 1`[root@localhost ``test``]``# #打印第3~6行``[root@localhost ``test``]``# cat -n data.txt | sed -n "3,6 p"`` ``3 花花 女 30 HeBei China`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan` `[root@localhost ``test``]``# #打印“Jane”的行，到“贝爷”之间的行``[root@localhost ``test``]``# sed -n "/Jane/, /贝爷/ p" data.txt``Jane 女 29 Los Angeles America``Maecheal 男 30 Washington America``山本 男 25 Nagasaki Japan``村上春树 男 40 Hiroshima Japan``贝爷 男 35 Paris Franch` 不选择某一行或者某几行 在后面加 ！ 即可 1`[root@localhost ``test``]``# #打印除了第4行以外的所有行``[root@localhost ``test``]``# cat -n data.txt | sed -n "4! p"`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #打印除3-7行之外的行``[root@localhost ``test``]``# cat -n data.txt | sed -n "3,7! p"`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``8 贝爷 男 35 Paris Franch` 间隔几行选择 使用x~y格式，首先打印第x行，然后每个y行，就打印一次 1`[root@localhost ``test``]``# #打印第3行，之后，每隔2行，就打印一次``[root@localhost ``test``]``# cat -n data.txt | sed -n "3~2 p"`` ``3 花花 女 30 HeBei China`` ``5 Maecheal 男 30 Washington America`` ``7 村上春树 男 40 Hiroshima Japan` 操作命令 sed有几个基本的操作命令，分别是下面几个： 1、-a (append，添加，在行后追加） 2、-i（insert，插入，在行前插入） 3、-d（delete，删除行） 4、-c（chage，替换） 5、-s（subsitute，替换） -a 增加行 1`[root@localhost ``test``]``# #在第3行后面增加一行“---------------”``[root@localhost ``test``]``# cat -n data.txt | sed "3a -------------"`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China``-------------`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` ` ` `[root@localhost ``test``]``# #在3~5行的每一行后面加一行“==========”``[root@localhost ``test``]``# cat -n data.txt | sed "3,5a =========="`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China``==========`` ``4 Jane 女 29 Los Angeles America``==========`` ``5 Maecheal 男 30 Washington America``==========`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #在每一行后面增加一行“===========”``[root@localhost ``test``]``# cat -n data.txt | sed "a =========="`` ``1 小红 女 20 BeiJing China``==========`` ``2 小明 男 22 ChongQing China``==========`` ``3 花花 女 30 HeBei China``==========`` ``4 Jane 女 29 Los Angeles America``==========`` ``5 Maecheal 男 30 Washington America``==========`` ``6 山本 男 25 Nagasaki Japan``==========`` ``7 村上春树 男 40 Hiroshima Japan``==========`` ``8 贝爷 男 35 Paris Franch``==========` `[root@localhost ``test``]``# #在行末增加一行“-------------------”``[root@localhost ``test``]``# sed '$a -------------------------' data.txt``小红 女 20 BeiJing China``小明 男 22 ChongQing China``花花 女 30 HeBei China``Jane 女 29 Los Angeles America``Maecheal 男 30 Washington America``山本 男 25 Nagasaki Japan``村上春树 男 40 Hiroshima Japan``贝爷 男 35 Paris Franch``-------------------------` -i 插入行 -i插入行和增加行的操作一样，区别是a是在行之后增加，i是在行之前插入 1`[root@localhost ``test``]``# #在第3行之前增加一行“---------------”``[root@localhost ``test``]``# cat -n data.txt | sed "3i --------------"`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China``--------------`` ``3 花花 女 30 HeBei China`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #在第3~5行的每一行之前插入一行"==========="``[root@localhost ``test``]``# cat -n data.txt | sed "3,5i ==========="`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China``===========`` ``3 花花 女 30 HeBei China``===========`` ``4 Jane 女 29 Los Angeles America``===========`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch``[root@localhost ``test``]``# #在每一行之前插入一行"==========="``[root@localhost ``test``]``# cat -n data.txt | sed "i ==========="``===========`` ``1 小红 女 20 BeiJing China``===========`` ``2 小明 男 22 ChongQing China``===========`` ``3 花花 女 30 HeBei China``===========`` ``4 Jane 女 29 Los Angeles America``===========`` ``5 Maecheal 男 30 Washington America``===========`` ``6 山本 男 25 Nagasaki Japan``===========`` ``7 村上春树 男 40 Hiroshima Japan``===========`` ``8 贝爷 男 35 Paris Franch` -c 替换行 替换行，是指，将指定行，整行内容都替换为指定内容，注意-s是指替换行中的一部分内容。 注意，区间替换的时候，是整体替换，而不是逐行替换。 1`[root@localhost ``test``]``# #将第2行替换为"hello shell"``[root@localhost ``test``]``# cat -n data.txt | sed "2c hello world"`` ``1 小红 女 20 BeiJing China``hello world`` ``3 花花 女 30 HeBei China`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #尝试将第2~5行的每一行都替换为"hello world"，但是实际操作后会将2-5行整体替换``[root@localhost ``test``]``# cat -n data.txt | sed "2,5c hello world"`` ``1 小红 女 20 BeiJing China``hello world`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #将每一行都替换为“hello world”``[root@localhost ``test``]``# cat -n data.txt | sed "c hello world"``hello world``hello world``hello world``hello world``hello world``hello world``hello world``hello world` -d 删除行1`[root@localhost ``test``]``# #删除第4行``[root@localhost ``test``]``# cat -n data.txt | sed "4d"`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #删除第4-6行``[root@localhost ``test``]``# cat -n data.txt | sed "4,6d"`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` `[root@localhost ``test``]``# #删除所有行（无意义）``[root@localhost ``test``]``# cat -n data.txt | sed "d"` -s 替换行的部分内容1`[root@localhost ``test``]``# #将字符a替换为X``[root@localhost ``test``]``# sed 's/a/X/' data.txt``小红 女 20 BeiJing ChinX``小明 男 22 ChongQing ChinX``花花 女 30 HeBei ChinX``JXne 女 29 Los Angeles America``MXecheal 男 30 Washington America``山本 男 25 NXgasaki Japan``村上春树 男 40 HiroshimX Japan``贝爷 男 35 PXris Franch` 注意，在替换的时候，只替换了一次，即只替换第一个匹配的内容。如果要将满足条件的内容都替换，就需要加上g 1`[root@localhost ``test``]``# sed &apos;s/a/X/g&apos; data.txt``小红 女 20 BeiJing ChinX``小明 男 22 ChongQing ChinX``花花 女 30 HeBei ChinX``JXne 女 29 Los Angeles AmericX``MXecheXl 男 30 WXshington AmericX``山本 男 25 NXgXsXki JXpXn``村上春树 男 40 HiroshimX JXpXn``贝爷 男 35 PXris FrXnch` sed试题 1、在文件的第8行下面增加一行“hello world”，并且hello world前面要有4个空格 1`[root@localhost ``test``]``# ifconfig eth0``eth0 Link encap:Ethernet HWaddr 00:0C:29:21:0C:0F`` ``inet addr:192.168.228.153 Bcast:192.168.228.255 Mask:255.255.255.0`` ``inet6 addr: fe80::20c:29ff:fe21:c0f``/64` `Scope:Link`` ``UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1`` ``RX packets:27644 errors:0 dropped:0 overruns:0 frame:0`` ``TX packets:14175 errors:0 dropped:0 overruns:0 carrier:0`` ``collisions:0 txqueuelen:1000`` ``RX bytes:22947297 (21.8 MiB) TX bytes:1135056 (1.0 MiB)` `[root@localhost ``test``]``# ifconfig eth0 | sed -n '/inet addr:/ p'`` ``inet addr:192.168.228.153 Bcast:192.168.228.255 Mask:255.255.255.0` `[root@localhost ``test``]``# ifconfig eth0 | sed -n '/inet addr:/ p' | sed 's/.*inet addr://'``192.168.228.153 Bcast:192.168.228.255 Mask:255.255.255.0` `[root@localhost ``test``]``# ifconfig eth0 | sed -n '/inet addr:/ p' | sed 's/.*inet addr://' | sed 's/B.*$//'``192.168.228.153` 高级sed操作 包括以下内容： 1、{command1; command2; command 3}多个sed命令，使用“；”分开 2、n表示跳1行 3、&amp;表示前面已经匹配的字符串内容，反向引用，不用再写一次正则表达式 多个sed命令 使用花括号{ }将多个sed命令包含在一起，多个sed之间用；分开 1`[root@localhost ``test``]``# cat -n data.txt`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch``[root@localhost ``test``]``# cat -n data.txt | sed '&#123;3,5 d; s/China/Chinese/&#125;'`` ``1 小红 女 20 BeiJing Chinese`` ``2 小明 男 22 ChongQing Chinese`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch` 跳行 打印奇数行和偶数行 1`[root@localhost ``test``]``# #打印奇数行``[root@localhost ``test``]``# cat -n data.txt | sed -n '1~2 p'`` ``1 小红 女 20 BeiJing China`` ``3 花花 女 30 HeBei China`` ``5 Maecheal 男 30 Washington America`` ``7 村上春树 男 40 Hiroshima Japan``[root@localhost ``test``]``# cat -n data.txt | sed -n '&#123;p; n&#125;'`` ``1 小红 女 20 BeiJing China`` ``3 花花 女 30 HeBei China`` ``5 Maecheal 男 30 Washington America`` ``7 村上春树 男 40 Hiroshima Japan``[root@localhost ``test``]``#``[root@localhost ``test``]``# #打印偶数行``[root@localhost ``test``]``# cat -n data.txt | sed -n '2~2 p'`` ``2 小明 男 22 ChongQing China`` ``4 Jane 女 29 Los Angeles America`` ``6 山本 男 25 Nagasaki Japan`` ``8 贝爷 男 35 Paris Franch``[root@localhost ``test``]``# cat -n data.txt | sed -n '&#123;n; p&#125;'`` ``2 小明 男 22 ChongQing China`` ``4 Jane 女 29 Los Angeles America`` ``6 山本 男 25 Nagasaki Japan`` ``8 贝爷 男 35 Paris Franch` 可以使用多个n来进行跳过 &amp;反向引用 &amp;表示前面已经匹配的字符串内容，反向引用，不用再写一次正则表达式 在男或者女之前加一个gender单词 1`[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[男|女]/gender:[男|女]/&apos;`` ``1 小红 gender:[男|女] 20 BeiJing China`` ``2 小明 gender:[男|女] 22 ChongQing China`` ``3 花花 gender:[男|女] 30 HeBei China`` ``4 Jane gender:[男|女] 29 Los Angeles America`` ``5 Maecheal gender:[男|女] 30 Washington America`` ``6 山本 gender:[男|女] 25 Nagasaki Japan`` ``7 村上春树 gender:[男|女] 40 Hiroshima Japan`` ``8 贝爷 gender:[男|女] 35 Paris Franch``[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[男|女]/gender:&amp;/&apos;`` ``1 小红 gender:女 20 BeiJing China`` ``2 小明 gender:男 22 ChongQing China`` ``3 花花 gender:女 30 HeBei China`` ``4 Jane gender:女 29 Los Angeles America`` ``5 Maecheal gender:男 30 Washington America`` ``6 山本 gender:男 25 Nagasaki Japan`` ``7 村上春树 gender:男 40 Hiroshima Japan`` ``8 贝爷 gender:男 35 Paris Franch` 案例1：将2.txt中的所有字母都变为大写 1`[root@localhost ``test``]``# cat -n data.txt`` ``1 小红 女 20 BeiJing China`` ``2 小明 男 22 ChongQing China`` ``3 花花 女 30 HeBei China`` ``4 Jane 女 29 Los Angeles America`` ``5 Maecheal 男 30 Washington America`` ``6 山本 男 25 Nagasaki Japan`` ``7 村上春树 男 40 Hiroshima Japan`` ``8 贝爷 男 35 Paris Franch``[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[A-Z]/\l&amp;/g&apos;`` ``1 小红 女 20 beijing china`` ``2 小明 男 22 chongqing china`` ``3 花花 女 30 hebei china`` ``4 jane 女 29 los angeles america`` ``5 maecheal 男 30 washington america`` ``6 山本 男 25 nagasaki japan`` ``7 村上春树 男 40 hiroshima japan`` ``8 贝爷 男 35 paris franch``[root@localhost ``test``]``# cat -n data.txt | sed &apos;s/[a-z]/\u&amp;/g&apos;`` ``1 小红 女 20 BEIJING CHINA`` ``2 小明 男 22 CHONGQING CHINA`` ``3 花花 女 30 HEBEI CHINA`` ``4 JANE 女 29 LOS ANGELES AMERICA`` ``5 MAECHEAL 男 30 WASHINGTON AMERICA`` ``6 山本 男 25 NAGASAKI JAPAN`` ``7 村上春树 男 40 HIROSHIMA JAPAN`` ``8 贝爷 男 35 PARIS FRANCH` -r 复制指定文件插入到匹配行1`[root@localhost ``test``]``# cat A.txt``111111``222222``333333``[root@localhost ``test``]``# cat B.txt``AAAAAAA``BBBBBBB``CCCCCCC` 将A.txt中的内容，插入到B.txt的第2行后面 1`[root@localhost ``test``]``# #将A.txt中的内容插入到B.txt中的第2行后面``[root@localhost ``test``]``# sed &apos;2 r A.txt&apos; B.txt``AAAAAAA``BBBBBBB``111111``222222``333333``CCCCCCC``[root@localhost ``test``]``# #将A.txt中的内容插入到B.txt中包含CCCCCC的行后面``[root@localhost ``test``]``# sed &apos;/CCCCCC/ r A.txt&apos; B.txt``AAAAAAA``BBBBBBB``CCCCCCC``111111``222222``333333``[root@localhost ``test``]``# #将A.txt中的内容插入B.txt中每一行的后面``[root@localhost ``test``]``# sed &apos;r A.txt&apos; B.txt``AAAAAAA``111111``222222``333333``BBBBBBB``111111``222222``333333``CCCCCCC``111111``222222``333333` -w 复制匹配行，拷贝到指定文件中 对于1.txt中选中的行，保存到文件2.txt中，会首先清空2.txt的内容，然后将选中的行拷贝出来，再保存到B.txt中。 1`[root@localhost ``test``]``# #将A.txt中的2-4行，写到C.txt中，注意会先清空C.txt``[root@localhost ``test``]``# sed &apos;2,4 w C.txt&apos; A.txt``111111``222222``333333``[root@localhost ``test``]``# cat C.txt``222222``333333` -q 提前退出sed sed的处理流程是：从文件中读入一行，然后sed处理一行，一直到文件结束为止。 使用q，可以让sed提前结束，不用读到文件结束。 1`[root@localhost ``test``]``# #打印前3行``[root@localhost ``test``]``# sed '3 q' data.txt``小红 女 20 BeiJing China``小明 男 22 ChongQing China``花花 女 30 HeBei China``[root@localhost ``test``]``#``[root@localhost ``test``]``# #找到第1个Japan``[root@localhost ``test``]``# sed '/Japan/ q' data.txt``小红 女 20 BeiJing China``小明 男 22 ChongQing China``花花 女 30 HeBei China``Jane 女 29 Los Angeles America``Maecheal 男 30 Washington America``山本 男 25 Nagasaki Japan`]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL的MEMORY引擎]]></title>
    <url>%2F2030%2F06%2F15%2Fmysql_memory%2F</url>
    <content type="text"><![CDATA[MEMORY 介绍 MEMORY存储引擎创建的表数据只能保存在内存。 memoery存储引擎是在内存中来创建表，每个memory表只实际对应一个磁盘文件格式是.frm. 该引擎的表访问非常得快，因为数据是放在内存中，且默认是hash索引，但服务关闭，表中的数据就会丢失掉。 MySQL宕机、硬件故障或者意外掉电，都会造成MEMORY引擎表丢失数据。所以，MEMORY表中的数据来源于其他表(可落盘永久保存)用于只读适用，或者用于临时工作起到数据周转。 服务器需要足够的内存来维护所有在同一时间使用的memory表，当不再需要时，要释放，应执行 delete from 或 truncate table 或删除表drop table。 每个memory表放置的数据量大小，受到max_heap_table_size系统变量的约束，初始值是16MB. 通过max_rows 子句指定表的最大行数。 MEMORY 引擎的特点 memeory存储引擎使用hash索引对于等值查找是很高效的 比较容易丢失数据 MEMORY 引擎适用的生产业务场景 临时使用、不重要的数据，例如网站的会话管理和缓存。可接受数据丢失可以用于存储在分析中产生的中间表使用memroy存储引擎的表一定要是可以再生的或者是不需要的 小结：据保存在ram(内存)中，访问速度快，但对表的大小有限制，要确保数据是可以恢复的，常用于更新不太频繁的小表，用以快速访问。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql MEMORY引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL存储引擎如何选择]]></title>
    <url>%2F2030%2F06%2F15%2Fmysql_select%2F</url>
    <content type="text"><![CDATA[定义以及作用 数据库引擎是用于存储、处理和保护数据的核心服务。 利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。 使用数据库引擎创建用于联机(客户端与服务端能够实时通信。由客户机发起，直到服务器确认。)事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）。 Mysql的存储引擎有哪些： InnoDB 这是MySQL 5.5或更高版本的默认存储引擎。它提供了事务安全(ACID兼容)表，支持外键引用完整性约束。它支持提交、回滚和紧急恢复功能来保护数据。它还支持行级锁定。当在多用户环境中使用时，它的“一致非锁定读取”提高了性能。它将数据存储在集群索引中，从而减少了基于主键的查询的I/O。 MyISAM 该存储引擎管理非事务性表，提供高速存储和检索，支持全文搜索。 MEMORY 提供内存中的表，以前称为堆。它在RAM中处理所有数据，以便比在磁盘上存储数据更快地访问。用于快速查找引用和其他相同的数据。 修改数据库引擎 方式壹： 修改配置文件my.ini 将mysql.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=Innodb,重启服务，数据库默认的引擎修改为Innodb 方式贰： 在建表得时候指定 create table table_name(你的各个字段名)type=MyISAM; 方式叁： 建表后更改 alert table table_name type=Innodb; 如何查看是否修改成功(查看当前数据库的引擎) 方式壹： show table status from table_name; 方拾贰： show create table table_name; 方式叁： 使用数据库管理工具(具体自己去问度娘)注意：不同版本之间有可能命令有些不同 MyISAM、InnoDB和MEMORY引擎之间的区别: InnoDB存储引擎 InnoDB给MySQL的表提供了事务处理、回滚、崩溃修复能力和多版本并发控制的事务安全。在MySQL从3.23.34a开始包含InnnoDB。它是MySQL上第一个提供外键约束的表引擎。而且InnoDB对事务处理的能力，也是其他存储引擎不能比拟的。靠后版本的MySQL的默认存储引擎就是InnoDB。 InnoDB存储引擎总支持AUTO_INCREMENT。自动增长列的值不能为空，并且值必须唯一。MySQL中规定自增列必须为主键。在插入值的时候，如果自动增长列不输入值，则插入的值为自动增长后的值；如果输入的值为0或空（NULL），则插入的值也是自动增长后的值；如果插入某个确定的值，且该值在前面没有出现过，就可以直接插入。 InnoDB还支持外键（FOREIGN KEY）。外键所在的表叫做子表，外键所依赖（REFERENCES）的表叫做父表。父表中被字表外键关联的字段必须为主键。当删除、更新父表中的某条信息时，子表也必须有相应的改变，这是数据库的参照完整性规则。 InnoDB中，创建的表的表结构存储在.frm文件中（我觉得是frame的缩写吧）。数据和索引存储在innodb_data_home_dir和innodb_data_file_path定义的表空间中。 InnoDB的优势在于提供了良好的事务处理、崩溃修复能力和并发控制。缺点是读写效率较差，占用的数据空间相对较大。 MyISAM存储引擎 MyISAM是MySQL中常见的存储引擎，曾经是MySQL的默认存储引擎。MyISAM是基于ISAM引擎发展起来的，增加了许多有用的扩展。 MyISAM的表存储成3个文件。文件的名字与表名相同。拓展名为frm、MYD、MYI。其实，frm文件存储表的结构；MYD文件存储数据，是MYData的缩写；MYI文件存储索引，是MYIndex的缩写。 基于MyISAM存储引擎的表支持3种不同的存储格式。包括静态型、动态型和压缩型。其中，静态型是MyISAM的默认存储格式，它的字段是固定长度的；动态型包含变长字段，记录的长度不是固定的；压缩型需要用到myisampack工具，占用的磁盘空间较小。 MyISAM的优势在于占用空间小，处理速度快。缺点是不支持事务的完整性和并发性。 MEMORY存储引擎 MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且数据全部放在内存中。这些特性与前面的两个很不同。 每个基于MEMORY存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为frm类型。该文件中只存储表的结构。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。值得注意的是，服务器需要有足够的内存来维持MEMORY存储引擎的表的使用。如果不需要了，可以释放内存，甚至删除不需要的表。 MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。 注意，MEMORY用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于MEMORY的表的生命周期很短，一般是一次性的 怎样选择合理的存储引擎 InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）。 MyISAM：插入数据快，空间和内存使用比较低。如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性、并发性要求比 较低，也可以使用。 MEMORY：所有的数据都在内存中，数据的处理速度快，但是安全性不高。如果需要很快的读写速度，对数据的安全性要求较低，可以选择MEMOEY。它对表的大小有要求，不能建立太大的表。所以，这类数据库只使用在相对较小的数据库表。 注意，同一个数据库也可以使用多种存储引擎的表。如果一个表要求比较高的事务处理，可以选择InnoDB。这个数据库中可以将查询要求比较高的表选择MyISAM存储。如果该数据库需要一个用于查询的临时表，可以选择MEMORY存储引擎。]]></content>
      <tags>
        <tag>Mysql存储引擎如何选择</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL的Innodb引擎]]></title>
    <url>%2F2030%2F06%2F15%2Fmysql_innodb%2F</url>
    <content type="text"><![CDATA[Innodb 介绍 InnoDB引擎的优点是支持兼容ACID的事务，以及参数完整性（即对外键的支持）。Oracle公司2005年10月收购了Innovase；mysql5.5.5之后数据库的默认存储引擎为InnoDB Innodb 的特点 1.支持事务，支持4个事务隔离级别，支持多版本读。2.行级锁定（更新时一般是锁定当前行），通过索引实现，全表扫描仍然会是表锁，注意间隙锁的影响。3.读写阻塞与事务隔离级别相关。4.具有非常高效的缓存特性：能缓存索引，也能缓存数据。5.整个表和主键以Cluster方式存储，组成一个平衡树。6.所有Secondary Index都会保存主键信息。7.支持分区，表空间，类似oracle数据库。8.支持外键约束，5.5之前不支持全文索引，5.5之后支持外键索引。9.和Myisam引擎比，Innodb对硬件资源要求比较高 InnoDB:支持行级锁(row-level locking)和表级锁,默认为行级锁。 Innodb 引擎适用的生产业务场景 1、需要事务支持的业务（具有较好的事务特性）2、行级锁定对高并发有很好的适应能力，但需要确保查询时通过索引完成。3、数据读写及更新都较为频繁的场景，如：bbs，sns，微博，微信等。4、数据一致性要求较高的业务，例如：充值转账，银行卡转账。5、硬件设备内存较大，可以利用Innodb较好的缓存能力来提高内存利用率，尽可能减少磁盘IO。 innodb_buffer_pool_size = 2048Minnodb_buffer_pool_size = 64M #InnoDB使用一个缓冲池来保存索引和原始数据，设置越大，在存取表里面数据时所需要的磁盘I/O越少。强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。16G内存多实例差不多给2G Innodb存储引擎 Innodb是事务型数据库的首选引，支持事物安全表(ACID) 事务的ACID属性：即原子性、一致性、隔离性、持久性 a.原子性：原子性也就是说这组语句要么全部执行，要么全部不执行，如果事务执行到一半出现错误，数据库就要回滚到事务开始执行的地方。 1实现：主要是基于MySQ日志系统的redo和undo机制。事务是一组SQL语句，里面有选择，查询、删除等功能。每条语句执行会有一个节点。例如，删除语句执行后，在事务中有个记录保存下来，这个记录中储存了我们什么时候做了什么事。如果出错了，就会回滚到原来的位置，redo里面已经存储了我做过什么事了，然后逆向执行一遍就可以了。 b.一致性：事务开始前和结束后，数据库的完整性约束没有被破坏。(eg:比如A向B转账，不可能A扣了钱，B却没有收到)c.隔离性：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰； 1234如果不考虑隔离性则会出现几个问题： a、脏读：是指在一个事务处理过程里读取了另一个未提交的事务中的数据（当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致）；（读取了另一个事务未提交的脏数据） aa、不可重复读：在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了；（读取了前一个事务提交的数据，查询的都是同一个数据项） aaa、虚读（幻读）：是事务非独立执行时发生的一种现象（eg:事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样）；（读取了前一个事务提交的数据，针对一批数据整体） d.持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚 MySQL数据库为我们提供的四种隔离级别： 1、Serializable（串行化）：可避免脏读、不可重复读、幻读的发生； 2、Repeatable read（可重复读）：可避免脏读、不可重复读的发生； 3、Read committed（读已提交）：可避免脏读的发生； 4、Read uncommitted（读未提交）：最低级别，任何情况都无法保证； 从1—-4隔离级别由高到低，级别越高，执行效率越低 InnoDB的存储文件有两个，后缀名分别是 .frm和 .idb；其中 .frm是表的定义文件， .idb是表的数据文件。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL的MyISAM引擎]]></title>
    <url>%2F2030%2F05%2F08%2Fmysql_myisam%2F</url>
    <content type="text"><![CDATA[MyISAM 介绍 myisam引擎是MySQL关系数据库系统的默认储存引擎（mysql 5.5.5之前）。这种MySQL表存储结构从旧的ISAM代码扩展出许多有用的功能。在新版本的Mysql中，Innodb引擎由于其对事务参照完整性，以及更高的并发性等优点开始逐步取代Myisam引擎。MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。 MySQL的MyISAM存储引擎支持压缩表空间，压缩后的表空间会减少，但是压缩后的表是只读的，不能插入和更新数据，如果需要更新，则需要解压后更新，再压缩 。 每一个myisam的表都对应于硬盘上的三个文件。这三个文件有一样的文件名，但是有不同的扩展名指示其类型用途：.frm文件保存表的定义，这个文件并不是myisam引擎的一部分，而是服务器的一部分；.MYD保存表的数据；.MYI是表的索引文件。.MYD和.MYI是MyISAM的关键点。 MyASAM 引擎的特点 1.不支持事务（事务是指逻辑上的一组操作，组成这组操作的各个单元，要么全成功要么全失败）2.表级锁定，数据更新时锁定整个表：其锁定机制是表级锁定，这虽然可以让锁定的实现成本很小但是也同时大大降低了其并发性能。3.读写互相阻塞：不仅会在写入的时候阻塞读取，myisam还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读。4.只会缓存索引：myisam可以通过key_buffer_size缓存索引，以大大提高访问性能，减少产品IO，但是这个缓存区只会缓存索引，而不会缓存数据。key_buffer_size = 16M5.读取速度较快，占用资源相对少。6.不支持外键约束，但支持全文索引。 MyISAM 引攀适用的生产业务场景， 1.不需要事务支持的业务（例如转账就不行）。2.一般为读数据比较多的应用，读写都频繁场景不适合，读多或者写多的都适合。3.读写并发访问相对较低的业务（纯读纯写高并发也可以）（锁定机制问题）4.数据修改相对较少的业务（阻塞问题）。5.以读为主的业务，例如：数据库系统表、www， blog ，图片信息数据库，用户数据库，商品库等业务。6.对数据一致性要求不是非常高的业务（不支持事务）。7.硬件资源比较差的机器可以用 MyiSAM （占用资源少）8.使用读写分离的 MySQL 从库可以使用 MyISAM。 小结：单一对数据库的操作都可以使用MyiSAM，所谓单一就是尽量纯读，或纯写 ( insert . update , delete ）等]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2030%2F03%2F30%2FDocker%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是Docker Docker是世界领先的软件容器平台。 Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docke最初实现是基于LXC。也就是说docker是宿主机上的一个独立隔离的进程。 Docker能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。 用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker与传统虚拟化方式区别：两者不同之处在于，传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整的操作系统，然后在该系统上运行所需应用进程。而docker容器内的应用进程直接直接运行于宿主机的内核，容器没有自己的内核，也没有自己的硬件虚拟。 Docker对比传统虚拟机总结 ：​ ![](C:\Users\张xiao\Pictures\Saved Pictures\docker.jpg) Docker的好处： Docker的镜像提供了除了内核外完整的运行环境，从而确保了应用运行环境的一致性。——一致的运行环境 可以做到秒级甚至毫秒级的启动速度，节约时间。——快速的启动速度 避免公用的服务器，资源会容易收到其他用户的影响。——隔离性 可以很轻易的移植到另一个平台上运行，不用担心运行环境的变化而导致应用无法正常运行。——迁移方便 Docker的三个基本概念：镜像 容器 仓库** 先来一句话总结下这三个之间的关系：镜像是Docker运行容器的前提，仓库是存放镜像的场所，可见镜像更是Docker的核心 1.镜像Docker的镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序，库，资源，配置等文件外，还包含了一些为运行时准备的一些配置参数（匿名卷，环境变量，用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 镜像就是一堆只读层的统一视角，下面这张图会帮你更好的理解： ![](C:\Users\张xiao\Pictures\Saved Pictures\1100338-20181010205425698-1711765011.png) 镜像构造时，会一层层构建，前一层是后一层的基础。除了最下面一层外，其他层都会有一个指针指向父层。每一层构建完之后就不会在发生改变，后一层上的任何改变都只会发生在自己这一层。比如，删除前一层的文件，实际并不会真正的删除前一层的文件，而是仅在当前层标记为已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。 Docker镜像分层存储的特征还使得镜像的复用，定制变得更加容易。我们可以用Dockerfile将之前构建好的镜像作为基础层，定制自己所需的内容，构造新的镜像。 2.容器容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一的区别就是容器最上一层是可读可写的。 也就是说：容器=镜像+读写层。但是这个定义并没有说出容器是否运行。 接下来说下运行态的容器： 一个运行时态的容器=一个可读写的统一文件系统加上隔离的进程空间和对应包含的子进程。 一个运行时的容器是这样的： ![](C:\Users\张xiao\Pictures\Saved Pictures\p.jpg) 它的所有都是建立在文件系统隔离系统之上的（Read Write File Systemctl），一个容器中的进程会对文件进行增删改查操作，这些改变都将应用于可读可写层（前面也提到了，容器就是镜像+读写层，所以对这一层读写层的改变不会影响原镜像的存储层。） ![](C:\Users\张xiao\Pictures\Saved Pictures\write.jpg) 可以运行一下命令来验证以上所说： docker run centos touch 1.txt 为了将这些零星的数据整合起来，提出了镜像层(image layer)的概念。下面这张图片就是一个镜像层。 ![](C:\Users\张xiao\Pictures\Saved Pictures\layer.jpg) 元数据（metadata）就是关于这个层的额外信息，它不仅能够让Docker获取运行和构建时的信息，还包括父层的层次信息。需要注意，只读层和读写层都包含元数据。 除此之外，每一层都包含了一个指向父层的指针，如果一个层没有指针，说明它处于最底层。 ![](C:\Users\张xiao\Pictures\Saved Pictures\zhizhen.jpg) Docker容器和镜像命令：docker create &lt;image-id&gt; docker create 命令为指定的镜像（image）添加了一个可读层，构成了一个新的容器。注意，这个容器并没有运行。 docker start &lt;container-id&gt; docker start命令为容器文件系统创建了一个进程隔离空间。注意，每一个容器只能够有一个进程隔离空间。 docker run &lt;image-id&gt; docker run 命令先是利用镜像创建了一个容器，然后运行这个容器。这个命令非常的方便 ,docker run 命令先是利用镜像创建了一个容器，然后运行这个容器。这个命令非常的方便 。 docker ps docker ps 命令会列出所有运行中的容器。这隐藏了非运行态容器的存在，如果想要找出这些容器，我们需要使用下面这个命令。 docker ps –a docker ps –a命令会列出所有的容器，不管是运行的，还是停止的。 docker images docker images命令会列出了所有顶层（top-level）镜像。实际上，在这里我们没有办法区分一个镜像和一个只读层，所以我们提出了top-level镜像。只有创建容器时使用的镜像或者是直接pull下来的镜像能被称为顶层（top-level）镜像，并且每一个顶层镜像下面都隐藏了多个镜像层。 docker rm &lt;container-id&gt; docker rm命令会移除构成容器的可读写层。注意，这个命令只能对非运行态容器执行。 docker rmi &lt;image-id&gt; docker rmi 命令会移除构成镜像的一个只读层。你只能够使用docker rmi来移除最顶层（top level layer）（也可以说是镜像），你也可以使用-f参数来强制删除中间的只读层。 docker commit &lt;container-id&gt; docker commit命令将容器的可读写层转换为一个只读层，这样就把一个容器转换成了不可变的镜像。 docker build docker build命令非常有趣，它会反复的执行多个命令。 ![](C:\Users\张xiao\Pictures\Saved Pictures\for.jpg) 我们从上图可以看到，build命令根据Dockerfile文件中的FROM指令获取到镜像，然后重复地1）run（create和start）、2）修改、3）commit。在循环中的每一步都会生成一个新的层，因此许多新的层会被创建。 关于Docker中的网络]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reids持久化]]></title>
    <url>%2F2030%2F03%2F26%2Fredis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[什么叫持久化？用一句话可以将持久化概括为：将数据（如内存中的对象）保存到可永久保存的存储设备中。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、 XML 数据文件中等等。 从应用层与系统层理解持久化 同时，也可以从应用层和系统层这两个层面来理解持久化： 应用层：如果关闭( Close )你的应用然后重新启动则先前的数据依然存在。 系统层：如果关闭( Shutdown )你的系统（电脑）然后重新启动则先前的数据依然存在。 说白了，就是在指定的时间间隔内,将内存当中的数据快照写入磁盘,它恢复时是拷快照文件直接读到内存 什么意思呢? 我们都知道, 内存当中的数据, 如果我们一断电,那么数据必然会丢失,但是玩过redis的同学应该都知道,我们一关机之后再启动的时候数据是还在的,所以它必然是在redis启动的时候重新去加载了持久化的文件 redis提供两种方式进行持久化 一种是RDB持久化默认, 另一种 AOF (append only file) 持久化. Redis 为什么要持久化？Redis 中的数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis 支持各种不同方式的排序。与 Memcached 一样，为了保证效率，数据都是缓存在内存中。 对，数据都是缓存在内存中的，当你重启系统或者关闭系统后，缓存在内存中的数据都会消失殆尽，再也找不回来了。所以，为了让数据能够长期保存，就要将 Redis 放在缓存中的数据做持久化存储。 redis持久化的意义，在于故障恢复比如你部署了一个redis，作为cache缓存，当然也可以保存一些较为重要的数据 如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据 如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的 1.RDB是什么？ 原理是redis会单独创建(fork函数)（复制）一个与当前进程一模一样的子进程来进行持久化,这个子线程的所有数据(变量,环境变量,程序,程序计数器等)都和原进程一模一样,会先将数据写入到一个临时文件中,待持久化结束了,再用这个临时文件替换上次持久化好的文件,整个过程中,主进程不进行任何的IO操作,（用到了fork子进程来进行持久化）这就确保了极高的性能 1.这个持久化文件在哪里 vi /usr/local/redis/etc/redis.conf 找dbfilename dump.rdb 默认就是dump.rdb dir ./ (包括很多例如redis实例，只要是redis产生的实例都会丢到) ./ ===== 哪里启动，哪里生成。 注意： 要么写死目录 要么启动的位置就在同一个地方，地方不一样可能造成数据丢失。 2.他是什么时候fork子进程，或者什么时候触发rdb持久化机制 11./usr/local/redis/bin/redis-cli 12.SHUTDOWN 1/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf ## 开启redis shutdown时,如果没有开启aof,会触发 配置文件中默认的快照配置 执行命令save成者bgsave , save是只管保存,其他不管,全部阻塞 redis会在后台异步进行快照操作, 同时可以响应客户端的请求(默认调用bgsave来进行持久化) 1rm -f ./dump.rdb 12/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf ## 开启redis 12/usr/local/redis/bin/redis-cli ## 连接客户端 1set k1 v1 1keys * 1save ## dump.rdb 是只管保存,其他不管,全部阻塞 1bgsave ## dump.rdb redis会在后台异步进行快照操作 执行flushall命令但是里面是空的,无意义 1FLUSHALL ## 清空 在redis.conf中rdb持久化策略 集群save 900 1 ## 900秒之内执行了一次增删改操作就会触发 ， 查不算 save 300 10 save 60 10000 默认配置 redis 性能调优 集群 master节点肯定会把rdb 实际上关不掉的在主从复制上 要么就是就写一个save 要么就注掉 2.aof执行set k1 v1 保存命令 123set k1 v1set k2 v1 ## 保存到文件中 保存的是命令 是什么？ 原理是将Reids的操作日志以追加的方式写入文件,读操作是不记录的 1.这个持久化文件在哪里 产生的位置还是 ./dir 1vi /usr/local/redis/etc/redis.conf 1appendfilename "appendonly.aof" ## 文件名 redis 默认关闭，开启需要手动把no改为yes 1appendonly yes 1/usr/local/redis/bin/redis-cli 1set k1 v1 1SHUTDOWN 12/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf ## 开启redis 1ll ‘*’ 开头代表下面有两组命令 $ 字符串的长度 日志追加的方式保存到文件里。 2.触发机制（根据配置文件配置项） AOF_FSYNC_NO:表示等操作系统进行数据缓存同步到磁盘(快,持久化没保证) —–不能配置不可控 AOF_FSYNC_ALWAYS: 同步持久化,每次发生数据变更时,立即记录到磁盘(慢,安全) —-消耗性能 AOF_FSYNC_EVERYSEC: 表示每秒同步一次(默认值很快,但可能会丢失一秒以内的数据)–所以默认 同步策略在了解同步策略之前，需要先来了解两个三方法flushAppendOnlyFile、write和save： redis的服务器进程是一个事件循环，文件事件负责处理客户端的命令请求，而时间事件负责执行serverCron函数这样的定时运行的函数。在处理文件事件执行写命令，使得命令被追加到aof_buf中，然后在处理时间事件执行serverCron函数会调用flushAppendOnlyFile函数进行文件的写入和同步 write：根据条件，将aof_buf中的缓存写入到AOF文件 save：根据条件，调用fsync或fdatasync函数将AOF文件保存到磁盘 下面来介绍Redis支持的三种同步策略： AOF_FSYNC_NO：不保存（write和read命令都由主进程执行） AOF_FSYNC_EVERYSEC：每一秒钟保存一次（write由主进程完成，save由子进程完成） AOF_FSYNC_ALWAYS：每执行一个命令保存一次（write和read命令都由主进程执行） AOF_FSYNC_NO在这种策略下，每次flushAppendOnlyFile函数被调用的时候都会执行一次write方法，但是不会执行save方法。 只有下面三种情况下才会执行save方法： Redis被关闭 AOF功能被关闭 系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行） 这三种情况下的save操作都会引起Redis主进程阻塞，并且由于长时间没有执行save命令，所以save命令执行的时候，阻塞时间会很长 AOF_FSYNC_EVERYSEC在这种策略下，save操作原则上每隔一秒钟就会执行一次， 因为save操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。 其实根据Redis的状态，每当 flushAppendOnlyFile函数被调用时，write命令和save命令的执行又分为四种不同情况： 根据以上图知道，在AOF_FSYNC_EVERYSEC策略下， 如果在情况1时发生故障停机， 那么用户最多损失小于2秒内所产生的数据；而如果在情况2时发生故障停机，堆积了很多save命令，那么用户损失的数据是可以超过 2 秒的。 AOF_FSYNC_ALWAYS在这种模式下，每次执行完一个命令之后，write和save命令都会被执行。 另外，因为save命令是由Redis主进程执行的，所以在save命令执行期间，主进程会被阻塞。 三种策略的优缺点AOF_FSYNC_NO策略虽然表面上看起来提升了性能，但是会存在每次save命令执行的时候相对长时间阻塞主进程的问题。并且数据的安全性的不到保证，如果Redis服务器突然宕机，那么没有从AOF缓存中保存到硬盘中的数据都会丢失。 AOF_FSYNC_ALWAYS策略的安全性的到了最大的保障，理论上最多丢失最后一次写操作，但是由于每个写操作都会阻塞主进程，所以Redis主进程的响应速度受到了很大的影响。 AOF_FSYNC_EVERYSEC策略是比较建议的配置，也是Redis的默认配置，相对来说兼顾安全性和性能。 AOF执行流程 所有的写命令都会追加到aof_buf（缓冲区）中。 可以使用不同的策略将AOF缓冲区中的命令写到AOF文件中。 随着AOF文件的越来越大，会对AOF文件进行重写。 当服务器重启的时候，会加载AOF文件并执行AOF文件中的命令用于恢复数据。 简单分析一下AOF执行流程中的一些问题： 因为Redis为了效率，使用单线程来响应命令，如果每次写命令都追加写硬盘的操作，那么Redis的响应速度还要取决于硬盘的IO效率，显然不现实，所以Redis将写命令先写到AOF缓冲区。 写道缓冲区还有一个好处是可以采用不同的策略来实现缓冲区到硬盘的同步，可以让用户自行在安全性和性能方面做出权衡。 3.aof重写机制我们以日志的方式,记录我们的命令记录到文件当中 如果我操作的特别频繁，文件肯定会特别大。 我写100万数据，持久化文件也会特别大 1/usr/local/redis/bin/redis-cli 1FLUSHALL ## 清空数据 1keys * ## 查看是否有数据 1INCR lock ## 加操作 1exit ## 退出 1vi appendonly.aof ## 查看文件 记录着 我可以直接执行一条命令set lock 11 重写就是将重复的剔除掉瘦身 1/usr/local/redis/bin/redis-cli 1BGREWRITEAOF ##手动调用重写命令 1exit ## 退出 1vi dump.rdb 是因为我这个版本是5.0的 当AOF文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当AOF文件大小的增长率大于该配置项时自动开启重写(这里指超过原大小的100%) . auto-aof-rewrite-percentage 100 当AOF文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写,当AOF文件大小大于该配置项时自动开启重写 auto-aof-rewrite-min-size 64mb incr lock 重写就是将重复的剔除掉瘦身 4.redis4.0后混合持久化机制开启混合持久化 4.0 版本是 像set lock 11 4.0版本的混合持久化默认关闭的,通过aof-use-rdb-preamble配置参数控制, yes则表示开启, no表示禁用, 5.0之后默认开启。 混合持久化是通过bgrewriteaof完成的,不同的是当开启混合持久化时, fork出的子进程先将共享的内存副本全量 以RDB方式写入aof文件,然后在将重写缓冲区的增量命令以AOF方式写入到文件,写入完成后通知主进程更新统计信息,并将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。 简单的说:新的AOF文件前半段是 RDB格式的全量数据后半段是AOF格式的增量数据, 优点:混合持久化结合了RDB持久化和AOF持久化的优点由于绝大部分都是RDB格式,加载速度快,同时结合 AOF,增量的数据以AOF方式保存了,数据更少的丢失. 缺点:兼容性差,一旦开启了混合持久化,在4.0之前版本都不识别该aof文件,同时由于前部分是RDB格式,阅读性较差 二进制方式存储 更小 什么时候下会自动重写 看 auto-aof-rewrite-percentage auto-aof-rewrite-min-size 小总结：1.redis提供了rdb持久化方案，为什么还要aof？ rdb 是跟据save触发持久化，所以会照成数据的丢失 aof持久化是1秒执行一次 在数据aof 在性能rdb高于aof 优化数据丢失问题，rdb会丢失最后一次快照后的数据，aof丢失不会超过2秒的数据 2.如果aof和rdb同时存在，听谁的？ aof数据准确率更高 3.rdb和aof优势劣势 rdb适合大规模的数据恢复,对数据完整性和一致性不高，在一定间隔时间做一次备份,如果redis意外宕机的话,就会丢失最后一次快照后的所有操作 aof根据配置项而定 1.官方建议两种持久化机制同时开启,如果两个同时开启优先使用aof久化机制 在生产环境中用集群，哨兵什么的 主机开aof 性能建议（这里只针对单机版redis持久化做性能建议）： 因为RDB文件只用作后备用途,只要15分钟备份一次就够了,只保留save 900 1这条规则. 因为开启aof持久化安全。 如果Enalbe AOF, 好处是在最恶劣情况下也只会丢失不超过两秒数据,启动脚本较简单只load自己的AOF文件就可以了. 代价一是带来了持续的IO,二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。 只要硬盘许可,应该尽量减少AOF rewrite的频率, AOF重写的基础大小默认值64M太小了,可以设到5G以上.默认超过原大小100%大小时重写可以改到适当的数值。 看硬盘 1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。 2）AOF关闭或者AOF文件不存在时，加载RDB文件。 3）加载AOF/RDB文件成功后，Redis启动成功。 4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。 1.从主进程中fork出子进程，并拿到fork时的AOF文件数据写到一个临时AOF文件中 2.在重写过程中，redis收到的命令会同时写到AOF缓冲区和重写缓冲区中，这样保证重写不丢失，重写过程中的命令 3.重写完成后通知主进程，主进程会将AOF缓冲区中的数据追加到子进程生成的文件中 4.redis会原子的将旧文件替换为新文件，并开始将数据写入到新的aof文件上 执行bgrewriteaof命令的时候，如果当前有进程正在执行AOF重写，那么直接返回；如果有进程正在执行bgsave，那么等待bgsave执行完毕再执行AOF重 Redis主进程会fork一个子进程执行AOF重写。 AOF重写过程中，不影响Redis原有的AOF过程，包括写消息到AOF缓存以及同步AOF缓存中的数据到硬盘。 AOF重写过程中，主进程收到的写操作还会将命令写到AOF重写缓冲区，注意和AOF缓冲区分开。 由于AOF重写过程中原AOF文件还在陆续写入数据，所以AOF重写子进程只会拿到fork子进程时的AOF文件进行重写。 子进程拿到原AOF文件中的数据写道一个临时的AOF文件中。 子进程完成AOF重写后会发消息给主进程，主进程会把AOF重写缓冲区中的数据写道AOF缓冲区，并且用新的AOF文件替换旧的AOF文件。 总结 Redis 默认开启RDB持久化方式，在指定的时间间隔内，执行指定次数的写操作，则将内存中的数据写入到磁盘中。 RDB 持久化适合大规模的数据恢复但它的数据一致性和完整性较差。 Redis 需要手动开启AOF持久化方式，默认是每秒将写操作日志追加到AOF文件中。 AOF 的数据完整性比RDB高，但记录内容多了，会影响数据恢复的效率。 Redis 针对 AOF文件大的问题，提供重写的瘦身机制。 若只打算用Redis 做缓存，可以关闭持久化。 若打算使用Redis 的持久化。建议RDB和AOF都开启。其实RDB更适合做数据的备份，留一后手。AOF出问题了，还有RDB。 RDB和AOF的优缺点 RDB的优缺点： 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数 据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。 RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。 RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。 AOF的优缺点： AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。 AOF 日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损。 如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据 一致性的问题。 AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。 因此在进行rewrite切换时可以更好的保证数据安全性。 AOF以一个格式清晰、易于理解的日志文件用于记录所有的修改操作， 非常适合做灾难性的误删除的紧急恢复。 比如有人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条flushall命令给删了，然后再将该aof文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低， 因为 AOF 一般会配置成每秒 fsync 一次日志文件。 类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。 如何选择？ RDB和AOF如何选择？ 不要仅仅使用 RDB，因为那样会导致你丢失很多数据； 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug； redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。]]></content>
      <tags>
        <tag>Reids</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reids主从]]></title>
    <url>%2F2030%2F03%2F15%2F%E5%A4%9A%E7%BA%A7redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[[TOC]Reids主从参考链接： Redis主从复制和哨兵 参考1 Redis主从复制和哨兵 参考2 Redis主从架构和主从从架构集群搭建详细步骤 Redis主从复制原理 Redis复制官方文档翻译 ​ 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 ​ 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主从复制的作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从拓扑结构​ 一主一从： 这一结构主要用于主节点故障从节点，当主节点的“写”命令并发高且需要持久化，可以只在从节点开启AOF（主节点不需要），这样即保证了数据的安全性，也避免持久化对主节点的影响。 ​ 一主多从： 这一结构主要针对“读”较多的场景，“读”由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定。 ​ 树状主从: 这一结构是对一主多从的补充，主节点只推送一次数据到slave1和slave2，再由从slave2推送到slave3和 slave4，减轻主节点推送的压力。 主从复制的实现原理主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段； 连接建立阶段step1：保存主节点信息​ 从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。 ​ slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 step2：建立socket连接​ 从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。 如果连接成功： ​ 从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 ​ 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 step3：发送ping命令​ 从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： 返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 step4：身份验证如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。 从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 step5：发送从节点端口信息身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步阶段主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。 具体执行的方式是：从节点向主节点发送psync命令，开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。 在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 命令传播阶段​ 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 ​ 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 PS： ​ 延迟与不一致：命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 ​ repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 【数据同步阶段】全量复制和部分复制在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制； 在Redis2.8以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。 全量复制Redis通过psync命令进行全量复制的过程如下： 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制； 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。 主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。 如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。 通过全量复制的过程可以看出，全量复制是非常重型的操作： 主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的； 主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗。 从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗。 部分复制​ 由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。 ​ 部分复制的实现，依赖于三个重要的概念：复制偏移量，复制积压缓冲区，服务器运行ID offset 复制偏移量​ 在主从复制的Master(主节点)和Slave(从节点)双方都会各自维持一个offset，代表的是主节点向从节点传递的字节数；Master成功发送N个字节的命令后会将Master的offset加上N，Slave在接收到N个字节命令后同样会将Slave的offset增加N。Master和Slave如果状态是一致的那么它的的offset也应该是一致的。 ​ offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。 复制积压缓冲区 复制积压缓冲区是由Master(主节点)维护的一个固定长度的FIFO队列(先进先出)，默认大小1MB；当主节点开始有从节点时创建，它的作用是缓存已经传播出去的命令。当Master进行命令传播时，不仅将命令发送给所有Slave，还会将命令写入到复制积压缓冲区里面。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。 ​ 除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 ​ 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制： 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制； 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。 runid 服务器运行ID​ 每个Redis服务器(无论主从)在启动时都会自动生成一个表明自己身份的随机ID(每次启动都不一样)，由40个随机的十六进制字符组成。在PSYNC中发送的这个ID是指之前连接的Master的ID，如果没保存这个ID，PSYNC命令会使用”PSYNC ? -1” 这种形式发送给Master，表示需要全量复制。 ​ 每个Redis节点，在启动时都会自动生成一个随机ID，由40个随机的十六进制字符组成； runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。 ​ 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点； 主节点根据runid判断能否进行部分复制： 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)； 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 PSYNC命令 Redis在2.8版本提供了PSYNC命令来带代替SYNC命令，为Redis主从复制提供了部分复制的能力。 PSYNC命令格式123PSYNC &lt;runid&gt; &lt;offset&gt;# runid:主服务器ID# offset:从服务器最后接收命令的偏移量 PSYNC执行过程中比较重要的概念有3个：runid、offset（复制偏移量）以及复制积压缓冲区。 psync命令的执行 首先从节点根据当前状态，决定如何调用psync命令： 如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制； 如果从节点之前执行了slaveof，则发送命令为 psync **，其中runid为上次复制的主节点的runid，offset**为上次复制截止时从节点保存的复制偏移量。 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制： 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制； 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可； 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC ，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 【命令传播阶段】心跳机制在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。 主-&gt;从：PING每隔指定的时间，主节点会向从节点发送PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。 PING发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是10s。 从-&gt;主：REPLCONF ACK在命令传播阶段，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次； 命令格式为： 1REPLCONF ACK &#123;offset&#125; # offset指从节点保存的复制偏移量。 REPLCONF ACK命令的作用包括： 实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1。 检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。 注意：offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。 辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。 开启主从复制从节点开启主从复制，有3种方式： 配置文件：在从服务器的配置文件中加入：slaveof 启动命令：redis-server启动命令后加入： –slaveof 客户端命令：Redis服务器启动后，直接通过客户端执行命令：slaveof ，则该Redis实例成为从节点。 修改配置文件方法：1. 配置从服务配置文件redis.conf1234567slaveof 192.168.1.9 6379 #添加属于某台主机的从 服务masterauth 123456 #从服务连接主服的密码（访问主服务器的密码）slave-read-only yes #从服务只读，不可在命令行写入数据5.0.4以后：replicaof &lt;masterip&gt; &lt;masterport&gt;replica-read-only yes 2. 重新启动从服务即实现主从连接121. ./bin/redis-cli # 启动redis客户端2. 输入 info replication # 查看与复制相关的状态，了解主从节点的当前状态 输入info replication 后显示的内容： 12345678910111213141516171819# Replicationrole:slave # 表示此台服务器是主是从master_host:39.107.38.62 # 主服务器ipmaster_port:6379 # 主服务器端口号master_link_status:up # 与主服务器是否连接成功 up为成功 down失败master_last_io_seconds_ago:9master_sync_in_progress:0slave_repl_offset:808slave_priority:100slave_read_only:1connected_slaves:0master_replid:ea5230cc485f9c6f372b2c89a65613fb075aff8bmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:808second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:15repl_backlog_histlen:794 遇到的报错：1. Error condition on socket for SYNC: Connection refused 出现原因： ​ redis主服务器绑定了127.0.0.1，跨服务器IP的访问就会失败，只能本机才能访问，外部请求会被过滤。 1234解决方法：1. 主服务器绑定ip: bind 39.107.38.623. bind 0.0.0.02. 注释bind # 会报下面的错↓ 2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec 出现原因： ​ 处于保护模式，只能本地链接。没有绑定ip 没有设置验证密码。 123解决方法：1. 主服务器绑定ip： bind 39.107.38.622. 设置主服务器访问密码：requirepass 12345 3. (error) READONLY You can’t write against a read only replica.​ 出现原因： ​ 从库只可读不可写 12解决方法：1. 设置slave-read-only no # 代表不限于只读 断开主从复制​ 通过slaveof 命令建立主从复制关系以后，可以通过slaveof no one断开。 从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。]]></content>
      <tags>
        <tag>Reids</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql事务]]></title>
    <url>%2F2030%2F03%2F04%2Fmysql%E4%BA%8B%E5%8A%A1%E7%89%B9%E6%80%A7%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1.1.2、事务的特性 原子性 事务中的全部操作在数据库中是不可分割的，要么全部完成，要么全都不完成 一致性 几个并行执行的事务，其执行结果必须与按某一顺序串行执行的结果相一致 隔离性 事务的执行不受其他事务的干扰，事务执行的中间结果对其他事务必须是透明的 持久性 一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作 1.1.3、事务隔离级别 未提交读：脏读（READ UNCOMMITTED） 事务2查询到的数据是事务1中修改但未提交的数据，但因为事务1回滚了数据 所以事务2查询的数据是不正确的，因此出现了脏读的问题 READ UNCOMMITTED（读未提交） 该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为脏读。 两个命令行客户端分别为A，B；不断改变A的隔离级别，在B端修改数据。 1234567891011121314151617181920212223242526将A的隔离级别设置为read uncommitted(未提交读)A：SET @@session.transaction_isolation = &apos;READ-UNCOMMITTED&apos;;创建一张testcreate database test;use test;create table test(id int primary key);insert into test(id) values(1);A：启动事务，此时数据为初始状态start transaction;B：启动事务，更新数据，但不提交start transaction;update test set id = 2 where id = 1;A：再次读取数据，发现数据已经被修改了，这就是所谓的“脏读select * from test;B:回滚事务rollback;A:再次读数据，发现数据变回初始状态select * from test; 提交读：不可重复读（READ COMMITTED） 注：一个事务从开始到提交之前对数据所做的改变对其他事务是不可见的，这样就解决在READ-UNCOMMITTED级别下的脏读问题。 事务2执行update语句但未提交前，事务1的前两个select操作返回结果是相同的 但事务2执行commit操作后，事务1的第三个select操作就读取到事务2对数据的改变 导致与前两次select操作返回不同的数据，因此出现了不可重复读的问题 READ COMMITTED（提交读） 一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，此现象称为不可重复读问题，Oracle 和 SQL Server 的默认隔离级别。 123456789101112131415161718192021222324A:将客户端A的事务隔离级别设置为read committed(已提交读)SET @@session.transaction_isolation = &apos;READ-COMMITTED&apos;;创建test表create database test;use test;create table test(id int primary key);insert into test(id) values(1);A：启动事务，此时数据为初始状态start transaction;B：启动事务，更新数据，但不提交start transaction;update test set id = 2 where id = 1;A：再次读数据，发现数据未被修改select * from test;B：提交事务commit;A：再次读取数据，发现数据已发生变化，说明B提交的修改被事务中的A读到了，这就是所谓的“不可重复读”select * from test; 可重复读：幻读（REPEATABLE READ）：这是MySQL的默认事务隔离级别 事务每开启一个实例，都会分配一个版本号给它，如果读取的数据行正在被其他事务执行DELETE或UPDATE操作（既该行上有排他锁） 这时该事务的读取操作不会等待行上的锁释放，而是根据版本号去读取行的快照数据（记录在undo log中） 这样，事务中的查询操作返回的都是同一版本下的数据，解决了不可重复读问题。 虽然该隔离级别下解决了不可重复读问题，但理论上会导致另一个问题：幻读（Phantom Read）。 一个事务在执行过程中，另一个事务对已有数据行的更改，MVCC机制可保障该事务读取到的原有数据行的内容相同 但并不能阻止另一个事务插入新的数据行，这就会导致该事务中凭空多出数据行，像出现了幻读一样，这便是幻读问题 REPEATABLE READ（可重复读） 该隔离级别是 MySQL 默认的隔离级别，在同一个事务里，select 的结果是事务开始时时间点的状态，因此，同样的 select 操作读到的结果会是一致的，但是，会有幻读现象 123456789101112131415161718192021222324252627282930将A的隔离级别设置为repeatable read(可重复读)SET @@session.transaction_isolation = &apos;REPEATABLE-READ&apos;;create database test;use test;create table test(id int primary key,name varchar(20));A：登录 mysql 终端 A，开启一个事务。start transaction;select * from test; -- 无记录B：登录 mysql 终端 B，开启一个事务。use test;start transaction;select * from test; -- 无记录A:切换到 mysql 终端 A，增加一条记录并提交。insert into test(id,name) values(1,&apos;a&apos;);commit;select * from test; --可以看到已经更改B:切换到 msyql 终端 B。select * from test; --此时查询还是无记录通过这一步可以证明，在该隔离级别下已经读取不到别的已提交的事务，如果想看到 mysql 终端 1 提交的事务，在 mysql 终端 2 将当前事务提交后再次查询就可以读取到 mysql 终端 1 提交的事务。 可重复读隔离级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务部的更新该记录。 B：此时接着在 mysql 终端 B 插入一条数据。insert into test(id,name) values(1,&apos;b&apos;); -- 此时报主键冲突的错误这就是该隔离级别下可能产生的问题，MySQL 称之为幻读。commit; 可串行读（SERIALIZABLE） 这是事务的最高隔离级别，通过强制事务排序，使之不可能相互冲突，就像在每个读的数据行加上共享锁来实现 在该隔离级别下，可以解决前面出现的脏读、不可重复读和幻读问题，但也会导致大量的超时和锁竞争现象，一般不推荐使用 SERIALIZABLE（可串行读） 在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式加一把读共享锁，从而避免了脏读、不可重读复读和幻读问题。 1234567891011121314151617181920A:准备两个终端，在此命名为 mysql 终端 A 和 mysql 终端 B，分别登入 mysql，准备一张测试表 test 并调整隔离级别为 SERIALIZABLE，任意一个终端执行即可。set session transaction isolation level serializable;create database test;use test;create table test(id int primary key);insert into test(id) values(1);A:登录 mysql 终端 A，开启一个事务，并写入一条数据。start transaction;select * from test;B:登录 mysql 终端 B，开启一个事务。start transaction;select * from test; delete from test;A:立马切换到 mysql 终端 A,提交事务。commit;一旦事务提交，msyql 终端 B 会立马返回 ID 为 1 的记录，否则会一直卡住，直到超时，其中超时参数是由 innodb_lock_wait_timeout 控制]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
</search>
